/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
/home/data3/Ali/Code/TabMixer-review/utility/dataset.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  for col in num_cols: X[col].fillna(X[col].mode()[0], inplace=True)
########################################
load from local data dir /home/data3/Ali/Code/TabMixer-review/DATA/Forest/Preprocessed
# data: 581012, # feat: 54, # cate: 0,  # bin: 0, # numerical: 54, pos rate: 0.02
Epoch:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch:   0%|          | 1/1000 [03:37<60:28:47, 217.95s/it]Epoch:   0%|          | 2/1000 [07:17<60:42:37, 219.00s/it]Epoch:   0%|          | 3/1000 [10:56<60:36:46, 218.86s/it]Epoch:   0%|          | 4/1000 [14:36<60:38:15, 219.17s/it]Epoch:   0%|          | 5/1000 [18:15<60:36:38, 219.29s/it]Epoch:   1%|          | 6/1000 [21:54<60:31:46, 219.22s/it]Epoch:   1%|          | 7/1000 [25:34<60:31:31, 219.43s/it]Epoch:   1%|          | 8/1000 [29:13<60:25:54, 219.31s/it]Epoch:   1%|          | 9/1000 [32:52<60:22:25, 219.32s/it]Epoch:   1%|          | 10/1000 [36:32<60:18:58, 219.33s/it]Epoch:   1%|          | 11/1000 [40:10<60:10:08, 219.02s/it]Epoch:   1%|          | 12/1000 [43:48<59:59:56, 218.62s/it]Epoch:   1%|▏         | 13/1000 [47:26<59:54:53, 218.53s/it]Epoch:   1%|▏         | 14/1000 [51:05<59:55:04, 218.77s/it]Epoch:   2%|▏         | 15/1000 [54:44<59:48:27, 218.59s/it]Epoch:   2%|▏         | 16/1000 [58:23<59:48:44, 218.83s/it]Epoch:   2%|▏         | 17/1000 [1:02:02<59:44:59, 218.82s/it]Epoch:   2%|▏         | 18/1000 [1:05:41<59:44:46, 219.03s/it]Epoch:   2%|▏         | 19/1000 [1:09:20<59:39:05, 218.90s/it]Epoch:   2%|▏         | 20/1000 [1:12:59<59:38:07, 219.07s/it]Epoch:   2%|▏         | 21/1000 [1:16:40<59:43:28, 219.62s/it]Epoch:   2%|▏         | 22/1000 [1:20:19<59:33:28, 219.23s/it]Epoch:   2%|▏         | 23/1000 [1:23:57<59:28:01, 219.12s/it]Epoch:   2%|▏         | 24/1000 [1:27:36<59:21:48, 218.96s/it]Epoch:   2%|▎         | 25/1000 [1:31:14<59:14:43, 218.75s/it]Epoch:   3%|▎         | 26/1000 [1:34:54<59:16:50, 219.11s/it]Epoch:   3%|▎         | 27/1000 [1:38:33<59:13:17, 219.11s/it]Epoch:   3%|▎         | 28/1000 [1:42:12<59:07:00, 218.95s/it]Epoch:   3%|▎         | 29/1000 [1:45:50<59:01:27, 218.83s/it]Epoch:   3%|▎         | 30/1000 [1:49:30<59:02:45, 219.14s/it]Epoch:   3%|▎         | 31/1000 [1:53:08<58:54:14, 218.84s/it]Epoch:   3%|▎         | 32/1000 [1:56:49<58:59:36, 219.40s/it]Epoch:   3%|▎         | 33/1000 [2:00:29<58:56:10, 219.41s/it]Epoch:   3%|▎         | 34/1000 [2:04:07<58:46:46, 219.05s/it]Epoch:   4%|▎         | 35/1000 [2:07:46<58:44:04, 219.11s/it]Epoch:   4%|▎         | 36/1000 [2:11:24<58:34:36, 218.75s/it]Epoch:   4%|▎         | 37/1000 [2:15:02<58:29:43, 218.67s/it]Epoch:   4%|▍         | 38/1000 [2:18:42<58:31:14, 219.00s/it]Epoch:   4%|▍         | 39/1000 [2:22:21<58:27:15, 218.98s/it]Epoch:   4%|▍         | 40/1000 [2:26:01<58:29:52, 219.37s/it]Epoch:   4%|▍         | 41/1000 [2:29:42<58:31:16, 219.68s/it]Epoch:   4%|▍         | 42/1000 [2:33:23<58:32:43, 220.00s/it]Epoch:   4%|▍         | 43/1000 [2:37:01<58:22:56, 219.62s/it]Epoch:   4%|▍         | 44/1000 [2:40:41<58:20:58, 219.73s/it]Epoch:   4%|▍         | 45/1000 [2:44:22<58:22:42, 220.07s/it]Epoch:   5%|▍         | 46/1000 [2:48:03<58:23:18, 220.33s/it]Epoch:   5%|▍         | 47/1000 [2:51:44<58:21:41, 220.46s/it]Epoch:   5%|▍         | 48/1000 [2:55:23<58:13:46, 220.20s/it]Epoch:   5%|▍         | 49/1000 [2:59:05<58:14:19, 220.46s/it]Epoch:   5%|▌         | 50/1000 [3:02:46<58:13:16, 220.63s/it]Epoch:   5%|▌         | 51/1000 [3:06:26<58:08:54, 220.58s/it]Epoch:   5%|▌         | 52/1000 [3:10:08<58:11:12, 220.96s/it]Epoch:   5%|▌         | 53/1000 [3:13:47<58:01:08, 220.56s/it]Epoch:   5%|▌         | 54/1000 [3:17:28<57:57:05, 220.53s/it]Epoch:   6%|▌         | 55/1000 [3:21:08<57:49:02, 220.26s/it]Epoch:   6%|▌         | 56/1000 [3:24:47<57:40:44, 219.96s/it]Epoch:   6%|▌         | 57/1000 [3:28:26<57:32:28, 219.67s/it]Epoch:   6%|▌         | 58/1000 [3:32:06<57:29:29, 219.71s/it]Epoch:   6%|▌         | 59/1000 [3:35:45<57:23:37, 219.57s/it]Epoch:   6%|▌         | 60/1000 [3:39:25<57:21:17, 219.66s/it]Epoch:   6%|▌         | 61/1000 [3:43:05<57:19:15, 219.76s/it]Epoch:   6%|▌         | 62/1000 [3:46:44<57:15:14, 219.74s/it]Epoch:   6%|▋         | 63/1000 [3:50:23<57:07:28, 219.48s/it]Epoch:   6%|▋         | 64/1000 [3:54:02<56:59:55, 219.23s/it]Epoch:   6%|▋         | 65/1000 [3:57:42<56:59:17, 219.42s/it]Epoch:   7%|▋         | 66/1000 [4:01:22<56:58:27, 219.60s/it]Epoch:   7%|▋         | 67/1000 [4:05:01<56:51:37, 219.40s/it]Epoch:   7%|▋         | 68/1000 [4:08:41<56:52:50, 219.71s/it]Epoch:   7%|▋         | 69/1000 [4:12:20<56:46:27, 219.54s/it]Epoch:   7%|▋         | 70/1000 [4:16:00<56:41:05, 219.43s/it]Epoch:   7%|▋         | 71/1000 [4:19:41<56:45:28, 219.94s/it]Epoch:   7%|▋         | 72/1000 [4:23:21<56:42:11, 219.97s/it]Epoch:   7%|▋         | 73/1000 [4:27:00<56:34:04, 219.68s/it]Epoch:   7%|▋         | 74/1000 [4:30:41<56:37:14, 220.12s/it]Epoch:   8%|▊         | 75/1000 [4:34:23<56:40:52, 220.60s/it]Epoch:   8%|▊         | 76/1000 [4:38:02<56:30:38, 220.17s/it]Epoch:   8%|▊         | 77/1000 [4:41:41<56:20:55, 219.78s/it]Epoch:   8%|▊         | 78/1000 [4:45:21<56:18:22, 219.85s/it]Epoch:   8%|▊         | 79/1000 [4:49:01<56:15:15, 219.89s/it]Epoch:   8%|▊         | 80/1000 [4:52:40<56:10:51, 219.84s/it]Epoch:   8%|▊         | 81/1000 [4:56:21<56:10:05, 220.03s/it]Epoch:   8%|▊         | 82/1000 [5:00:01<56:07:02, 220.07s/it]Epoch:   8%|▊         | 83/1000 [5:03:41<56:04:52, 220.17s/it]Epoch:   8%|▊         | 84/1000 [5:07:20<55:56:31, 219.86s/it]Epoch:   8%|▊         | 85/1000 [5:11:01<55:54:35, 219.97s/it]Epoch:   9%|▊         | 86/1000 [5:14:41<55:51:51, 220.03s/it]Epoch:   9%|▊         | 87/1000 [5:18:19<55:39:17, 219.45s/it]Epoch:   9%|▉         | 88/1000 [5:21:58<55:32:03, 219.21s/it]Epoch:   9%|▉         | 89/1000 [5:25:36<55:26:33, 219.09s/it]Epoch:   9%|▉         | 90/1000 [5:29:18<55:32:09, 219.70s/it]Epoch:   9%|▉         | 91/1000 [5:32:58<55:32:12, 219.95s/it]Epoch:   9%|▉         | 92/1000 [5:36:39<55:31:22, 220.13s/it]Epoch:   9%|▉         | 93/1000 [5:40:20<55:31:12, 220.37s/it]Epoch:   9%|▉         | 94/1000 [5:43:57<55:15:57, 219.60s/it]Epoch:  10%|▉         | 95/1000 [5:47:38<55:15:04, 219.78s/it]Epoch:  10%|▉         | 96/1000 [5:51:19<55:17:08, 220.16s/it]Epoch:  10%|▉         | 97/1000 [5:54:58<55:09:26, 219.90s/it]Epoch:  10%|▉         | 98/1000 [5:58:38<55:07:25, 220.01s/it]Epoch:  10%|▉         | 99/1000 [6:02:20<55:10:27, 220.45s/it]Epoch:  10%|█         | 100/1000 [6:06:00<55:08:10, 220.55s/it]Epoch:  10%|█         | 101/1000 [6:09:40<55:01:23, 220.34s/it]Epoch:  10%|█         | 102/1000 [6:13:23<55:08:39, 221.07s/it]Epoch:  10%|█         | 103/1000 [6:17:02<54:55:24, 220.43s/it]Epoch:  10%|█         | 104/1000 [6:20:43<54:52:37, 220.49s/it]Epoch:  10%|█         | 105/1000 [6:24:25<54:56:04, 220.97s/it]Epoch:  11%|█         | 106/1000 [6:28:04<54:46:37, 220.58s/it]Epoch:  11%|█         | 107/1000 [6:31:43<54:36:05, 220.12s/it]Epoch:  11%|█         | 108/1000 [6:35:24<54:34:49, 220.28s/it]Epoch:  11%|█         | 109/1000 [6:39:05<54:34:08, 220.48s/it]Epoch:  11%|█         | 110/1000 [6:42:44<54:23:51, 220.04s/it]Epoch:  11%|█         | 111/1000 [6:46:24<54:17:45, 219.87s/it]Epoch:  11%|█         | 112/1000 [6:50:03<54:12:42, 219.78s/it]Epoch:  11%|█▏        | 113/1000 [6:53:43<54:08:41, 219.75s/it]Epoch:  11%|█▏        | 114/1000 [6:57:25<54:14:12, 220.37s/it]Epoch:  12%|█▏        | 115/1000 [7:01:06<54:13:35, 220.58s/it]Epoch:  12%|█▏        | 116/1000 [7:04:47<54:14:55, 220.92s/it]Epoch:  12%|█▏        | 117/1000 [7:08:28<54:09:26, 220.80s/it]Epoch:  12%|█▏        | 118/1000 [7:12:09<54:08:06, 220.96s/it]Epoch:  12%|█▏        | 119/1000 [7:15:48<53:54:11, 220.26s/it]Epoch:  12%|█▏        | 120/1000 [7:19:30<53:56:33, 220.67s/it]Epoch:  12%|█▏        | 121/1000 [7:23:11<53:54:43, 220.80s/it]Epoch:  12%|█▏        | 122/1000 [7:26:51<53:50:51, 220.79s/it]Epoch:  12%|█▏        | 123/1000 [7:30:32<53:47:31, 220.81s/it]Epoch:  12%|█▏        | 124/1000 [7:34:16<53:56:07, 221.65s/it]Epoch:  12%|█▎        | 125/1000 [7:37:56<53:45:15, 221.16s/it]Epoch:  13%|█▎        | 126/1000 [7:41:37<53:41:53, 221.18s/it]Epoch:  13%|█▎        | 127/1000 [7:45:17<53:34:35, 220.93s/it]Epoch:  13%|█▎        | 128/1000 [7:48:58<53:29:38, 220.85s/it]Epoch:  13%|█▎        | 129/1000 [7:52:38<53:23:16, 220.66s/it]Epoch:  13%|█▎        | 130/1000 [7:56:20<53:26:03, 221.11s/it]Epoch:  13%|█▎        | 131/1000 [8:00:00<53:16:42, 220.72s/it]Epoch:  13%|█▎        | 132/1000 [8:03:42<53:18:23, 221.09s/it]Epoch:  13%|█▎        | 133/1000 [8:07:22<53:10:01, 220.76s/it]Epoch:  13%|█▎        | 134/1000 [8:11:01<52:58:01, 220.19s/it]Epoch:  14%|█▎        | 135/1000 [8:14:42<52:58:37, 220.48s/it]Epoch:  14%|█▎        | 136/1000 [8:18:22<52:51:56, 220.27s/it]Epoch:  14%|█▎        | 137/1000 [8:22:01<52:42:57, 219.90s/it]Epoch:  14%|█▍        | 138/1000 [8:25:41<52:37:47, 219.80s/it]Epoch:  14%|█▍        | 139/1000 [8:29:21<52:38:01, 220.07s/it]Epoch:  14%|█▍        | 140/1000 [8:33:01<52:30:44, 219.82s/it]Epoch:  14%|█▍        | 141/1000 [8:36:39<52:22:47, 219.52s/it]Epoch:  14%|█▍        | 142/1000 [8:40:19<52:20:55, 219.65s/it]Epoch:  14%|█▍        | 143/1000 [8:44:00<52:22:09, 219.99s/it]Epoch:  14%|█▍        | 144/1000 [8:47:40<52:16:15, 219.83s/it]Epoch:  14%|█▍        | 145/1000 [8:51:20<52:13:29, 219.89s/it]Epoch:  15%|█▍        | 146/1000 [8:54:58<52:04:35, 219.53s/it]Epoch:  15%|█▍        | 147/1000 [8:58:39<52:05:23, 219.84s/it]Epoch:  15%|█▍        | 148/1000 [9:02:20<52:05:17, 220.09s/it]Epoch:  15%|█▍        | 149/1000 [9:05:58<51:53:53, 219.55s/it]Epoch:  15%|█▌        | 150/1000 [9:09:39<51:56:25, 219.98s/it]Epoch:  15%|█▌        | 151/1000 [9:13:16<51:41:42, 219.20s/it]Epoch:  15%|█▌        | 152/1000 [9:16:54<51:32:47, 218.83s/it]Epoch:  15%|█▌        | 153/1000 [9:20:33<51:29:38, 218.87s/it]Epoch:  15%|█▌        | 154/1000 [9:24:12<51:24:24, 218.75s/it]Epoch:  16%|█▌        | 155/1000 [9:27:51<51:22:09, 218.85s/it]Epoch:  16%|█▌        | 156/1000 [9:31:30<51:21:03, 219.03s/it]Epoch:  16%|█▌        | 157/1000 [9:35:09<51:15:12, 218.88s/it]Epoch:  16%|█▌        | 158/1000 [9:38:47<51:08:16, 218.64s/it]Epoch:  16%|█▌        | 159/1000 [9:42:25<51:03:43, 218.58s/it]Epoch:  16%|█▌        | 160/1000 [9:46:04<51:02:59, 218.79s/it]Epoch:  16%|█▌        | 161/1000 [9:49:45<51:05:14, 219.21s/it]Epoch:  16%|█▌        | 162/1000 [9:53:24<51:02:02, 219.24s/it]Epoch:  16%|█▋        | 163/1000 [9:57:03<50:57:57, 219.21s/it]Epoch:  16%|█▋        | 164/1000 [10:00:43<50:55:23, 219.29s/it]Epoch:  16%|█▋        | 165/1000 [10:04:22<50:53:28, 219.41s/it]Epoch:  17%|█▋        | 166/1000 [10:08:03<50:54:35, 219.75s/it]Epoch:  17%|█▋        | 167/1000 [10:11:43<50:53:00, 219.91s/it]Epoch:  17%|█▋        | 168/1000 [10:15:24<50:52:41, 220.15s/it]Epoch:  17%|█▋        | 169/1000 [10:19:05<50:54:47, 220.56s/it]Epoch:  17%|█▋        | 170/1000 [10:22:47<50:55:38, 220.89s/it]Epoch:  17%|█▋        | 171/1000 [10:26:26<50:44:29, 220.35s/it]Epoch:  17%|█▋        | 172/1000 [10:30:06<50:37:29, 220.11s/it]Epoch:  17%|█▋        | 173/1000 [10:33:45<50:29:23, 219.79s/it]Epoch:  17%|█▋        | 174/1000 [10:37:24<50:22:47, 219.57s/it]Epoch:  18%|█▊        | 175/1000 [10:41:03<50:19:58, 219.63s/it]Epoch:  18%|█▊        | 176/1000 [10:44:42<50:12:49, 219.38s/it]Epoch:  18%|█▊        | 177/1000 [10:48:21<50:06:49, 219.21s/it]Epoch:  18%|█▊        | 178/1000 [10:52:01<50:04:40, 219.32s/it]Epoch:  18%|█▊        | 179/1000 [10:55:40<50:02:10, 219.40s/it]Epoch:  18%|█▊        | 180/1000 [10:59:20<49:58:21, 219.39s/it]Epoch:  18%|█▊        | 181/1000 [11:02:58<49:50:13, 219.06s/it]Epoch:  18%|█▊        | 182/1000 [11:06:36<49:42:42, 218.78s/it]Epoch:  18%|█▊        | 183/1000 [11:10:14<49:35:15, 218.50s/it]Epoch:  18%|█▊        | 184/1000 [11:13:52<49:32:00, 218.53s/it]Epoch:  18%|█▊        | 185/1000 [11:17:30<49:24:48, 218.27s/it]Epoch:  19%|█▊        | 186/1000 [11:21:09<49:22:21, 218.36s/it]Epoch:  19%|█▊        | 187/1000 [11:24:47<49:19:52, 218.44s/it]Epoch:  19%|█▉        | 188/1000 [11:28:26<49:15:09, 218.36s/it]Epoch:  19%|█▉        | 189/1000 [11:32:05<49:14:03, 218.55s/it]Epoch:  19%|█▉        | 190/1000 [11:35:43<49:11:07, 218.60s/it]Epoch:  19%|█▉        | 191/1000 [11:39:22<49:08:46, 218.70s/it]Epoch:  19%|█▉        | 192/1000 [11:43:02<49:10:07, 219.07s/it]Epoch:  19%|█▉        | 193/1000 [11:46:41<49:04:53, 218.95s/it]Epoch:  19%|█▉        | 194/1000 [11:50:19<48:58:02, 218.71s/it]Epoch:  20%|█▉        | 195/1000 [11:54:00<49:05:52, 219.57s/it]Epoch:  20%|█▉        | 196/1000 [11:57:39<48:59:26, 219.36s/it]Epoch:  20%|█▉        | 197/1000 [12:01:19<48:57:45, 219.51s/it]Epoch:  20%|█▉        | 198/1000 [12:04:58<48:51:02, 219.28s/it]Epoch:  20%|█▉        | 199/1000 [12:08:37<48:45:28, 219.14s/it]Epoch:  20%|██        | 200/1000 [12:12:16<48:43:13, 219.24s/it]Epoch:  20%|██        | 201/1000 [12:15:54<48:35:09, 218.91s/it]Epoch:  20%|██        | 202/1000 [12:19:33<48:30:20, 218.82s/it]Epoch:  20%|██        | 203/1000 [12:23:13<48:29:34, 219.04s/it]Epoch:  20%|██        | 204/1000 [12:26:51<48:24:59, 218.97s/it]Epoch:  20%|██        | 205/1000 [12:30:31<48:23:03, 219.10s/it]Epoch:  21%|██        | 206/1000 [12:34:10<48:18:02, 219.00s/it]Epoch:  21%|██        | 207/1000 [12:37:51<48:23:22, 219.67s/it]Epoch:  21%|██        | 208/1000 [12:41:30<48:17:26, 219.50s/it]Epoch:  21%|██        | 209/1000 [12:45:09<48:11:25, 219.32s/it]Epoch:  21%|██        | 210/1000 [12:48:48<48:08:12, 219.36s/it]Epoch:  21%|██        | 211/1000 [12:52:29<48:09:08, 219.71s/it]Epoch:  21%|██        | 212/1000 [12:56:08<48:04:07, 219.60s/it]Epoch:  21%|██▏       | 213/1000 [12:59:47<47:58:21, 219.44s/it]Epoch:  21%|██▏       | 214/1000 [13:03:26<47:51:05, 219.17s/it]Epoch:  22%|██▏       | 215/1000 [13:07:04<47:42:53, 218.82s/it]Epoch:  22%|██▏       | 216/1000 [13:10:45<47:47:26, 219.45s/it]Epoch:  22%|██▏       | 217/1000 [13:14:23<47:41:25, 219.27s/it]Epoch:  22%|██▏       | 218/1000 [13:18:04<47:44:08, 219.76s/it]Epoch:  22%|██▏       | 219/1000 [13:21:45<47:45:30, 220.14s/it]Epoch:  22%|██▏       | 220/1000 [13:25:26<47:45:15, 220.40s/it]Epoch:  22%|██▏       | 221/1000 [13:29:07<47:41:16, 220.38s/it]Epoch:  22%|██▏       | 222/1000 [13:32:46<47:31:34, 219.92s/it]Epoch:  22%|██▏       | 223/1000 [13:36:25<47:26:49, 219.83s/it]Epoch:  22%|██▏       | 224/1000 [13:40:05<47:23:06, 219.83s/it]Epoch:  22%|██▎       | 225/1000 [13:43:45<47:18:32, 219.76s/it]Epoch:  23%|██▎       | 226/1000 [13:47:25<47:16:01, 219.85s/it]Epoch:  23%|██▎       | 227/1000 [13:51:05<47:12:26, 219.85s/it]Epoch:  23%|██▎       | 228/1000 [13:54:45<47:09:20, 219.90s/it]Epoch:  23%|██▎       | 229/1000 [13:58:23<47:01:30, 219.57s/it]Epoch:  23%|██▎       | 230/1000 [14:02:03<46:57:11, 219.52s/it]Epoch:  23%|██▎       | 231/1000 [14:05:41<46:47:45, 219.07s/it]Epoch:  23%|██▎       | 232/1000 [14:09:19<46:41:20, 218.85s/it]Epoch:  23%|██▎       | 233/1000 [14:12:58<46:39:09, 218.97s/it]Epoch:  23%|██▎       | 234/1000 [14:16:38<46:38:54, 219.24s/it]Epoch:  24%|██▎       | 235/1000 [14:20:19<46:39:40, 219.58s/it]Epoch:  24%|██▎       | 236/1000 [14:23:57<46:33:17, 219.37s/it]Epoch:  24%|██▎       | 237/1000 [14:27:35<46:24:21, 218.95s/it]Epoch:  24%|██▍       | 238/1000 [14:31:14<46:18:12, 218.76s/it]Epoch:  24%|██▍       | 239/1000 [14:34:54<46:18:57, 219.10s/it]Epoch:  24%|██▍       | 240/1000 [14:38:33<46:17:22, 219.27s/it]Epoch:  24%|██▍       | 241/1000 [14:42:12<46:10:42, 219.03s/it]Epoch:  24%|██▍       | 242/1000 [14:45:51<46:07:17, 219.05s/it]Epoch:  24%|██▍       | 243/1000 [14:49:30<46:03:06, 219.00s/it]Epoch:  24%|██▍       | 244/1000 [14:53:08<45:56:10, 218.74s/it]Epoch:  24%|██▍       | 245/1000 [14:56:45<45:46:32, 218.27s/it]Epoch:  25%|██▍       | 246/1000 [15:00:23<45:41:58, 218.19s/it]Epoch:  25%|██▍       | 247/1000 [15:04:02<45:42:23, 218.52s/it]Epoch:  25%|██▍       | 248/1000 [15:07:41<45:38:49, 218.52s/it]Epoch:  25%|██▍       | 249/1000 [15:11:23<45:48:34, 219.59s/it]Epoch:  25%|██▌       | 250/1000 [15:15:01<45:38:00, 219.04s/it]Epoch:  25%|██▌       | 251/1000 [15:18:40<45:33:29, 218.97s/it]Epoch:  25%|██▌       | 252/1000 [15:22:19<45:33:04, 219.23s/it]Epoch:  25%|██▌       | 253/1000 [15:25:58<45:26:53, 219.03s/it]Epoch:  25%|██▌       | 254/1000 [15:29:38<45:25:15, 219.19s/it]Epoch:  26%|██▌       | 255/1000 [15:33:18<45:26:19, 219.57s/it]Epoch:  26%|██▌       | 256/1000 [15:36:59<45:27:35, 219.97s/it]Epoch:  26%|██▌       | 257/1000 [15:40:38<45:19:04, 219.58s/it]Epoch:  26%|██▌       | 258/1000 [15:44:17<45:13:37, 219.43s/it]Epoch:  26%|██▌       | 259/1000 [15:47:55<45:07:14, 219.21s/it]Epoch:  26%|██▌       | 260/1000 [15:51:33<44:59:33, 218.88s/it]Epoch:  26%|██▌       | 261/1000 [15:55:14<45:01:12, 219.31s/it]Epoch:  26%|██▌       | 262/1000 [15:58:52<44:54:49, 219.09s/it]Epoch:  26%|██▋       | 263/1000 [16:02:31<44:50:55, 219.07s/it]Epoch:  26%|██▋       | 264/1000 [16:06:09<44:42:16, 218.66s/it]Epoch:  26%|██▋       | 265/1000 [16:09:47<44:35:35, 218.42s/it]Epoch:  27%|██▋       | 266/1000 [16:13:25<44:32:24, 218.45s/it]Epoch:  27%|██▋       | 267/1000 [16:17:04<44:30:14, 218.57s/it]Epoch:  27%|██▋       | 268/1000 [16:20:46<44:38:05, 219.52s/it]Epoch:  27%|██▋       | 269/1000 [16:24:27<44:39:21, 219.92s/it]Epoch:  27%|██▋       | 270/1000 [16:28:08<44:38:40, 220.17s/it]Epoch:  27%|██▋       | 271/1000 [16:31:49<44:38:46, 220.47s/it]Epoch:  27%|██▋       | 272/1000 [16:35:33<44:50:09, 221.72s/it]Epoch:  27%|██▋       | 273/1000 [16:39:19<44:59:48, 222.82s/it]Epoch:  27%|██▋       | 274/1000 [16:43:01<44:52:58, 222.56s/it]Epoch:  28%|██▊       | 275/1000 [16:46:41<44:41:49, 221.94s/it]Epoch:  28%|██▊       | 276/1000 [16:50:21<44:30:44, 221.33s/it]Epoch:  28%|██▊       | 277/1000 [16:54:02<44:24:45, 221.14s/it]Epoch:  28%|██▊       | 278/1000 [16:57:42<44:18:58, 220.97s/it]Epoch:  28%|██▊       | 279/1000 [17:01:23<44:12:11, 220.71s/it]Epoch:  28%|██▊       | 280/1000 [17:05:05<44:14:51, 221.24s/it]Epoch:  28%|██▊       | 281/1000 [17:08:46<44:10:11, 221.16s/it]Epoch:  28%|██▊       | 282/1000 [17:12:28<44:11:06, 221.54s/it]Epoch:  28%|██▊       | 283/1000 [17:16:10<44:08:08, 221.60s/it]Epoch:  28%|██▊       | 284/1000 [17:19:52<44:06:11, 221.75s/it]Epoch:  28%|██▊       | 285/1000 [17:23:34<44:03:02, 221.79s/it]Epoch:  29%|██▊       | 286/1000 [17:27:18<44:06:24, 222.39s/it]Epoch:  29%|██▊       | 287/1000 [17:30:57<43:52:09, 221.50s/it]Epoch:  29%|██▉       | 288/1000 [17:34:38<43:45:02, 221.21s/it]Epoch:  29%|██▉       | 289/1000 [17:38:18<43:37:34, 220.89s/it]Epoch:  29%|██▉       | 290/1000 [17:41:57<43:25:39, 220.20s/it]Epoch:  29%|██▉       | 291/1000 [17:45:38<43:25:08, 220.46s/it]Epoch:  29%|██▉       | 292/1000 [17:49:18<43:22:23, 220.54s/it]Epoch:  29%|██▉       | 293/1000 [17:52:58<43:15:26, 220.26s/it]Epoch:  29%|██▉       | 294/1000 [17:56:41<43:22:22, 221.17s/it]Epoch:  30%|██▉       | 295/1000 [18:00:21<43:13:58, 220.76s/it]Epoch:  30%|██▉       | 296/1000 [18:04:02<43:10:55, 220.82s/it]Epoch:  30%|██▉       | 297/1000 [18:07:41<43:01:31, 220.33s/it]Epoch:  30%|██▉       | 298/1000 [18:11:21<42:55:00, 220.09s/it]Epoch:  30%|██▉       | 299/1000 [18:15:01<42:52:03, 220.15s/it]Epoch:  30%|███       | 300/1000 [18:18:40<42:45:49, 219.93s/it]Epoch:  30%|███       | 301/1000 [18:22:21<42:43:38, 220.05s/it]Epoch:  30%|███       | 302/1000 [18:26:00<42:38:31, 219.93s/it]Epoch:  30%|███       | 303/1000 [18:29:39<42:29:53, 219.50s/it]Epoch:  30%|███       | 304/1000 [18:33:17<42:19:37, 218.93s/it]Epoch:  30%|███       | 305/1000 [18:36:56<42:16:06, 218.94s/it]Epoch:  31%|███       | 306/1000 [18:40:35<42:14:03, 219.08s/it]Epoch:  31%|███       | 307/1000 [18:44:14<42:09:11, 218.98s/it]Epoch:  31%|███       | 308/1000 [18:47:52<42:01:36, 218.64s/it]Epoch:  31%|███       | 309/1000 [18:51:31<42:00:10, 218.83s/it]Epoch:  31%|███       | 310/1000 [18:55:11<41:59:28, 219.08s/it]Epoch:  31%|███       | 311/1000 [18:58:48<41:50:47, 218.65s/it]Epoch:  31%|███       | 312/1000 [19:02:29<41:56:19, 219.45s/it]Epoch:  31%|███▏      | 313/1000 [19:06:10<41:57:51, 219.90s/it]Epoch:  31%|███▏      | 314/1000 [19:09:50<41:52:42, 219.77s/it]Epoch:  32%|███▏      | 315/1000 [19:13:29<41:46:44, 219.57s/it]Epoch:  32%|███▏      | 316/1000 [19:17:08<41:39:34, 219.26s/it]Epoch:  32%|███▏      | 317/1000 [19:20:46<41:33:56, 219.09s/it]Epoch:  32%|███▏      | 318/1000 [19:24:25<41:28:49, 218.96s/it]Epoch:  32%|███▏      | 319/1000 [19:28:04<41:26:39, 219.09s/it]Epoch:  32%|███▏      | 320/1000 [19:31:44<41:26:46, 219.42s/it]Epoch:  32%|███▏      | 321/1000 [19:35:23<41:20:12, 219.16s/it]Epoch:  32%|███▏      | 322/1000 [19:39:04<41:23:34, 219.79s/it]Epoch:  32%|███▏      | 323/1000 [19:42:44<41:20:27, 219.83s/it]Epoch:  32%|███▏      | 324/1000 [19:46:25<41:20:41, 220.18s/it]Epoch:  32%|███▎      | 325/1000 [19:50:04<41:11:22, 219.68s/it]Epoch:  33%|███▎      | 326/1000 [19:53:42<41:04:11, 219.36s/it]Epoch:  33%|███▎      | 327/1000 [19:57:23<41:05:22, 219.80s/it]Epoch:  33%|███▎      | 328/1000 [20:01:03<41:01:22, 219.77s/it]Epoch:  33%|███▎      | 329/1000 [20:04:44<41:03:13, 220.26s/it]Epoch:  33%|███▎      | 330/1000 [20:08:24<40:59:10, 220.22s/it]Epoch:  33%|███▎      | 331/1000 [20:12:05<40:56:17, 220.30s/it]Epoch:  33%|███▎      | 332/1000 [20:15:47<40:58:11, 220.80s/it]Epoch:  33%|███▎      | 333/1000 [20:19:27<40:52:27, 220.61s/it]Epoch:  33%|███▎      | 334/1000 [20:23:06<40:44:58, 220.27s/it]Epoch:  34%|███▎      | 335/1000 [20:26:46<40:38:29, 220.01s/it]Epoch:  34%|███▎      | 336/1000 [20:30:25<40:31:53, 219.75s/it]Epoch:  34%|███▎      | 337/1000 [20:34:05<40:29:32, 219.87s/it]Epoch:  34%|███▍      | 338/1000 [20:37:44<40:23:24, 219.64s/it]Epoch:  34%|███▍      | 339/1000 [20:41:23<40:16:55, 219.39s/it]Epoch:  34%|███▍      | 340/1000 [20:45:00<40:06:23, 218.76s/it]Epoch:  34%|███▍      | 341/1000 [20:48:39<40:02:51, 218.77s/it]Epoch:  34%|███▍      | 342/1000 [20:52:19<40:02:17, 219.05s/it]Epoch:  34%|███▍      | 343/1000 [20:56:00<40:05:18, 219.66s/it]Epoch:  34%|███▍      | 344/1000 [20:59:39<40:00:27, 219.55s/it]Epoch:  34%|███▍      | 345/1000 [21:03:18<39:53:29, 219.25s/it]Epoch:  35%|███▍      | 346/1000 [21:06:56<39:46:47, 218.97s/it]Epoch:  35%|███▍      | 347/1000 [21:10:36<39:44:40, 219.11s/it]Epoch:  35%|███▍      | 348/1000 [21:14:17<39:48:28, 219.80s/it]Epoch:  35%|███▍      | 349/1000 [21:17:56<39:41:19, 219.48s/it]Epoch:  35%|███▌      | 350/1000 [21:21:36<39:41:10, 219.80s/it]Epoch:  35%|███▌      | 351/1000 [21:25:16<39:36:59, 219.75s/it]Epoch:  35%|███▌      | 352/1000 [21:28:56<39:34:44, 219.88s/it]Epoch:  35%|███▌      | 353/1000 [21:32:34<39:26:13, 219.43s/it]Epoch:  35%|███▌      | 354/1000 [21:36:14<39:22:55, 219.47s/it]Epoch:  36%|███▌      | 355/1000 [21:39:55<39:25:32, 220.05s/it]Epoch:  36%|███▌      | 356/1000 [21:43:36<39:22:25, 220.10s/it]Epoch:  36%|███▌      | 357/1000 [21:47:14<39:13:17, 219.59s/it]Epoch:  36%|███▌      | 358/1000 [21:50:54<39:11:24, 219.76s/it]Epoch:  36%|███▌      | 359/1000 [21:54:33<39:05:15, 219.53s/it]Epoch:  36%|███▌      | 360/1000 [21:58:15<39:08:23, 220.16s/it]Epoch:  36%|███▌      | 361/1000 [22:01:53<38:59:35, 219.68s/it]Epoch:  36%|███▌      | 362/1000 [22:05:31<38:49:00, 219.03s/it]Epoch:  36%|███▋      | 363/1000 [22:09:08<38:38:44, 218.41s/it]Epoch:  36%|███▋      | 364/1000 [22:12:45<38:29:38, 217.89s/it]Epoch:  36%|███▋      | 365/1000 [22:16:22<38:25:35, 217.85s/it]Epoch:  37%|███▋      | 366/1000 [22:20:00<38:20:18, 217.69s/it]Epoch:  37%|███▋      | 367/1000 [22:23:36<38:13:14, 217.37s/it]Epoch:  37%|███▋      | 368/1000 [22:27:13<38:08:59, 217.31s/it]Epoch:  37%|███▋      | 369/1000 [22:30:51<38:07:19, 217.50s/it]Epoch:  37%|███▋      | 370/1000 [22:34:28<38:02:34, 217.39s/it]Epoch:  37%|███▋      | 371/1000 [22:38:05<37:56:10, 217.12s/it]Epoch:  37%|███▋      | 372/1000 [22:41:42<37:53:02, 217.17s/it]Epoch:  37%|███▋      | 373/1000 [22:45:20<37:51:40, 217.39s/it]Epoch:  37%|███▋      | 374/1000 [22:48:58<37:50:13, 217.59s/it]Epoch:  38%|███▊      | 375/1000 [22:52:35<37:44:45, 217.42s/it]Epoch:  38%|███▊      | 376/1000 [22:56:13<37:42:29, 217.55s/it]Epoch:  38%|███▊      | 377/1000 [22:59:50<37:37:54, 217.46s/it]Epoch:  38%|███▊      | 378/1000 [23:03:28<37:35:06, 217.53s/it]Epoch:  38%|███▊      | 379/1000 [23:07:06<37:32:03, 217.59s/it]Epoch:  38%|███▊      | 380/1000 [23:10:44<37:29:36, 217.70s/it]Epoch:  38%|███▊      | 381/1000 [23:14:21<37:25:06, 217.62s/it]Epoch:  38%|███▊      | 382/1000 [23:17:58<37:19:32, 217.43s/it]Epoch:  38%|███▊      | 383/1000 [23:21:34<37:11:12, 216.97s/it]Epoch:  38%|███▊      | 384/1000 [23:25:12<37:09:22, 217.15s/it]Epoch:  38%|███▊      | 385/1000 [23:28:49<37:07:23, 217.31s/it]Epoch:  39%|███▊      | 386/1000 [23:32:27<37:06:39, 217.59s/it]Epoch:  39%|███▊      | 387/1000 [23:36:05<37:04:17, 217.71s/it]Epoch:  39%|███▉      | 388/1000 [23:39:42<36:58:02, 217.46s/it]Epoch:  39%|███▉      | 389/1000 [23:43:21<36:58:03, 217.81s/it]Epoch:  39%|███▉      | 390/1000 [23:46:58<36:53:08, 217.69s/it]Epoch:  39%|███▉      | 391/1000 [23:50:37<36:52:11, 217.95s/it]Epoch:  39%|███▉      | 392/1000 [23:54:15<36:49:18, 218.02s/it]Epoch:  39%|███▉      | 393/1000 [23:57:52<36:41:57, 217.66s/it]Epoch:  39%|███▉      | 394/1000 [24:01:30<36:38:45, 217.70s/it]Epoch:  40%|███▉      | 395/1000 [24:05:07<36:33:22, 217.53s/it]Epoch:  40%|███▉      | 396/1000 [24:08:43<36:26:25, 217.19s/it]Epoch:  40%|███▉      | 397/1000 [24:12:20<36:20:00, 216.92s/it]Epoch:  40%|███▉      | 398/1000 [24:15:55<36:13:25, 216.62s/it]Epoch:  40%|███▉      | 399/1000 [24:19:32<36:10:31, 216.69s/it]Epoch:  40%|████      | 400/1000 [24:23:09<36:08:15, 216.83s/it]Epoch:  40%|████      | 401/1000 [24:26:45<36:01:41, 216.53s/it]Epoch:  40%|████      | 402/1000 [24:30:22<35:57:44, 216.50s/it]Epoch:  40%|████      | 403/1000 [24:33:58<35:53:25, 216.42s/it]Epoch:  40%|████      | 404/1000 [24:37:35<35:50:50, 216.53s/it]Epoch:  40%|████      | 405/1000 [24:41:12<35:49:06, 216.72s/it]Epoch:  41%|████      | 406/1000 [24:44:47<35:41:20, 216.30s/it]Epoch:  41%|████      | 407/1000 [24:48:24<35:39:22, 216.46s/it]Epoch:  41%|████      | 408/1000 [24:52:01<35:38:05, 216.70s/it]Epoch:  41%|████      | 409/1000 [24:55:38<35:34:45, 216.73s/it]Epoch:  41%|████      | 410/1000 [24:59:15<35:30:37, 216.67s/it]Epoch:  41%|████      | 411/1000 [25:02:52<35:28:05, 216.78s/it]Epoch:  41%|████      | 412/1000 [25:06:28<35:24:26, 216.78s/it]Epoch:  41%|████▏     | 413/1000 [25:10:06<35:21:49, 216.88s/it]Epoch:  41%|████▏     | 414/1000 [25:13:43<35:19:31, 217.02s/it]Epoch:  42%|████▏     | 415/1000 [25:17:19<35:14:19, 216.85s/it]Epoch:  42%|████▏     | 416/1000 [25:20:56<35:09:55, 216.77s/it]Epoch:  42%|████▏     | 417/1000 [25:24:33<35:06:18, 216.77s/it]Epoch:  42%|████▏     | 418/1000 [25:28:10<35:02:58, 216.80s/it]Epoch:  42%|████▏     | 419/1000 [25:31:47<35:00:15, 216.89s/it]Epoch:  42%|████▏     | 420/1000 [25:35:24<34:57:33, 216.99s/it]Epoch:  42%|████▏     | 421/1000 [25:39:01<34:54:03, 217.00s/it]Epoch:  42%|████▏     | 422/1000 [25:42:38<34:49:55, 216.95s/it]Epoch:  42%|████▏     | 423/1000 [25:46:14<34:45:12, 216.83s/it]Epoch:  42%|████▏     | 424/1000 [25:49:50<34:37:50, 216.44s/it]Epoch:  42%|████▎     | 425/1000 [25:53:27<34:35:21, 216.56s/it]Epoch:  43%|████▎     | 426/1000 [25:57:04<34:33:06, 216.70s/it]Epoch:  43%|████▎     | 427/1000 [26:00:41<34:29:33, 216.71s/it]Epoch:  43%|████▎     | 428/1000 [26:04:17<34:26:03, 216.72s/it]Epoch:  43%|████▎     | 429/1000 [26:07:54<34:22:12, 216.69s/it]Epoch:  43%|████▎     | 430/1000 [26:11:29<34:14:51, 216.30s/it]Epoch:  43%|████▎     | 431/1000 [26:15:06<34:11:19, 216.31s/it]Epoch:  43%|████▎     | 432/1000 [26:18:42<34:07:14, 216.26s/it]Epoch:  43%|████▎     | 433/1000 [26:22:17<34:00:37, 215.94s/it]Epoch:  43%|████▎     | 434/1000 [26:25:54<33:58:54, 216.14s/it]Epoch:  44%|████▎     | 435/1000 [26:29:31<33:58:05, 216.44s/it]Epoch:  44%|████▎     | 436/1000 [26:33:08<33:57:05, 216.71s/it]Epoch:  44%|████▎     | 437/1000 [26:36:45<33:55:23, 216.92s/it]Epoch:  44%|████▍     | 438/1000 [26:40:23<33:52:46, 217.02s/it]Epoch:  44%|████▍     | 439/1000 [26:43:59<33:47:28, 216.84s/it]Epoch:  44%|████▍     | 440/1000 [26:47:36<33:43:48, 216.84s/it]Epoch:  44%|████▍     | 441/1000 [26:51:13<33:39:38, 216.78s/it]Epoch:  44%|████▍     | 442/1000 [26:54:50<33:38:37, 217.06s/it]Epoch:  44%|████▍     | 443/1000 [26:58:28<33:37:42, 217.35s/it]Epoch:  44%|████▍     | 444/1000 [27:02:06<33:35:23, 217.49s/it]Epoch:  44%|████▍     | 445/1000 [27:05:44<33:32:26, 217.56s/it]Epoch:  45%|████▍     | 446/1000 [27:09:22<33:29:05, 217.59s/it]Epoch:  45%|████▍     | 447/1000 [27:12:59<33:25:10, 217.56s/it]Epoch:  45%|████▍     | 448/1000 [27:16:36<33:19:45, 217.37s/it]Epoch:  45%|████▍     | 449/1000 [27:20:13<33:15:21, 217.28s/it]Epoch:  45%|████▌     | 450/1000 [27:23:51<33:13:59, 217.53s/it]Epoch:  45%|████▌     | 451/1000 [27:27:28<33:09:39, 217.45s/it]Epoch:  45%|████▌     | 452/1000 [27:31:06<33:06:03, 217.45s/it]Epoch:  45%|████▌     | 453/1000 [27:34:43<33:01:36, 217.36s/it]Epoch:  45%|████▌     | 454/1000 [27:38:20<32:58:00, 217.36s/it]Epoch:  46%|████▌     | 455/1000 [27:41:59<32:56:40, 217.62s/it]Epoch:  46%|████▌     | 456/1000 [27:45:36<32:53:12, 217.63s/it]Epoch:  46%|████▌     | 457/1000 [27:49:14<32:50:18, 217.71s/it]Epoch:  46%|████▌     | 458/1000 [27:52:52<32:47:04, 217.76s/it]Epoch:  46%|████▌     | 459/1000 [27:56:29<32:42:31, 217.65s/it]Epoch:  46%|████▌     | 460/1000 [28:00:05<32:34:22, 217.15s/it]Epoch:  46%|████▌     | 461/1000 [28:03:42<32:28:40, 216.92s/it]Epoch:  46%|████▌     | 462/1000 [28:07:19<32:25:30, 216.97s/it]Epoch:  46%|████▋     | 463/1000 [28:10:57<32:24:26, 217.26s/it]Epoch:  46%|████▋     | 464/1000 [28:14:35<32:22:07, 217.40s/it]Epoch:  46%|████▋     | 465/1000 [28:18:12<32:19:14, 217.49s/it]Epoch:  47%|████▋     | 466/1000 [28:21:50<32:17:08, 217.66s/it]Epoch:  47%|████▋     | 467/1000 [28:25:28<32:12:31, 217.54s/it]Epoch:  47%|████▋     | 468/1000 [28:29:04<32:06:17, 217.25s/it]Epoch:  47%|████▋     | 469/1000 [28:32:42<32:03:28, 217.34s/it]Epoch:  47%|████▋     | 470/1000 [28:36:19<32:00:31, 217.42s/it]Epoch:  47%|████▋     | 471/1000 [28:39:57<31:59:03, 217.66s/it]Epoch:  47%|████▋     | 472/1000 [28:43:34<31:53:23, 217.43s/it]Epoch:  47%|████▋     | 473/1000 [28:47:11<31:46:49, 217.10s/it]Epoch:  47%|████▋     | 474/1000 [28:50:48<31:43:02, 217.08s/it]Epoch:  48%|████▊     | 475/1000 [28:54:25<31:38:57, 217.02s/it]Epoch:  48%|████▊     | 476/1000 [28:58:01<31:32:48, 216.73s/it]Epoch:  48%|████▊     | 477/1000 [29:01:37<31:28:42, 216.68s/it]Epoch:  48%|████▊     | 478/1000 [29:05:13<31:23:16, 216.47s/it]Epoch:  48%|████▊     | 479/1000 [29:08:50<31:21:17, 216.65s/it]Epoch:  48%|████▊     | 480/1000 [29:12:27<31:17:48, 216.67s/it]Epoch:  48%|████▊     | 481/1000 [29:16:04<31:14:56, 216.76s/it]Epoch:  48%|████▊     | 482/1000 [29:19:40<31:09:55, 216.59s/it]Epoch:  48%|████▊     | 483/1000 [29:23:17<31:07:15, 216.70s/it]Epoch:  48%|████▊     | 484/1000 [29:26:54<31:05:07, 216.87s/it]Epoch:  48%|████▊     | 485/1000 [29:30:29<30:56:21, 216.27s/it]Epoch:  49%|████▊     | 486/1000 [29:34:06<30:53:27, 216.36s/it]Epoch:  49%|████▊     | 487/1000 [29:37:43<30:51:09, 216.51s/it]Epoch:  49%|████▉     | 488/1000 [29:41:20<30:48:53, 216.67s/it]Epoch:  49%|████▉     | 489/1000 [29:44:57<30:46:16, 216.78s/it]Epoch:  49%|████▉     | 490/1000 [29:48:34<30:43:33, 216.89s/it]Epoch:  49%|████▉     | 491/1000 [29:52:11<30:39:23, 216.82s/it]Epoch:  49%|████▉     | 492/1000 [29:55:47<30:35:18, 216.77s/it]Epoch:  49%|████▉     | 493/1000 [29:59:24<30:31:42, 216.77s/it]Epoch:  49%|████▉     | 494/1000 [30:03:02<30:31:13, 217.14s/it]Epoch:  50%|████▉     | 495/1000 [30:06:40<30:28:52, 217.29s/it]Epoch:  50%|████▉     | 496/1000 [30:10:16<30:23:09, 217.04s/it]Epoch:  50%|████▉     | 497/1000 [30:13:53<30:18:15, 216.89s/it]Epoch:  50%|████▉     | 498/1000 [30:17:27<30:08:54, 216.20s/it]Epoch:  50%|████▉     | 499/1000 [30:21:05<30:08:55, 216.64s/it]Epoch:  50%|█████     | 500/1000 [30:24:42<30:07:32, 216.91s/it]Epoch:  50%|█████     | 501/1000 [30:28:20<30:05:45, 217.12s/it]Epoch:  50%|█████     | 502/1000 [30:31:58<30:03:20, 217.27s/it]Epoch:  50%|█████     | 503/1000 [30:35:35<30:00:13, 217.33s/it]Epoch:  50%|█████     | 504/1000 [30:39:13<29:58:34, 217.57s/it]Epoch:  50%|█████     | 505/1000 [30:42:51<29:55:02, 217.58s/it]Epoch:  51%|█████     | 506/1000 [30:46:28<29:51:06, 217.54s/it]Epoch:  51%|█████     | 507/1000 [30:50:06<29:47:29, 217.55s/it]Epoch:  51%|█████     | 508/1000 [30:53:43<29:43:02, 217.44s/it]Epoch:  51%|█████     | 509/1000 [30:57:20<29:38:53, 217.38s/it]Epoch:  51%|█████     | 510/1000 [31:00:57<29:32:28, 217.04s/it]Epoch:  51%|█████     | 511/1000 [31:04:32<29:25:12, 216.59s/it]Epoch:  51%|█████     | 512/1000 [31:08:09<29:22:02, 216.64s/it]Epoch:  51%|█████▏    | 513/1000 [31:11:46<29:19:37, 216.79s/it]Epoch:  51%|█████▏    | 514/1000 [31:15:23<29:16:24, 216.84s/it]Epoch:  52%|█████▏    | 515/1000 [31:19:00<29:12:17, 216.78s/it]Epoch:  52%|█████▏    | 516/1000 [31:22:37<29:10:05, 216.95s/it]Epoch:  52%|█████▏    | 517/1000 [31:26:15<29:08:36, 217.22s/it]Epoch:  52%|█████▏    | 518/1000 [31:29:52<29:05:53, 217.33s/it]Epoch:  52%|█████▏    | 519/1000 [31:33:29<29:01:12, 217.20s/it]Epoch:  52%|█████▏    | 520/1000 [31:37:07<28:57:50, 217.23s/it]Epoch:  52%|█████▏    | 521/1000 [31:40:44<28:54:50, 217.31s/it]Epoch:  52%|█████▏    | 522/1000 [31:44:22<28:51:41, 217.37s/it]Epoch:  52%|█████▏    | 523/1000 [31:47:59<28:48:00, 217.36s/it]Epoch:  52%|█████▏    | 524/1000 [31:51:36<28:44:27, 217.37s/it]Epoch:  52%|█████▎    | 525/1000 [31:55:13<28:39:19, 217.18s/it]Epoch:  53%|█████▎    | 526/1000 [31:58:50<28:35:41, 217.18s/it]Epoch:  53%|█████▎    | 527/1000 [32:02:27<28:32:15, 217.20s/it]Epoch:  53%|█████▎    | 528/1000 [32:06:05<28:29:23, 217.30s/it]Epoch:  53%|█████▎    | 529/1000 [32:09:43<28:26:19, 217.37s/it]Epoch:  53%|█████▎    | 530/1000 [32:13:20<28:22:18, 217.32s/it]Epoch:  53%|█████▎    | 531/1000 [32:16:57<28:19:01, 217.36s/it]Epoch:  53%|█████▎    | 532/1000 [32:20:34<28:15:04, 217.32s/it]Epoch:  53%|█████▎    | 533/1000 [32:24:12<28:11:42, 217.35s/it]Epoch:  53%|█████▎    | 534/1000 [32:27:49<28:07:51, 217.32s/it]Epoch:  54%|█████▎    | 535/1000 [32:31:26<28:04:08, 217.31s/it]Epoch:  54%|█████▎    | 536/1000 [32:35:03<27:58:49, 217.09s/it]Epoch:  54%|█████▎    | 537/1000 [32:38:40<27:55:04, 217.07s/it]Epoch:  54%|█████▍    | 538/1000 [32:42:18<27:54:11, 217.43s/it]Epoch:  54%|█████▍    | 539/1000 [32:45:55<27:47:59, 217.09s/it]Epoch:  54%|█████▍    | 540/1000 [32:49:31<27:42:15, 216.82s/it]Epoch:  54%|█████▍    | 541/1000 [32:53:07<27:38:34, 216.81s/it]Epoch:  54%|█████▍    | 542/1000 [32:56:44<27:33:29, 216.61s/it]Epoch:  54%|█████▍    | 543/1000 [33:00:21<27:31:49, 216.87s/it]Epoch:  54%|█████▍    | 544/1000 [33:03:59<27:29:25, 217.03s/it]Epoch:  55%|█████▍    | 545/1000 [33:07:35<27:25:07, 216.94s/it]Epoch:  55%|█████▍    | 546/1000 [33:11:13<27:22:46, 217.11s/it]Epoch:  55%|█████▍    | 547/1000 [33:14:51<27:21:21, 217.40s/it]Epoch:  55%|█████▍    | 548/1000 [33:18:29<27:18:29, 217.50s/it]Epoch:  55%|█████▍    | 549/1000 [33:22:06<27:13:59, 217.38s/it]Epoch:  55%|█████▌    | 550/1000 [33:25:43<27:09:24, 217.25s/it]Epoch:  55%|█████▌    | 551/1000 [33:29:20<27:05:59, 217.28s/it]Epoch:  55%|█████▌    | 552/1000 [33:32:57<27:01:02, 217.10s/it]Epoch:  55%|█████▌    | 553/1000 [33:36:34<26:56:58, 217.04s/it]Epoch:  55%|█████▌    | 554/1000 [33:40:06<26:43:53, 215.77s/it]Epoch:  56%|█████▌    | 555/1000 [33:43:43<26:41:43, 215.96s/it]Epoch:  56%|█████▌    | 556/1000 [33:47:20<26:41:05, 216.36s/it]Epoch:  56%|█████▌    | 557/1000 [33:50:58<26:40:59, 216.84s/it]Epoch:  56%|█████▌    | 558/1000 [33:54:35<26:37:30, 216.86s/it]Epoch:  56%|█████▌    | 559/1000 [33:58:12<26:34:34, 216.95s/it]Epoch:  56%|█████▌    | 560/1000 [34:01:49<26:31:36, 217.04s/it]Epoch:  56%|█████▌    | 561/1000 [34:05:27<26:30:24, 217.37s/it]Epoch:  56%|█████▌    | 562/1000 [34:09:06<26:29:22, 217.72s/it]Epoch:  56%|█████▋    | 563/1000 [34:12:43<26:25:10, 217.64s/it]Epoch:  56%|█████▋    | 564/1000 [34:16:21<26:21:27, 217.63s/it]Epoch:  56%|█████▋    | 565/1000 [34:19:59<26:18:51, 217.77s/it]Epoch:  57%|█████▋    | 566/1000 [34:23:37<26:14:41, 217.70s/it]Epoch:  57%|█████▋    | 567/1000 [34:27:14<26:09:26, 217.48s/it]Epoch:  57%|█████▋    | 568/1000 [34:30:50<26:03:29, 217.15s/it]Epoch:  57%|█████▋    | 569/1000 [34:34:26<25:57:44, 216.85s/it]Epoch:  57%|█████▋    | 570/1000 [34:38:03<25:54:37, 216.92s/it]Epoch:  57%|█████▋    | 571/1000 [34:41:41<25:53:06, 217.22s/it]Epoch:  57%|█████▋    | 572/1000 [34:45:19<25:51:21, 217.48s/it]Epoch:  57%|█████▋    | 573/1000 [34:48:57<25:47:18, 217.42s/it]Epoch:  57%|█████▋    | 574/1000 [34:52:33<25:41:16, 217.08s/it]Epoch:  57%|█████▊    | 575/1000 [34:56:10<25:37:02, 216.99s/it]Epoch:  58%|█████▊    | 576/1000 [34:59:47<25:33:16, 216.97s/it]Epoch:  58%|█████▊    | 577/1000 [35:03:22<25:26:00, 216.45s/it]Epoch:  58%|█████▊    | 578/1000 [35:06:59<25:24:16, 216.72s/it]Epoch:  58%|█████▊    | 579/1000 [35:10:36<25:21:33, 216.85s/it]Epoch:  58%|█████▊    | 580/1000 [35:14:13<25:17:59, 216.86s/it]Epoch:  58%|█████▊    | 581/1000 [35:17:50<25:14:36, 216.89s/it]Epoch:  58%|█████▊    | 582/1000 [35:21:27<25:10:09, 216.77s/it]Epoch:  58%|█████▊    | 583/1000 [35:25:03<25:06:06, 216.71s/it]Epoch:  58%|█████▊    | 584/1000 [35:28:40<25:03:25, 216.84s/it]Epoch:  58%|█████▊    | 585/1000 [35:32:17<25:00:23, 216.92s/it]Epoch:  59%|█████▊    | 586/1000 [35:35:53<24:53:24, 216.44s/it]Epoch:  59%|█████▊    | 587/1000 [35:39:30<24:51:59, 216.75s/it]Epoch:  59%|█████▉    | 588/1000 [35:43:06<24:46:40, 216.51s/it]Epoch:  59%|█████▉    | 589/1000 [35:46:43<24:43:24, 216.56s/it]Epoch:  59%|█████▉    | 590/1000 [35:50:19<24:39:09, 216.46s/it]Epoch:  59%|█████▉    | 591/1000 [35:53:56<24:36:28, 216.60s/it]Epoch:  59%|█████▉    | 592/1000 [35:57:33<24:34:31, 216.84s/it]Epoch:  59%|█████▉    | 593/1000 [36:01:11<24:32:42, 217.11s/it]Epoch:  59%|█████▉    | 594/1000 [36:04:49<24:29:59, 217.24s/it]Epoch:  60%|█████▉    | 595/1000 [36:08:27<24:27:40, 217.43s/it]Epoch:  60%|█████▉    | 596/1000 [36:12:02<24:20:29, 216.91s/it]Epoch:  60%|█████▉    | 597/1000 [36:15:40<24:18:15, 217.11s/it]Epoch:  60%|█████▉    | 598/1000 [36:19:17<24:15:03, 217.17s/it]Epoch:  60%|█████▉    | 599/1000 [36:22:54<24:10:08, 216.98s/it]Epoch:  60%|██████    | 600/1000 [36:26:31<24:06:32, 216.98s/it]Epoch:  60%|██████    | 601/1000 [36:30:07<24:02:09, 216.87s/it]Epoch:  60%|██████    | 602/1000 [36:33:41<23:53:10, 216.06s/it]Epoch:  60%|██████    | 603/1000 [36:37:19<23:52:32, 216.50s/it]Epoch:  60%|██████    | 604/1000 [36:40:56<23:49:26, 216.58s/it]Epoch:  60%|██████    | 605/1000 [36:44:33<23:46:09, 216.63s/it]Epoch:  61%|██████    | 606/1000 [36:48:10<23:43:15, 216.74s/it]Epoch:  61%|██████    | 607/1000 [36:51:47<23:41:07, 216.97s/it]Epoch:  61%|██████    | 608/1000 [36:55:24<23:36:46, 216.85s/it]Epoch:  61%|██████    | 609/1000 [36:59:01<23:33:20, 216.88s/it]Epoch:  61%|██████    | 610/1000 [37:02:38<23:30:06, 216.94s/it]Epoch:  61%|██████    | 611/1000 [37:06:14<23:26:15, 216.90s/it]Epoch:  61%|██████    | 612/1000 [37:09:52<23:22:56, 216.95s/it]Epoch:  61%|██████▏   | 613/1000 [37:13:29<23:19:28, 216.97s/it]Epoch:  61%|██████▏   | 614/1000 [37:17:05<23:15:49, 216.97s/it]Epoch:  62%|██████▏   | 615/1000 [37:20:43<23:12:27, 217.01s/it]Epoch:  62%|██████▏   | 616/1000 [37:24:20<23:09:08, 217.05s/it]Epoch:  62%|██████▏   | 617/1000 [37:27:56<23:04:54, 216.96s/it]Epoch:  62%|██████▏   | 618/1000 [37:31:33<23:01:03, 216.92s/it]Epoch:  62%|██████▏   | 619/1000 [37:35:10<22:57:36, 216.95s/it]Epoch:  62%|██████▏   | 620/1000 [37:38:48<22:54:59, 217.10s/it]Epoch:  62%|██████▏   | 621/1000 [37:42:25<22:52:06, 217.22s/it]Epoch:  62%|██████▏   | 622/1000 [37:46:02<22:48:01, 217.15s/it]Epoch:  62%|██████▏   | 623/1000 [37:49:39<22:43:48, 217.05s/it]Epoch:  62%|██████▏   | 624/1000 [37:53:16<22:39:51, 217.00s/it]Epoch:  62%|██████▎   | 625/1000 [37:56:53<22:37:11, 217.15s/it]Epoch:  63%|██████▎   | 626/1000 [38:00:30<22:33:17, 217.11s/it]Epoch:  63%|██████▎   | 627/1000 [38:04:06<22:27:36, 216.77s/it]Epoch:  63%|██████▎   | 628/1000 [38:07:43<22:24:25, 216.84s/it]Epoch:  63%|██████▎   | 629/1000 [38:11:20<22:20:41, 216.82s/it]Epoch:  63%|██████▎   | 630/1000 [38:14:57<22:17:00, 216.81s/it]Epoch:  63%|██████▎   | 631/1000 [38:18:34<22:13:11, 216.78s/it]Epoch:  63%|██████▎   | 632/1000 [38:22:10<22:09:04, 216.70s/it]Epoch:  63%|██████▎   | 633/1000 [38:25:48<22:06:30, 216.87s/it]Epoch:  63%|██████▎   | 634/1000 [38:29:26<22:04:56, 217.20s/it]Epoch:  64%|██████▎   | 635/1000 [38:33:04<22:03:17, 217.53s/it]Epoch:  64%|██████▎   | 636/1000 [38:36:41<21:58:38, 217.36s/it]Epoch:  64%|██████▎   | 637/1000 [38:40:18<21:54:19, 217.24s/it]Epoch:  64%|██████▍   | 638/1000 [38:43:55<21:50:21, 217.19s/it]Epoch:  64%|██████▍   | 639/1000 [38:47:31<21:45:30, 216.98s/it]Epoch:  64%|██████▍   | 640/1000 [38:51:08<21:41:38, 216.94s/it]Epoch:  64%|██████▍   | 641/1000 [38:54:45<21:38:07, 216.96s/it]Epoch:  64%|██████▍   | 642/1000 [38:58:22<21:33:55, 216.86s/it]Epoch:  64%|██████▍   | 643/1000 [39:01:58<21:29:40, 216.75s/it]Epoch:  64%|██████▍   | 644/1000 [39:05:35<21:25:58, 216.74s/it]Epoch:  64%|██████▍   | 645/1000 [39:09:12<21:22:32, 216.77s/it]Epoch:  65%|██████▍   | 646/1000 [39:12:49<21:18:53, 216.76s/it]Epoch:  65%|██████▍   | 647/1000 [39:16:26<21:16:31, 216.97s/it]Epoch:  65%|██████▍   | 648/1000 [39:20:03<21:13:15, 217.03s/it]Epoch:  65%|██████▍   | 649/1000 [39:23:40<21:09:54, 217.08s/it]Epoch:  65%|██████▌   | 650/1000 [39:27:17<21:05:45, 216.99s/it]Epoch:  65%|██████▌   | 651/1000 [39:30:55<21:03:57, 217.30s/it]Epoch:  65%|██████▌   | 652/1000 [39:34:32<20:59:16, 217.12s/it]Epoch:  65%|██████▌   | 653/1000 [39:38:07<20:52:46, 216.62s/it]Epoch:  65%|██████▌   | 654/1000 [39:41:44<20:49:47, 216.73s/it]Epoch:  66%|██████▌   | 655/1000 [39:45:22<20:47:40, 216.99s/it]Epoch:  66%|██████▌   | 656/1000 [39:48:59<20:43:36, 216.91s/it]Epoch:  66%|██████▌   | 657/1000 [39:52:36<20:39:57, 216.90s/it]Epoch:  66%|██████▌   | 658/1000 [39:56:13<20:37:19, 217.08s/it]Epoch:  66%|██████▌   | 659/1000 [39:59:51<20:34:40, 217.24s/it]Epoch:  66%|██████▌   | 660/1000 [40:03:29<20:33:10, 217.62s/it]Epoch:  66%|██████▌   | 661/1000 [40:07:06<20:29:04, 217.54s/it]Epoch:  66%|██████▌   | 662/1000 [40:10:44<20:25:06, 217.47s/it]Epoch:  66%|██████▋   | 663/1000 [40:14:21<20:20:37, 217.32s/it]Epoch:  66%|██████▋   | 664/1000 [40:17:58<20:16:25, 217.22s/it]Epoch:  66%|██████▋   | 665/1000 [40:21:35<20:12:28, 217.16s/it]Epoch:  67%|██████▋   | 666/1000 [40:25:12<20:09:33, 217.29s/it]Epoch:  67%|██████▋   | 667/1000 [40:28:50<20:07:01, 217.48s/it]Epoch:  67%|██████▋   | 668/1000 [40:32:28<20:04:35, 217.70s/it]Epoch:  67%|██████▋   | 669/1000 [40:36:06<20:01:02, 217.71s/it]Epoch:  67%|██████▋   | 670/1000 [40:39:46<20:00:21, 218.25s/it]Epoch:  67%|██████▋   | 671/1000 [40:43:23<19:55:21, 218.00s/it]Epoch:  67%|██████▋   | 672/1000 [40:47:00<19:50:37, 217.80s/it]Epoch:  67%|██████▋   | 673/1000 [40:50:39<19:48:49, 218.13s/it]Epoch:  67%|██████▋   | 674/1000 [40:54:18<19:46:05, 218.30s/it]Epoch:  68%|██████▊   | 675/1000 [40:57:55<19:40:02, 217.85s/it]Epoch:  68%|██████▊   | 676/1000 [41:01:32<19:35:01, 217.60s/it]Epoch:  68%|██████▊   | 677/1000 [41:05:10<19:32:24, 217.78s/it]Epoch:  68%|██████▊   | 678/1000 [41:08:49<19:30:37, 218.13s/it]Epoch:  68%|██████▊   | 679/1000 [41:12:28<19:28:06, 218.34s/it]Epoch:  68%|██████▊   | 680/1000 [41:16:06<19:23:35, 218.17s/it]Epoch:  68%|██████▊   | 681/1000 [41:19:43<19:19:10, 218.03s/it]Epoch:  68%|██████▊   | 682/1000 [41:23:22<19:16:02, 218.12s/it]Epoch:  68%|██████▊   | 683/1000 [41:26:59<19:11:38, 217.98s/it]Epoch:  68%|██████▊   | 684/1000 [41:30:37<19:07:00, 217.79s/it]Epoch:  68%|██████▊   | 685/1000 [41:34:14<19:02:46, 217.67s/it]Epoch:  69%|██████▊   | 686/1000 [41:37:51<18:58:32, 217.56s/it]Epoch:  69%|██████▊   | 687/1000 [41:41:29<18:55:14, 217.62s/it]Epoch:  69%|██████▉   | 688/1000 [41:45:05<18:49:16, 217.17s/it]Epoch:  69%|██████▉   | 689/1000 [41:48:45<18:49:11, 217.85s/it]Epoch:  69%|██████▉   | 690/1000 [41:52:25<18:49:45, 218.66s/it]Epoch:  69%|██████▉   | 691/1000 [41:56:02<18:43:04, 218.07s/it]Epoch:  69%|██████▉   | 692/1000 [41:59:45<18:47:22, 219.62s/it]Epoch:  69%|██████▉   | 693/1000 [42:03:23<18:40:23, 218.97s/it]Epoch:  69%|██████▉   | 694/1000 [42:06:59<18:32:13, 218.08s/it]Epoch:  70%|██████▉   | 695/1000 [42:10:40<18:33:53, 219.13s/it]Epoch:  70%|██████▉   | 696/1000 [42:14:18<18:27:49, 218.65s/it]Epoch:  70%|██████▉   | 697/1000 [42:17:56<18:23:02, 218.42s/it]Epoch:  70%|██████▉   | 698/1000 [42:21:35<18:20:28, 218.64s/it]Epoch:  70%|██████▉   | 699/1000 [42:25:12<18:14:15, 218.13s/it]Epoch:  70%|███████   | 700/1000 [42:28:49<18:09:55, 217.99s/it]Epoch:  70%|███████   | 701/1000 [42:32:27<18:05:09, 217.76s/it]Epoch:  70%|███████   | 702/1000 [42:36:03<17:59:32, 217.36s/it]Epoch:  70%|███████   | 703/1000 [42:39:41<17:56:41, 217.51s/it]Epoch:  70%|███████   | 704/1000 [42:43:17<17:51:21, 217.17s/it]Epoch:  70%|███████   | 705/1000 [42:46:54<17:47:15, 217.07s/it]Epoch:  71%|███████   | 706/1000 [42:50:32<17:44:20, 217.21s/it]Epoch:  71%|███████   | 707/1000 [42:54:09<17:41:14, 217.32s/it]Epoch:  71%|███████   | 708/1000 [42:57:47<17:37:44, 217.34s/it]Epoch:  71%|███████   | 709/1000 [43:01:24<17:34:29, 217.42s/it]Epoch:  71%|███████   | 710/1000 [43:05:01<17:29:48, 217.20s/it]Epoch:  71%|███████   | 711/1000 [43:08:38<17:25:36, 217.08s/it]Epoch:  71%|███████   | 712/1000 [43:12:15<17:21:39, 217.01s/it]Epoch:  71%|███████▏  | 713/1000 [43:15:51<17:17:16, 216.85s/it]Epoch:  71%|███████▏  | 714/1000 [43:19:28<17:14:36, 217.05s/it]Epoch:  72%|███████▏  | 715/1000 [43:23:06<17:11:16, 217.11s/it]Epoch:  72%|███████▏  | 716/1000 [43:26:43<17:07:22, 217.05s/it]Epoch:  72%|███████▏  | 717/1000 [43:30:19<17:03:20, 216.96s/it]Epoch:  72%|███████▏  | 718/1000 [43:33:56<16:59:17, 216.87s/it]Epoch:  72%|███████▏  | 719/1000 [43:37:33<16:55:13, 216.77s/it]Epoch:  72%|███████▏  | 720/1000 [43:41:09<16:51:00, 216.65s/it]Epoch:  72%|███████▏  | 721/1000 [43:44:48<16:50:58, 217.41s/it]Epoch:  72%|███████▏  | 722/1000 [43:48:30<16:53:15, 218.69s/it]Epoch:  72%|███████▏  | 723/1000 [43:52:09<16:49:56, 218.76s/it]Epoch:  72%|███████▏  | 724/1000 [43:55:47<16:45:14, 218.53s/it]Epoch:  72%|███████▎  | 725/1000 [43:59:24<16:40:09, 218.22s/it]Epoch:  73%|███████▎  | 726/1000 [44:03:02<16:36:21, 218.18s/it]Epoch:  73%|███████▎  | 727/1000 [44:06:42<16:34:47, 218.64s/it]Epoch:  73%|███████▎  | 728/1000 [44:10:27<16:39:23, 220.45s/it]Epoch:  73%|███████▎  | 729/1000 [44:14:09<16:37:54, 220.94s/it]Epoch:  73%|███████▎  | 730/1000 [44:17:47<16:30:39, 220.15s/it]Epoch:  73%|███████▎  | 731/1000 [44:21:24<16:22:36, 219.17s/it]Epoch:  73%|███████▎  | 732/1000 [44:25:02<16:17:30, 218.84s/it]Epoch:  73%|███████▎  | 733/1000 [44:28:43<16:16:58, 219.54s/it]Epoch:  73%|███████▎  | 734/1000 [44:32:23<16:13:10, 219.51s/it]Epoch:  74%|███████▎  | 735/1000 [44:36:00<16:07:01, 218.95s/it]Epoch:  74%|███████▎  | 736/1000 [44:39:37<15:59:53, 218.16s/it]Epoch:  74%|███████▎  | 737/1000 [44:43:14<15:55:40, 218.02s/it]Epoch:  74%|███████▍  | 738/1000 [44:46:51<15:50:40, 217.71s/it]Epoch:  74%|███████▍  | 739/1000 [44:50:29<15:47:21, 217.79s/it]Epoch:  74%|███████▍  | 740/1000 [44:54:07<15:43:30, 217.73s/it]Epoch:  74%|███████▍  | 741/1000 [44:57:46<15:41:42, 218.16s/it]Epoch:  74%|███████▍  | 742/1000 [45:01:25<15:38:45, 218.32s/it]Epoch:  74%|███████▍  | 743/1000 [45:05:02<15:33:56, 218.04s/it]Epoch:  74%|███████▍  | 744/1000 [45:08:39<15:29:16, 217.80s/it]Epoch:  74%|███████▍  | 745/1000 [45:12:16<15:24:22, 217.50s/it]Epoch:  75%|███████▍  | 746/1000 [45:15:53<15:20:16, 217.39s/it]Epoch:  75%|███████▍  | 747/1000 [45:19:31<15:17:16, 217.53s/it]Epoch:  75%|███████▍  | 748/1000 [45:23:08<15:12:23, 217.24s/it]Epoch:  75%|███████▍  | 749/1000 [45:26:44<15:07:59, 217.05s/it]Epoch:  75%|███████▌  | 750/1000 [45:30:21<15:04:17, 217.03s/it]Epoch:  75%|███████▌  | 751/1000 [45:33:59<15:02:02, 217.36s/it]Epoch:  75%|███████▌  | 752/1000 [45:37:37<14:58:56, 217.49s/it]Epoch:  75%|███████▌  | 753/1000 [45:41:14<14:54:35, 217.31s/it]Epoch:  75%|███████▌  | 754/1000 [45:44:49<14:48:26, 216.69s/it]Epoch:  76%|███████▌  | 755/1000 [45:48:25<14:44:02, 216.50s/it]Epoch:  76%|███████▌  | 756/1000 [45:52:03<14:41:52, 216.85s/it]Epoch:  76%|███████▌  | 757/1000 [45:55:40<14:38:38, 216.95s/it]Epoch:  76%|███████▌  | 758/1000 [45:59:18<14:36:26, 217.30s/it]Epoch:  76%|███████▌  | 759/1000 [46:02:59<14:36:56, 218.33s/it]Epoch:  76%|███████▌  | 760/1000 [46:06:38<14:33:37, 218.41s/it]Epoch:  76%|███████▌  | 761/1000 [46:10:16<14:29:36, 218.31s/it]Epoch:  76%|███████▌  | 762/1000 [46:13:56<14:27:42, 218.75s/it]Epoch:  76%|███████▋  | 763/1000 [46:17:34<14:23:53, 218.71s/it]Epoch:  76%|███████▋  | 764/1000 [46:21:13<14:20:49, 218.85s/it]Epoch:  76%|███████▋  | 765/1000 [46:24:52<14:16:35, 218.70s/it]Epoch:  77%|███████▋  | 766/1000 [46:28:32<14:14:35, 219.13s/it]Epoch:  77%|███████▋  | 767/1000 [46:32:12<14:12:20, 219.49s/it]Epoch:  77%|███████▋  | 768/1000 [46:35:52<14:09:04, 219.59s/it]Epoch:  77%|███████▋  | 769/1000 [46:39:31<14:05:09, 219.52s/it]Epoch:  77%|███████▋  | 770/1000 [46:43:11<14:01:15, 219.46s/it]Epoch:  77%|███████▋  | 771/1000 [46:46:51<13:58:22, 219.66s/it]Epoch:  77%|███████▋  | 772/1000 [46:50:30<13:54:32, 219.62s/it]Epoch:  77%|███████▋  | 773/1000 [46:54:10<13:51:05, 219.67s/it]Epoch:  77%|███████▋  | 774/1000 [46:57:51<13:48:59, 220.09s/it]Epoch:  78%|███████▊  | 775/1000 [47:01:31<13:45:15, 220.07s/it]Epoch:  78%|███████▊  | 776/1000 [47:05:10<13:39:53, 219.61s/it]Epoch:  78%|███████▊  | 777/1000 [47:08:49<13:36:12, 219.61s/it]Epoch:  78%|███████▊  | 778/1000 [47:12:29<13:32:12, 219.52s/it]Epoch:  78%|███████▊  | 779/1000 [47:16:08<13:28:38, 219.54s/it]Epoch:  78%|███████▊  | 780/1000 [47:19:48<13:25:20, 219.64s/it]Epoch:  78%|███████▊  | 781/1000 [47:23:27<13:20:32, 219.33s/it]Epoch:  78%|███████▊  | 782/1000 [47:27:06<13:16:31, 219.23s/it]Epoch:  78%|███████▊  | 783/1000 [47:30:46<13:14:00, 219.54s/it]Epoch:  78%|███████▊  | 784/1000 [47:34:26<13:11:18, 219.81s/it]Epoch:  78%|███████▊  | 785/1000 [47:38:07<13:08:29, 220.04s/it]Epoch:  79%|███████▊  | 786/1000 [47:41:44<13:01:46, 219.19s/it]Epoch:  79%|███████▊  | 787/1000 [47:45:23<12:58:03, 219.17s/it]Epoch:  79%|███████▉  | 788/1000 [47:49:01<12:52:47, 218.71s/it]Epoch:  79%|███████▉  | 789/1000 [47:52:39<12:47:58, 218.38s/it]Epoch:  79%|███████▉  | 790/1000 [47:56:19<12:46:19, 218.95s/it]Epoch:  79%|███████▉  | 791/1000 [47:59:58<12:42:52, 219.01s/it]Epoch:  79%|███████▉  | 792/1000 [48:03:37<12:38:52, 218.91s/it]Epoch:  79%|███████▉  | 793/1000 [48:07:14<12:33:43, 218.47s/it]Epoch:  79%|███████▉  | 794/1000 [48:10:54<12:31:51, 218.99s/it]Epoch:  80%|███████▉  | 795/1000 [48:14:33<12:28:00, 218.93s/it]Epoch:  80%|███████▉  | 796/1000 [48:18:12<12:24:30, 218.97s/it]Epoch:  80%|███████▉  | 797/1000 [48:21:51<12:21:11, 219.07s/it]Epoch:  80%|███████▉  | 798/1000 [48:25:31<12:17:54, 219.18s/it]Epoch:  80%|███████▉  | 799/1000 [48:29:11<12:14:45, 219.33s/it]Epoch:  80%|████████  | 800/1000 [48:32:50<12:11:17, 219.39s/it]Epoch:  80%|████████  | 801/1000 [48:36:30<12:07:58, 219.49s/it]Epoch:  80%|████████  | 802/1000 [48:40:09<12:04:01, 219.40s/it]Epoch:  80%|████████  | 803/1000 [48:43:50<12:01:24, 219.72s/it]Epoch:  80%|████████  | 804/1000 [48:47:30<11:58:39, 220.00s/it]Epoch:  80%|████████  | 805/1000 [48:51:10<11:54:32, 219.86s/it]Epoch:  81%|████████  | 806/1000 [48:54:49<11:50:10, 219.64s/it]Epoch:  81%|████████  | 807/1000 [48:58:28<11:45:45, 219.41s/it]Epoch:  81%|████████  | 808/1000 [49:02:07<11:42:19, 219.48s/it]Epoch:  81%|████████  | 809/1000 [49:05:45<11:37:10, 219.01s/it]Epoch:  81%|████████  | 810/1000 [49:09:25<11:34:03, 219.17s/it]Epoch:  81%|████████  | 811/1000 [49:13:04<11:30:32, 219.22s/it]Epoch:  81%|████████  | 812/1000 [49:16:42<11:25:14, 218.69s/it]Epoch:  81%|████████▏ | 813/1000 [49:20:20<11:21:42, 218.73s/it]Epoch:  81%|████████▏ | 814/1000 [49:23:59<11:18:06, 218.75s/it]Epoch:  82%|████████▏ | 815/1000 [49:27:38<11:14:48, 218.86s/it]Epoch:  82%|████████▏ | 816/1000 [49:31:18<11:12:17, 219.23s/it]Epoch:  82%|████████▏ | 817/1000 [49:34:57<11:08:21, 219.14s/it]Epoch:  82%|████████▏ | 818/1000 [49:38:37<11:04:59, 219.23s/it]Epoch:  82%|████████▏ | 819/1000 [49:42:18<11:02:45, 219.70s/it]Epoch:  82%|████████▏ | 820/1000 [49:45:57<10:58:57, 219.65s/it]Epoch:  82%|████████▏ | 821/1000 [49:49:37<10:55:31, 219.73s/it]Epoch:  82%|████████▏ | 822/1000 [49:53:16<10:51:18, 219.54s/it]Epoch:  82%|████████▏ | 823/1000 [49:56:56<10:48:22, 219.79s/it]Epoch:  82%|████████▏ | 824/1000 [50:00:36<10:44:13, 219.62s/it]Epoch:  82%|████████▎ | 825/1000 [50:04:15<10:40:32, 219.61s/it]Epoch:  83%|████████▎ | 826/1000 [50:07:55<10:36:54, 219.62s/it]Epoch:  83%|████████▎ | 827/1000 [50:11:36<10:34:11, 219.95s/it]Epoch:  83%|████████▎ | 828/1000 [50:15:15<10:30:02, 219.78s/it]Epoch:  83%|████████▎ | 829/1000 [50:18:54<10:25:55, 219.62s/it]Epoch:  83%|████████▎ | 830/1000 [50:22:33<10:21:31, 219.36s/it]Epoch:  83%|████████▎ | 831/1000 [50:26:12<10:17:46, 219.33s/it]Epoch:  83%|████████▎ | 832/1000 [50:29:53<10:14:54, 219.61s/it]Epoch:  83%|████████▎ | 833/1000 [50:33:32<10:10:56, 219.50s/it]Epoch:  83%|████████▎ | 834/1000 [50:37:10<10:06:09, 219.10s/it]Epoch:  84%|████████▎ | 835/1000 [50:40:48<10:01:53, 218.87s/it]Epoch:  84%|████████▎ | 836/1000 [50:44:28<9:59:01, 219.15s/it] Epoch:  84%|████████▎ | 837/1000 [50:48:07<9:55:21, 219.15s/it]Epoch:  84%|████████▍ | 838/1000 [50:51:46<9:51:37, 219.12s/it]Epoch:  84%|████████▍ | 839/1000 [50:55:25<9:47:58, 219.12s/it]Epoch:  84%|████████▍ | 840/1000 [50:59:05<9:44:20, 219.13s/it]Epoch:  84%|████████▍ | 841/1000 [51:02:43<9:39:56, 218.84s/it]Epoch:  84%|████████▍ | 842/1000 [51:06:22<9:36:24, 218.89s/it]Epoch:  84%|████████▍ | 843/1000 [51:10:01<9:32:56, 218.96s/it]Epoch:  84%|████████▍ | 844/1000 [51:13:39<9:28:58, 218.84s/it]Epoch:  84%|████████▍ | 845/1000 [51:17:18<9:25:10, 218.78s/it]Epoch:  85%|████████▍ | 846/1000 [51:20:55<9:20:26, 218.36s/it]Epoch:  85%|████████▍ | 847/1000 [51:24:35<9:17:26, 218.61s/it]Epoch:  85%|████████▍ | 848/1000 [51:28:14<9:14:05, 218.72s/it]Epoch:  85%|████████▍ | 849/1000 [51:31:54<9:11:47, 219.25s/it]Epoch:  85%|████████▌ | 850/1000 [51:35:34<9:08:20, 219.33s/it]Epoch:  85%|████████▌ | 851/1000 [51:39:13<9:04:54, 219.43s/it]Epoch:  85%|████████▌ | 852/1000 [51:42:52<9:01:03, 219.35s/it]Epoch:  85%|████████▌ | 853/1000 [51:46:32<8:57:43, 219.48s/it]Epoch:  85%|████████▌ | 854/1000 [51:50:12<8:54:04, 219.48s/it]Epoch:  86%|████████▌ | 855/1000 [51:53:51<8:50:13, 219.40s/it]Epoch:  86%|████████▌ | 856/1000 [51:57:29<8:45:33, 218.99s/it]Epoch:  86%|████████▌ | 857/1000 [52:01:09<8:42:20, 219.16s/it]Epoch:  86%|████████▌ | 858/1000 [52:04:48<8:38:40, 219.16s/it]Epoch:  86%|████████▌ | 859/1000 [52:08:27<8:34:59, 219.14s/it]Epoch:  86%|████████▌ | 860/1000 [52:12:06<8:31:23, 219.17s/it]Epoch:  86%|████████▌ | 861/1000 [52:15:45<8:27:49, 219.20s/it]Epoch:  86%|████████▌ | 862/1000 [52:19:26<8:24:57, 219.55s/it]Epoch:  86%|████████▋ | 863/1000 [52:23:05<8:21:26, 219.61s/it]Epoch:  86%|████████▋ | 864/1000 [52:26:46<8:18:13, 219.80s/it]Epoch:  86%|████████▋ | 865/1000 [52:30:27<8:15:17, 220.13s/it]Epoch:  87%|████████▋ | 866/1000 [52:34:06<8:11:02, 219.87s/it]Epoch:  87%|████████▋ | 867/1000 [52:37:46<8:07:15, 219.81s/it]Epoch:  87%|████████▋ | 868/1000 [52:41:25<8:03:12, 219.64s/it]Epoch:  87%|████████▋ | 869/1000 [52:45:04<7:59:13, 219.49s/it]Epoch:  87%|████████▋ | 870/1000 [52:48:44<7:55:57, 219.67s/it]Epoch:  87%|████████▋ | 871/1000 [52:52:23<7:52:03, 219.56s/it]Epoch:  87%|████████▋ | 872/1000 [52:56:04<7:49:23, 220.03s/it]Epoch:  87%|████████▋ | 873/1000 [52:59:45<7:46:22, 220.34s/it]Epoch:  87%|████████▋ | 874/1000 [53:03:25<7:42:04, 220.03s/it]Epoch:  88%|████████▊ | 875/1000 [53:07:04<7:37:39, 219.67s/it]Epoch:  88%|████████▊ | 876/1000 [53:10:44<7:34:40, 220.00s/it]Epoch:  88%|████████▊ | 877/1000 [53:14:25<7:31:06, 220.06s/it]Epoch:  88%|████████▊ | 878/1000 [53:18:03<7:26:24, 219.54s/it]Epoch:  88%|████████▊ | 879/1000 [53:21:41<7:22:03, 219.20s/it]Epoch:  88%|████████▊ | 880/1000 [53:25:21<7:18:25, 219.21s/it]Epoch:  88%|████████▊ | 881/1000 [53:29:00<7:14:38, 219.15s/it]Epoch:  88%|████████▊ | 882/1000 [53:32:39<7:11:14, 219.27s/it]Epoch:  88%|████████▊ | 883/1000 [53:36:19<7:07:39, 219.31s/it]Epoch:  88%|████████▊ | 884/1000 [53:39:58<7:04:17, 219.46s/it]Epoch:  88%|████████▊ | 885/1000 [53:43:37<7:00:26, 219.36s/it]Epoch:  89%|████████▊ | 886/1000 [53:47:17<6:57:03, 219.51s/it]Epoch:  89%|████████▊ | 887/1000 [53:50:57<6:53:40, 219.65s/it]Epoch:  89%|████████▉ | 888/1000 [53:54:38<6:50:20, 219.83s/it]Epoch:  89%|████████▉ | 889/1000 [53:58:17<6:46:40, 219.83s/it]Epoch:  89%|████████▉ | 890/1000 [54:01:56<6:42:21, 219.46s/it]Epoch:  89%|████████▉ | 891/1000 [54:05:35<6:38:15, 219.22s/it]Epoch:  89%|████████▉ | 892/1000 [54:09:14<6:34:30, 219.17s/it]Epoch:  89%|████████▉ | 893/1000 [54:12:53<6:30:40, 219.07s/it]Epoch:  89%|████████▉ | 894/1000 [54:16:32<6:26:59, 219.05s/it]Epoch:  90%|████████▉ | 895/1000 [54:20:11<6:23:40, 219.24s/it]Epoch:  90%|████████▉ | 896/1000 [54:23:50<6:19:51, 219.15s/it]Epoch:  90%|████████▉ | 897/1000 [54:27:30<6:16:40, 219.42s/it]Epoch:  90%|████████▉ | 898/1000 [54:31:09<6:12:42, 219.24s/it]Epoch:  90%|████████▉ | 899/1000 [54:34:49<6:09:21, 219.42s/it]Epoch:  90%|█████████ | 900/1000 [54:38:28<6:05:45, 219.46s/it]Epoch:  90%|█████████ | 901/1000 [54:42:08<6:02:22, 219.62s/it]Epoch:  90%|█████████ | 902/1000 [54:45:48<5:58:44, 219.63s/it]Epoch:  90%|█████████ | 903/1000 [54:49:27<5:54:48, 219.47s/it]Epoch:  90%|█████████ | 904/1000 [54:53:06<5:50:51, 219.29s/it]Epoch:  90%|█████████ | 905/1000 [54:56:44<5:46:48, 219.04s/it]Epoch:  91%|█████████ | 906/1000 [55:00:23<5:43:05, 219.00s/it]Epoch:  91%|█████████ | 907/1000 [55:04:03<5:39:34, 219.08s/it]Epoch:  91%|█████████ | 908/1000 [55:07:42<5:36:07, 219.22s/it]Epoch:  91%|█████████ | 909/1000 [55:11:21<5:32:27, 219.20s/it]Epoch:  91%|█████████ | 910/1000 [55:15:00<5:28:43, 219.15s/it]Epoch:  91%|█████████ | 911/1000 [55:18:41<5:25:54, 219.71s/it]Epoch:  91%|█████████ | 912/1000 [55:22:21<5:22:24, 219.82s/it]Epoch:  91%|█████████▏| 913/1000 [55:26:01<5:18:49, 219.87s/it]Epoch:  91%|█████████▏| 914/1000 [55:29:41<5:14:57, 219.73s/it]Epoch:  92%|█████████▏| 915/1000 [55:33:21<5:11:18, 219.75s/it]Epoch:  92%|█████████▏| 916/1000 [55:37:01<5:07:42, 219.80s/it]Epoch:  92%|█████████▏| 917/1000 [55:40:40<5:03:49, 219.63s/it]Epoch:  92%|█████████▏| 918/1000 [55:44:19<5:00:03, 219.55s/it]Epoch:  92%|█████████▏| 919/1000 [55:47:59<4:56:38, 219.73s/it]Epoch:  92%|█████████▏| 920/1000 [55:51:38<4:52:37, 219.47s/it]Epoch:  92%|█████████▏| 921/1000 [55:55:18<4:49:11, 219.63s/it]Epoch:  92%|█████████▏| 922/1000 [55:58:58<4:45:29, 219.61s/it]Epoch:  92%|█████████▏| 923/1000 [56:02:36<4:41:29, 219.34s/it]Epoch:  92%|█████████▏| 924/1000 [56:06:15<4:37:39, 219.20s/it]Epoch:  92%|█████████▎| 925/1000 [56:09:55<4:34:03, 219.24s/it]Epoch:  93%|█████████▎| 926/1000 [56:13:35<4:30:46, 219.55s/it]Epoch:  93%|█████████▎| 927/1000 [56:17:14<4:27:02, 219.48s/it]Epoch:  93%|█████████▎| 928/1000 [56:20:55<4:23:46, 219.81s/it]Epoch:  93%|█████████▎| 929/1000 [56:24:34<4:19:57, 219.68s/it]Epoch:  93%|█████████▎| 930/1000 [56:28:12<4:15:42, 219.18s/it]Epoch:  93%|█████████▎| 931/1000 [56:31:52<4:12:11, 219.30s/it]Epoch:  93%|█████████▎| 932/1000 [56:35:31<4:08:22, 219.15s/it]Epoch:  93%|█████████▎| 933/1000 [56:39:10<4:04:43, 219.16s/it]Epoch:  93%|█████████▎| 934/1000 [56:42:49<4:01:04, 219.16s/it]Epoch:  94%|█████████▎| 935/1000 [56:46:29<3:57:34, 219.29s/it]Epoch:  94%|█████████▎| 936/1000 [56:50:07<3:53:36, 219.00s/it]Epoch:  94%|█████████▎| 937/1000 [56:53:46<3:49:59, 219.04s/it]Epoch:  94%|█████████▍| 938/1000 [56:57:24<3:46:04, 218.78s/it]Epoch:  94%|█████████▍| 939/1000 [57:01:03<3:42:34, 218.92s/it]Epoch:  94%|█████████▍| 940/1000 [57:04:43<3:39:06, 219.11s/it]Epoch:  94%|█████████▍| 941/1000 [57:08:24<3:35:52, 219.54s/it]Epoch:  94%|█████████▍| 942/1000 [57:12:01<3:31:43, 219.03s/it]Epoch:  94%|█████████▍| 943/1000 [57:15:41<3:28:17, 219.25s/it]Epoch:  94%|█████████▍| 944/1000 [57:19:21<3:24:55, 219.57s/it]Epoch:  94%|█████████▍| 945/1000 [57:23:02<3:21:36, 219.94s/it]Epoch:  95%|█████████▍| 946/1000 [57:26:41<3:17:44, 219.71s/it]Epoch:  95%|█████████▍| 947/1000 [57:30:21<3:14:05, 219.73s/it]Epoch:  95%|█████████▍| 948/1000 [57:34:01<3:10:20, 219.62s/it]Epoch:  95%|█████████▍| 949/1000 [57:37:40<3:06:36, 219.54s/it]Epoch:  95%|█████████▌| 950/1000 [57:41:19<3:02:52, 219.45s/it]Epoch:  95%|█████████▌| 951/1000 [57:44:59<2:59:11, 219.41s/it]Epoch:  95%|█████████▌| 952/1000 [57:48:37<2:55:23, 219.24s/it]Epoch:  95%|█████████▌| 953/1000 [57:52:17<2:51:49, 219.35s/it]Epoch:  95%|█████████▌| 954/1000 [57:55:58<2:48:30, 219.80s/it]Epoch:  96%|█████████▌| 955/1000 [57:59:37<2:44:49, 219.77s/it]Epoch:  96%|█████████▌| 956/1000 [58:03:17<2:41:12, 219.84s/it]Epoch:  96%|█████████▌| 957/1000 [58:06:57<2:37:32, 219.83s/it]Epoch:  96%|█████████▌| 958/1000 [58:10:35<2:33:27, 219.22s/it]Epoch:  96%|█████████▌| 959/1000 [58:14:13<2:29:36, 218.94s/it]Epoch:  96%|█████████▌| 960/1000 [58:17:52<2:25:53, 218.85s/it]Epoch:  96%|█████████▌| 961/1000 [58:21:30<2:22:09, 218.69s/it]Epoch:  96%|█████████▌| 962/1000 [58:25:08<2:18:15, 218.31s/it]Epoch:  96%|█████████▋| 963/1000 [58:28:47<2:14:50, 218.66s/it]Epoch:  96%|█████████▋| 964/1000 [58:32:26<2:11:09, 218.59s/it]Epoch:  96%|█████████▋| 965/1000 [58:36:06<2:07:49, 219.13s/it]Epoch:  97%|█████████▋| 966/1000 [58:39:44<2:04:03, 218.92s/it]Epoch:  97%|█████████▋| 967/1000 [58:43:24<2:00:26, 219.00s/it]Epoch:  97%|█████████▋| 968/1000 [58:47:03<1:56:55, 219.24s/it]Epoch:  97%|█████████▋| 969/1000 [58:50:42<1:53:08, 218.99s/it]Epoch:  97%|█████████▋| 970/1000 [58:54:21<1:49:27, 218.92s/it]Epoch:  97%|█████████▋| 971/1000 [58:57:59<1:45:45, 218.81s/it]Epoch:  97%|█████████▋| 972/1000 [59:01:37<1:42:00, 218.58s/it]Epoch:  97%|█████████▋| 973/1000 [59:05:17<1:38:33, 219.01s/it]Epoch:  97%|█████████▋| 974/1000 [59:08:58<1:35:06, 219.50s/it]Epoch:  98%|█████████▊| 975/1000 [59:12:38<1:31:29, 219.59s/it]Epoch:  98%|█████████▊| 976/1000 [59:16:17<1:27:45, 219.41s/it]Epoch:  98%|█████████▊| 977/1000 [59:19:55<1:23:57, 219.04s/it]Epoch:  98%|█████████▊| 978/1000 [59:23:35<1:20:24, 219.29s/it]Epoch:  98%|█████████▊| 979/1000 [59:27:15<1:16:51, 219.60s/it]Epoch:  98%|█████████▊| 980/1000 [59:30:55<1:13:11, 219.58s/it]Epoch:  98%|█████████▊| 981/1000 [59:34:36<1:09:41, 220.08s/it]Epoch:  98%|█████████▊| 982/1000 [59:38:16<1:06:01, 220.09s/it]Epoch:  98%|█████████▊| 983/1000 [59:41:55<1:02:18, 219.89s/it]Epoch:  98%|█████████▊| 984/1000 [59:45:36<58:40, 220.01s/it]  Epoch:  98%|█████████▊| 985/1000 [59:49:16<55:02, 220.19s/it]Epoch:  99%|█████████▊| 986/1000 [59:52:57<51:25, 220.36s/it]Epoch:  99%|█████████▊| 987/1000 [59:56:37<47:44, 220.38s/it]Epoch:  99%|█████████▉| 988/1000 [60:00:17<44:02, 220.25s/it]Epoch:  99%|█████████▉| 989/1000 [60:03:57<40:21, 220.12s/it]Epoch:  99%|█████████▉| 990/1000 [60:07:37<36:39, 219.95s/it]Epoch:  99%|█████████▉| 991/1000 [60:11:15<32:54, 219.43s/it]Epoch:  99%|█████████▉| 992/1000 [60:14:53<29:12, 219.10s/it]Epoch:  99%|█████████▉| 993/1000 [60:18:33<25:34, 219.16s/it]Epoch:  99%|█████████▉| 994/1000 [60:22:10<21:51, 218.66s/it]Epoch: 100%|█████████▉| 995/1000 [60:25:51<18:17, 219.44s/it]Epoch: 100%|█████████▉| 996/1000 [60:29:31<14:37, 219.44s/it]Epoch: 100%|█████████▉| 997/1000 [60:33:11<10:59, 219.71s/it]Epoch: 100%|█████████▉| 998/1000 [60:36:50<07:19, 219.56s/it]Epoch: 100%|█████████▉| 999/1000 [60:40:30<03:39, 219.54s/it]Epoch: 100%|██████████| 1000/1000 [60:44:10<00:00, 219.72s/it]Epoch: 100%|██████████| 1000/1000 [60:44:10<00:00, 218.65s/it]
2024-11-07 07:45:32.933 | INFO     | trainer:train:137 - load best at last from ./checkpoint
2024-11-07 07:45:32.942 | INFO     | trainer:save_model:248 - saving model checkpoint to ./checkpoint
2024-11-07 07:45:33.739 | INFO     | trainer:train:142 - training complete, cost 218651.3 secs.
epoch: 0, test val_loss: 0.141986
epoch: 0, train loss: 464.5404, lr: 0.000100, spent: 217.9 secs
epoch: 1, test val_loss: 0.141986
epoch: 1, train loss: 464.4300, lr: 0.000100, spent: 437.7 secs
epoch: 2, test val_loss: 0.141986
epoch: 2, train loss: 464.5416, lr: 0.000100, spent: 656.4 secs
epoch: 3, test val_loss: 0.141986
epoch: 3, train loss: 464.6508, lr: 0.000100, spent: 876.0 secs
epoch: 4, test val_loss: 0.141986
epoch: 4, train loss: 464.7606, lr: 0.000100, spent: 1095.5 secs
epoch: 5, test val_loss: 0.141986
epoch: 5, train loss: 464.4312, lr: 0.000100, spent: 1314.6 secs
epoch: 6, test val_loss: 0.141986
epoch: 6, train loss: 464.4300, lr: 0.000100, spent: 1534.5 secs
epoch: 7, test val_loss: 0.141986
epoch: 7, train loss: 464.4288, lr: 0.000100, spent: 1753.5 secs
epoch: 8, test val_loss: 0.141986
epoch: 8, train loss: 464.5404, lr: 0.000100, spent: 1972.9 secs
epoch: 9, test val_loss: 0.141986
epoch: 9, train loss: 464.5404, lr: 0.000100, spent: 2192.2 secs
epoch: 10, test val_loss: 0.141986
epoch: 10, train loss: 464.4294, lr: 0.000100, spent: 2410.5 secs
epoch: 11, test val_loss: 0.141986
epoch: 11, train loss: 464.5404, lr: 0.000100, spent: 2628.2 secs
epoch: 12, test val_loss: 0.141986
epoch: 12, train loss: 464.5404, lr: 0.000100, spent: 2846.6 secs
epoch: 13, test val_loss: 0.141986
epoch: 13, train loss: 464.4294, lr: 0.000100, spent: 3065.9 secs
epoch: 14, test val_loss: 0.141986
epoch: 14, train loss: 464.6508, lr: 0.000100, spent: 3284.1 secs
epoch: 15, test val_loss: 0.141986
epoch: 15, train loss: 464.4306, lr: 0.000100, spent: 3503.4 secs
epoch: 16, test val_loss: 0.141986
epoch: 16, train loss: 464.4306, lr: 0.000100, spent: 3722.2 secs
epoch: 17, test val_loss: 0.141986
epoch: 17, train loss: 464.6508, lr: 0.000100, spent: 3941.8 secs
epoch: 18, test val_loss: 0.141986
epoch: 18, train loss: 464.4294, lr: 0.000100, spent: 4160.4 secs
epoch: 19, test val_loss: 0.141986
epoch: 19, train loss: 464.6508, lr: 0.000100, spent: 4379.8 secs
epoch: 20, test val_loss: 0.141986
epoch: 20, train loss: 464.4306, lr: 0.000100, spent: 4600.7 secs
epoch: 21, test val_loss: 0.141986
epoch: 21, train loss: 464.4306, lr: 0.000100, spent: 4819.1 secs
epoch: 22, test val_loss: 0.141986
epoch: 22, train loss: 464.4294, lr: 0.000100, spent: 5037.9 secs
epoch: 23, test val_loss: 0.141986
epoch: 23, train loss: 464.5392, lr: 0.000100, spent: 5256.5 secs
epoch: 24, test val_loss: 0.141986
epoch: 24, train loss: 464.4288, lr: 0.000100, spent: 5474.8 secs
epoch: 25, test val_loss: 0.141986
epoch: 25, train loss: 464.4312, lr: 0.000100, spent: 5694.7 secs
epoch: 26, test val_loss: 0.141986
epoch: 26, train loss: 464.4306, lr: 0.000100, spent: 5913.8 secs
epoch: 27, test val_loss: 0.141986
epoch: 27, train loss: 464.6508, lr: 0.000100, spent: 6132.4 secs
epoch: 28, test val_loss: 0.141986
epoch: 28, train loss: 464.5404, lr: 0.000100, spent: 6351.0 secs
epoch: 29, test val_loss: 0.141986
epoch: 29, train loss: 464.5416, lr: 0.000100, spent: 6570.8 secs
epoch: 30, test val_loss: 0.141986
epoch: 30, train loss: 464.6502, lr: 0.000100, spent: 6789.0 secs
epoch: 31, test val_loss: 0.141986
epoch: 31, train loss: 464.5404, lr: 0.000100, spent: 7009.7 secs
epoch: 32, test val_loss: 0.141986
epoch: 32, train loss: 464.5410, lr: 0.000100, spent: 7229.1 secs
epoch: 33, test val_loss: 0.141986
epoch: 33, train loss: 464.4288, lr: 0.000100, spent: 7447.3 secs
epoch: 34, test val_loss: 0.141986
epoch: 34, train loss: 464.4300, lr: 0.000100, spent: 7666.6 secs
epoch: 35, test val_loss: 0.141986
epoch: 35, train loss: 464.4329, lr: 0.000100, spent: 7884.5 secs
epoch: 36, test val_loss: 0.141986
epoch: 36, train loss: 464.6502, lr: 0.000100, spent: 8103.0 secs
epoch: 37, test val_loss: 0.141986
epoch: 37, train loss: 464.4300, lr: 0.000100, spent: 8322.7 secs
epoch: 38, test val_loss: 0.141986
epoch: 38, train loss: 464.6502, lr: 0.000100, spent: 8541.7 secs
epoch: 39, test val_loss: 0.141986
epoch: 39, train loss: 464.7606, lr: 0.000100, spent: 8761.9 secs
epoch: 40, test val_loss: 0.141986
epoch: 40, train loss: 464.4312, lr: 0.000100, spent: 8982.4 secs
epoch: 41, test val_loss: 0.141986
epoch: 41, train loss: 464.5410, lr: 0.000100, spent: 9203.1 secs
epoch: 42, test val_loss: 0.141986
epoch: 42, train loss: 464.5392, lr: 0.000100, spent: 9421.8 secs
epoch: 43, test val_loss: 0.141986
epoch: 43, train loss: 464.4300, lr: 0.000100, spent: 9641.8 secs
epoch: 44, test val_loss: 0.141986
epoch: 44, train loss: 464.4288, lr: 0.000100, spent: 9862.7 secs
epoch: 45, test val_loss: 0.141986
epoch: 45, train loss: 464.4294, lr: 0.000100, spent: 10083.6 secs
epoch: 46, test val_loss: 0.141986
epoch: 46, train loss: 464.5392, lr: 0.000100, spent: 10304.4 secs
epoch: 47, test val_loss: 0.141986
epoch: 47, train loss: 464.4294, lr: 0.000100, spent: 10524.0 secs
epoch: 48, test val_loss: 0.141986
epoch: 48, train loss: 464.4300, lr: 0.000100, spent: 10745.0 secs
epoch: 49, test val_loss: 0.141986
epoch: 49, train loss: 464.4288, lr: 0.000100, spent: 10966.1 secs
epoch: 50, test val_loss: 0.141986
epoch: 50, train loss: 464.4300, lr: 0.000100, spent: 11186.5 secs
epoch: 51, test val_loss: 0.141986
epoch: 51, train loss: 464.4288, lr: 0.000100, spent: 11408.4 secs
epoch: 52, test val_loss: 0.141986
epoch: 52, train loss: 464.5404, lr: 0.000100, spent: 11628.0 secs
epoch: 53, test val_loss: 0.141986
epoch: 53, train loss: 464.4294, lr: 0.000100, spent: 11848.5 secs
epoch: 54, test val_loss: 0.141986
epoch: 54, train loss: 464.5410, lr: 0.000100, spent: 12068.1 secs
epoch: 55, test val_loss: 0.141986
epoch: 55, train loss: 464.5410, lr: 0.000100, spent: 12287.4 secs
epoch: 56, test val_loss: 0.141986
epoch: 56, train loss: 464.6520, lr: 0.000100, spent: 12506.4 secs
epoch: 57, test val_loss: 0.141986
epoch: 57, train loss: 464.4300, lr: 0.000100, spent: 12726.2 secs
epoch: 58, test val_loss: 0.141986
epoch: 58, train loss: 464.4306, lr: 0.000100, spent: 12945.4 secs
epoch: 59, test val_loss: 0.141986
epoch: 59, train loss: 464.5392, lr: 0.000100, spent: 13165.3 secs
epoch: 60, test val_loss: 0.141986
epoch: 60, train loss: 464.6502, lr: 0.000100, spent: 13385.3 secs
epoch: 61, test val_loss: 0.141986
epoch: 61, train loss: 464.5404, lr: 0.000100, spent: 13605.0 secs
epoch: 62, test val_loss: 0.141986
epoch: 62, train loss: 464.5428, lr: 0.000100, spent: 13823.8 secs
epoch: 63, test val_loss: 0.141986
epoch: 63, train loss: 464.4312, lr: 0.000100, spent: 14042.5 secs
epoch: 64, test val_loss: 0.141986
epoch: 64, train loss: 464.4306, lr: 0.000100, spent: 14262.3 secs
epoch: 65, test val_loss: 0.141986
epoch: 65, train loss: 464.4306, lr: 0.000100, spent: 14482.4 secs
epoch: 66, test val_loss: 0.141986
epoch: 66, train loss: 464.6502, lr: 0.000100, spent: 14701.3 secs
epoch: 67, test val_loss: 0.141986
epoch: 67, train loss: 464.4294, lr: 0.000100, spent: 14921.7 secs
epoch: 68, test val_loss: 0.141986
epoch: 68, train loss: 464.5410, lr: 0.000100, spent: 15140.8 secs
epoch: 69, test val_loss: 0.141986
epoch: 69, train loss: 464.4294, lr: 0.000100, spent: 15360.0 secs
epoch: 70, test val_loss: 0.141986
epoch: 70, train loss: 464.6508, lr: 0.000100, spent: 15581.2 secs
epoch: 71, test val_loss: 0.141986
epoch: 71, train loss: 464.4300, lr: 0.000100, spent: 15801.2 secs
epoch: 72, test val_loss: 0.141986
epoch: 72, train loss: 464.5398, lr: 0.000100, spent: 16020.2 secs
epoch: 73, test val_loss: 0.141986
epoch: 73, train loss: 464.4300, lr: 0.000100, spent: 16241.4 secs
epoch: 74, test val_loss: 0.141986
epoch: 74, train loss: 464.4300, lr: 0.000100, spent: 16463.1 secs
epoch: 75, test val_loss: 0.141986
epoch: 75, train loss: 464.5392, lr: 0.000100, spent: 16682.2 secs
epoch: 76, test val_loss: 0.141986
epoch: 76, train loss: 464.5398, lr: 0.000100, spent: 16901.1 secs
epoch: 77, test val_loss: 0.141986
epoch: 77, train loss: 464.5422, lr: 0.000100, spent: 17121.1 secs
epoch: 78, test val_loss: 0.141986
epoch: 78, train loss: 464.6514, lr: 0.000100, spent: 17341.1 secs
epoch: 79, test val_loss: 0.141986
epoch: 79, train loss: 464.4300, lr: 0.000100, spent: 17560.8 secs
epoch: 80, test val_loss: 0.141986
epoch: 80, train loss: 464.5398, lr: 0.000100, spent: 17781.3 secs
epoch: 81, test val_loss: 0.141986
epoch: 81, train loss: 464.5398, lr: 0.000100, spent: 18001.4 secs
epoch: 82, test val_loss: 0.141986
epoch: 82, train loss: 464.4288, lr: 0.000100, spent: 18221.8 secs
epoch: 83, test val_loss: 0.141986
epoch: 83, train loss: 464.4306, lr: 0.000100, spent: 18441.0 secs
epoch: 84, test val_loss: 0.141986
epoch: 84, train loss: 464.7606, lr: 0.000100, spent: 18661.2 secs
epoch: 85, test val_loss: 0.141986
epoch: 85, train loss: 464.4312, lr: 0.000100, spent: 18881.4 secs
epoch: 86, test val_loss: 0.141986
epoch: 86, train loss: 464.6502, lr: 0.000100, spent: 19099.5 secs
epoch: 87, test val_loss: 0.141986
epoch: 87, train loss: 464.4294, lr: 0.000100, spent: 19318.2 secs
epoch: 88, test val_loss: 0.141986
epoch: 88, train loss: 464.4294, lr: 0.000100, spent: 19537.0 secs
epoch: 89, test val_loss: 0.141986
epoch: 89, train loss: 464.4306, lr: 0.000100, spent: 19758.1 secs
epoch: 90, test val_loss: 0.141986
epoch: 90, train loss: 464.5398, lr: 0.000100, spent: 19978.6 secs
epoch: 91, test val_loss: 0.141986
epoch: 91, train loss: 464.5392, lr: 0.000100, spent: 20199.2 secs
epoch: 92, test val_loss: 0.141986
epoch: 92, train loss: 464.4294, lr: 0.000100, spent: 20420.1 secs
epoch: 93, test val_loss: 0.141986
epoch: 93, train loss: 464.6508, lr: 0.000100, spent: 20637.9 secs
epoch: 94, test val_loss: 0.141986
epoch: 94, train loss: 464.4288, lr: 0.000100, spent: 20858.1 secs
epoch: 95, test val_loss: 0.141986
epoch: 95, train loss: 464.4294, lr: 0.000100, spent: 21079.2 secs
epoch: 96, test val_loss: 0.141986
epoch: 96, train loss: 464.4294, lr: 0.000100, spent: 21298.4 secs
epoch: 97, test val_loss: 0.141986
epoch: 97, train loss: 464.5404, lr: 0.000100, spent: 21518.7 secs
epoch: 98, test val_loss: 0.141986
epoch: 98, train loss: 464.5392, lr: 0.000100, spent: 21740.2 secs
epoch: 99, test val_loss: 0.141986
epoch: 99, train loss: 464.4294, lr: 0.000100, spent: 21961.0 secs
epoch: 100, test val_loss: 0.141986
epoch: 100, train loss: 464.4300, lr: 0.000100, spent: 22180.8 secs
epoch: 101, test val_loss: 0.141986
epoch: 101, train loss: 464.4306, lr: 0.000100, spent: 22403.6 secs
epoch: 102, test val_loss: 0.141986
epoch: 102, train loss: 464.5398, lr: 0.000100, spent: 22622.5 secs
epoch: 103, test val_loss: 0.141986
epoch: 103, train loss: 464.5392, lr: 0.000100, spent: 22843.1 secs
epoch: 104, test val_loss: 0.141986
epoch: 104, train loss: 464.4317, lr: 0.000100, spent: 23065.2 secs
epoch: 105, test val_loss: 0.141986
epoch: 105, train loss: 464.6502, lr: 0.000100, spent: 23284.9 secs
epoch: 106, test val_loss: 0.141986
epoch: 106, train loss: 464.4300, lr: 0.000100, spent: 23503.9 secs
epoch: 107, test val_loss: 0.141986
epoch: 107, train loss: 464.4300, lr: 0.000100, spent: 23724.6 secs
epoch: 108, test val_loss: 0.141986
epoch: 108, train loss: 464.4294, lr: 0.000100, spent: 23945.6 secs
epoch: 109, test val_loss: 0.141986
epoch: 109, train loss: 464.4300, lr: 0.000100, spent: 24164.5 secs
epoch: 110, test val_loss: 0.141986
epoch: 110, train loss: 464.5416, lr: 0.000100, spent: 24384.0 secs
epoch: 111, test val_loss: 0.141986
epoch: 111, train loss: 464.4294, lr: 0.000100, spent: 24603.6 secs
epoch: 112, test val_loss: 0.141986
epoch: 112, train loss: 464.4306, lr: 0.000100, spent: 24823.3 secs
epoch: 113, test val_loss: 0.141986
epoch: 113, train loss: 464.4294, lr: 0.000100, spent: 25045.1 secs
epoch: 114, test val_loss: 0.141986
epoch: 114, train loss: 464.4294, lr: 0.000100, spent: 25266.2 secs
epoch: 115, test val_loss: 0.141986
epoch: 115, train loss: 464.6502, lr: 0.000100, spent: 25487.9 secs
epoch: 116, test val_loss: 0.141986
epoch: 116, train loss: 464.4306, lr: 0.000100, spent: 25708.4 secs
epoch: 117, test val_loss: 0.141986
epoch: 117, train loss: 464.5392, lr: 0.000100, spent: 25929.7 secs
epoch: 118, test val_loss: 0.141986
epoch: 118, train loss: 464.5404, lr: 0.000100, spent: 26148.4 secs
epoch: 119, test val_loss: 0.141986
epoch: 119, train loss: 464.5410, lr: 0.000100, spent: 26370.0 secs
epoch: 120, test val_loss: 0.141986
epoch: 120, train loss: 464.4300, lr: 0.000100, spent: 26591.1 secs
epoch: 121, test val_loss: 0.141986
epoch: 121, train loss: 464.4294, lr: 0.000100, spent: 26811.9 secs
epoch: 122, test val_loss: 0.141986
epoch: 122, train loss: 464.4312, lr: 0.000100, spent: 27032.7 secs
epoch: 123, test val_loss: 0.141986
epoch: 123, train loss: 464.5398, lr: 0.000100, spent: 27256.4 secs
epoch: 124, test val_loss: 0.141986
epoch: 124, train loss: 464.6514, lr: 0.000100, spent: 27476.4 secs
epoch: 125, test val_loss: 0.141986
epoch: 125, train loss: 464.4288, lr: 0.000100, spent: 27697.6 secs
epoch: 126, test val_loss: 0.141986
epoch: 126, train loss: 464.5404, lr: 0.000100, spent: 27918.0 secs
epoch: 127, test val_loss: 0.141986
epoch: 127, train loss: 464.4300, lr: 0.000100, spent: 28138.6 secs
epoch: 128, test val_loss: 0.141986
epoch: 128, train loss: 464.6496, lr: 0.000100, spent: 28358.8 secs
epoch: 129, test val_loss: 0.141986
epoch: 129, train loss: 464.4294, lr: 0.000100, spent: 28581.0 secs
epoch: 130, test val_loss: 0.141986
epoch: 130, train loss: 464.5404, lr: 0.000100, spent: 28800.8 secs
epoch: 131, test val_loss: 0.141986
epoch: 131, train loss: 464.5404, lr: 0.000100, spent: 29022.7 secs
epoch: 132, test val_loss: 0.141986
epoch: 132, train loss: 464.4317, lr: 0.000100, spent: 29242.7 secs
epoch: 133, test val_loss: 0.141986
epoch: 133, train loss: 464.4288, lr: 0.000100, spent: 29461.6 secs
epoch: 134, test val_loss: 0.141986
epoch: 134, train loss: 464.4294, lr: 0.000100, spent: 29682.7 secs
epoch: 135, test val_loss: 0.141986
epoch: 135, train loss: 464.4294, lr: 0.000100, spent: 29902.5 secs
epoch: 136, test val_loss: 0.141986
epoch: 136, train loss: 464.5398, lr: 0.000100, spent: 30121.6 secs
epoch: 137, test val_loss: 0.141986
epoch: 137, train loss: 464.4306, lr: 0.000100, spent: 30341.1 secs
epoch: 138, test val_loss: 0.141986
epoch: 138, train loss: 464.4317, lr: 0.000100, spent: 30561.8 secs
epoch: 139, test val_loss: 0.141986
epoch: 139, train loss: 464.4300, lr: 0.000100, spent: 30781.1 secs
epoch: 140, test val_loss: 0.141986
epoch: 140, train loss: 464.7606, lr: 0.000100, spent: 30999.9 secs
epoch: 141, test val_loss: 0.141986
epoch: 141, train loss: 464.4300, lr: 0.000100, spent: 31219.8 secs
epoch: 142, test val_loss: 0.141986
epoch: 142, train loss: 464.5410, lr: 0.000100, spent: 31440.6 secs
epoch: 143, test val_loss: 0.141986
epoch: 143, train loss: 464.5404, lr: 0.000100, spent: 31660.1 secs
epoch: 144, test val_loss: 0.141986
epoch: 144, train loss: 464.7618, lr: 0.000100, spent: 31880.1 secs
epoch: 145, test val_loss: 0.141986
epoch: 145, train loss: 464.4294, lr: 0.000100, spent: 32098.8 secs
epoch: 146, test val_loss: 0.141986
epoch: 146, train loss: 464.5404, lr: 0.000100, spent: 32319.4 secs
epoch: 147, test val_loss: 0.141986
epoch: 147, train loss: 464.4312, lr: 0.000100, spent: 32540.0 secs
epoch: 148, test val_loss: 0.141986
epoch: 148, train loss: 464.5392, lr: 0.000100, spent: 32758.3 secs
epoch: 149, test val_loss: 0.141986
epoch: 149, train loss: 464.5392, lr: 0.000100, spent: 32979.3 secs
epoch: 150, test val_loss: 0.141986
epoch: 150, train loss: 464.4300, lr: 0.000100, spent: 33196.7 secs
epoch: 151, test val_loss: 0.141986
epoch: 151, train loss: 464.5416, lr: 0.000100, spent: 33414.7 secs
epoch: 152, test val_loss: 0.141986
epoch: 152, train loss: 464.4300, lr: 0.000100, spent: 33633.6 secs
epoch: 153, test val_loss: 0.141986
epoch: 153, train loss: 464.5404, lr: 0.000100, spent: 33852.1 secs
epoch: 154, test val_loss: 0.141986
epoch: 154, train loss: 464.5398, lr: 0.000100, spent: 34071.2 secs
epoch: 155, test val_loss: 0.141986
epoch: 155, train loss: 464.4288, lr: 0.000100, spent: 34290.6 secs
epoch: 156, test val_loss: 0.141986
epoch: 156, train loss: 464.5398, lr: 0.000100, spent: 34509.1 secs
epoch: 157, test val_loss: 0.141986
epoch: 157, train loss: 464.5398, lr: 0.000100, spent: 34727.2 secs
epoch: 158, test val_loss: 0.141986
epoch: 158, train loss: 464.6502, lr: 0.000100, spent: 34945.7 secs
epoch: 159, test val_loss: 0.141986
epoch: 159, train loss: 464.5398, lr: 0.000100, spent: 35164.9 secs
epoch: 160, test val_loss: 0.141986
epoch: 160, train loss: 464.4294, lr: 0.000100, spent: 35385.1 secs
epoch: 161, test val_loss: 0.141986
epoch: 161, train loss: 464.4294, lr: 0.000100, spent: 35604.4 secs
epoch: 162, test val_loss: 0.141986
epoch: 162, train loss: 464.4294, lr: 0.000100, spent: 35823.6 secs
epoch: 163, test val_loss: 0.141986
epoch: 163, train loss: 464.6502, lr: 0.000100, spent: 36043.0 secs
epoch: 164, test val_loss: 0.141986
epoch: 164, train loss: 464.4294, lr: 0.000100, spent: 36262.8 secs
epoch: 165, test val_loss: 0.141986
epoch: 165, train loss: 464.5410, lr: 0.000100, spent: 36483.3 secs
epoch: 166, test val_loss: 0.141986
epoch: 166, train loss: 464.5410, lr: 0.000100, spent: 36703.6 secs
epoch: 167, test val_loss: 0.141986
epoch: 167, train loss: 464.5398, lr: 0.000100, spent: 36924.3 secs
epoch: 168, test val_loss: 0.141986
epoch: 168, train loss: 464.5404, lr: 0.000100, spent: 37145.8 secs
epoch: 169, test val_loss: 0.141986
epoch: 169, train loss: 464.6502, lr: 0.000100, spent: 37367.5 secs
epoch: 170, test val_loss: 0.141986
epoch: 170, train loss: 464.5398, lr: 0.000100, spent: 37586.5 secs
epoch: 171, test val_loss: 0.141986
epoch: 171, train loss: 464.6520, lr: 0.000100, spent: 37806.1 secs
epoch: 172, test val_loss: 0.141986
epoch: 172, train loss: 464.5416, lr: 0.000100, spent: 38025.1 secs
epoch: 173, test val_loss: 0.141986
epoch: 173, train loss: 464.6508, lr: 0.000100, spent: 38244.2 secs
epoch: 174, test val_loss: 0.141986
epoch: 174, train loss: 464.4300, lr: 0.000100, spent: 38464.0 secs
epoch: 175, test val_loss: 0.141986
epoch: 175, train loss: 464.5410, lr: 0.000100, spent: 38682.8 secs
epoch: 176, test val_loss: 0.141986
epoch: 176, train loss: 464.5392, lr: 0.000100, spent: 38901.6 secs
epoch: 177, test val_loss: 0.141986
epoch: 177, train loss: 464.4306, lr: 0.000100, spent: 39121.2 secs
epoch: 178, test val_loss: 0.141986
epoch: 178, train loss: 464.4294, lr: 0.000100, spent: 39340.8 secs
epoch: 179, test val_loss: 0.141986
epoch: 179, train loss: 464.4300, lr: 0.000100, spent: 39560.1 secs
epoch: 180, test val_loss: 0.141986
epoch: 180, train loss: 464.4294, lr: 0.000100, spent: 39778.4 secs
epoch: 181, test val_loss: 0.141986
epoch: 181, train loss: 464.7600, lr: 0.000100, spent: 39996.5 secs
epoch: 182, test val_loss: 0.141986
epoch: 182, train loss: 464.5392, lr: 0.000100, spent: 40214.4 secs
epoch: 183, test val_loss: 0.141986
epoch: 183, train loss: 464.4317, lr: 0.000100, spent: 40433.0 secs
epoch: 184, test val_loss: 0.141986
epoch: 184, train loss: 464.4317, lr: 0.000100, spent: 40650.6 secs
epoch: 185, test val_loss: 0.141986
epoch: 185, train loss: 464.5398, lr: 0.000100, spent: 40869.2 secs
epoch: 186, test val_loss: 0.141986
epoch: 186, train loss: 464.6496, lr: 0.000100, spent: 41087.8 secs
epoch: 187, test val_loss: 0.141986
epoch: 187, train loss: 464.4306, lr: 0.000100, spent: 41306.0 secs
epoch: 188, test val_loss: 0.141986
epoch: 188, train loss: 464.4294, lr: 0.000100, spent: 41525.0 secs
epoch: 189, test val_loss: 0.141986
epoch: 189, train loss: 464.5410, lr: 0.000100, spent: 41743.7 secs
epoch: 190, test val_loss: 0.141986
epoch: 190, train loss: 464.6520, lr: 0.000100, spent: 41962.6 secs
epoch: 191, test val_loss: 0.141986
epoch: 191, train loss: 464.4306, lr: 0.000100, spent: 42182.6 secs
epoch: 192, test val_loss: 0.141986
epoch: 192, train loss: 464.4300, lr: 0.000100, spent: 42401.3 secs
epoch: 193, test val_loss: 0.141986
epoch: 193, train loss: 464.4294, lr: 0.000100, spent: 42619.4 secs
epoch: 194, test val_loss: 0.141986
epoch: 194, train loss: 464.4306, lr: 0.000100, spent: 42841.0 secs
epoch: 195, test val_loss: 0.141986
epoch: 195, train loss: 464.5428, lr: 0.000100, spent: 43059.9 secs
epoch: 196, test val_loss: 0.141986
epoch: 196, train loss: 464.4306, lr: 0.000100, spent: 43279.7 secs
epoch: 197, test val_loss: 0.141986
epoch: 197, train loss: 464.5416, lr: 0.000100, spent: 43498.5 secs
epoch: 198, test val_loss: 0.141986
epoch: 198, train loss: 464.5392, lr: 0.000100, spent: 43717.3 secs
epoch: 199, test val_loss: 0.141986
epoch: 199, train loss: 464.8711, lr: 0.000100, spent: 43936.7 secs
epoch: 200, test val_loss: 0.141986
epoch: 200, train loss: 464.5398, lr: 0.000100, spent: 44154.9 secs
epoch: 201, test val_loss: 0.141986
epoch: 201, train loss: 464.5404, lr: 0.000100, spent: 44373.5 secs
epoch: 202, test val_loss: 0.141986
epoch: 202, train loss: 464.5398, lr: 0.000100, spent: 44593.1 secs
epoch: 203, test val_loss: 0.141986
epoch: 203, train loss: 464.4317, lr: 0.000100, spent: 44811.9 secs
epoch: 204, test val_loss: 0.141986
epoch: 204, train loss: 464.4300, lr: 0.000100, spent: 45031.3 secs
epoch: 205, test val_loss: 0.141986
epoch: 205, train loss: 464.7606, lr: 0.000100, spent: 45250.0 secs
epoch: 206, test val_loss: 0.141986
epoch: 206, train loss: 464.4294, lr: 0.000100, spent: 45471.3 secs
epoch: 207, test val_loss: 0.141986
epoch: 207, train loss: 464.4288, lr: 0.000100, spent: 45690.4 secs
epoch: 208, test val_loss: 0.141986
epoch: 208, train loss: 464.4288, lr: 0.000100, spent: 45909.3 secs
epoch: 209, test val_loss: 0.141986
epoch: 209, train loss: 464.6496, lr: 0.000100, spent: 46128.7 secs
epoch: 210, test val_loss: 0.141986
epoch: 210, train loss: 464.5404, lr: 0.000100, spent: 46349.2 secs
epoch: 211, test val_loss: 0.141986
epoch: 211, train loss: 464.5410, lr: 0.000100, spent: 46568.6 secs
epoch: 212, test val_loss: 0.141986
epoch: 212, train loss: 464.4306, lr: 0.000100, spent: 46787.7 secs
epoch: 213, test val_loss: 0.141986
epoch: 213, train loss: 464.4300, lr: 0.000100, spent: 47006.2 secs
epoch: 214, test val_loss: 0.141986
epoch: 214, train loss: 464.5392, lr: 0.000100, spent: 47224.2 secs
epoch: 215, test val_loss: 0.141986
epoch: 215, train loss: 464.4300, lr: 0.000100, spent: 47445.1 secs
epoch: 216, test val_loss: 0.141986
epoch: 216, train loss: 464.5410, lr: 0.000100, spent: 47664.0 secs
epoch: 217, test val_loss: 0.141986
epoch: 217, train loss: 464.4294, lr: 0.000100, spent: 47884.9 secs
epoch: 218, test val_loss: 0.141986
epoch: 218, train loss: 464.4294, lr: 0.000100, spent: 48105.9 secs
epoch: 219, test val_loss: 0.141986
epoch: 219, train loss: 464.4306, lr: 0.000100, spent: 48326.9 secs
epoch: 220, test val_loss: 0.141986
epoch: 220, train loss: 464.5410, lr: 0.000100, spent: 48547.2 secs
epoch: 221, test val_loss: 0.141986
epoch: 221, train loss: 464.5392, lr: 0.000100, spent: 48766.1 secs
epoch: 222, test val_loss: 0.141986
epoch: 222, train loss: 464.5398, lr: 0.000100, spent: 48985.7 secs
epoch: 223, test val_loss: 0.141986
epoch: 223, train loss: 464.5410, lr: 0.000100, spent: 49205.5 secs
epoch: 224, test val_loss: 0.141986
epoch: 224, train loss: 464.4294, lr: 0.000100, spent: 49425.1 secs
epoch: 225, test val_loss: 0.141986
epoch: 225, train loss: 464.5398, lr: 0.000100, spent: 49645.2 secs
epoch: 226, test val_loss: 0.141986
epoch: 226, train loss: 464.5410, lr: 0.000100, spent: 49865.0 secs
epoch: 227, test val_loss: 0.141986
epoch: 227, train loss: 464.5416, lr: 0.000100, spent: 50085.0 secs
epoch: 228, test val_loss: 0.141986
epoch: 228, train loss: 464.4300, lr: 0.000100, spent: 50303.9 secs
epoch: 229, test val_loss: 0.141986
epoch: 229, train loss: 464.5404, lr: 0.000100, spent: 50523.3 secs
epoch: 230, test val_loss: 0.141986
epoch: 230, train loss: 464.5410, lr: 0.000100, spent: 50741.3 secs
epoch: 231, test val_loss: 0.141986
epoch: 231, train loss: 464.4294, lr: 0.000100, spent: 50959.6 secs
epoch: 232, test val_loss: 0.141986
epoch: 232, train loss: 464.5398, lr: 0.000100, spent: 51178.9 secs
epoch: 233, test val_loss: 0.141986
epoch: 233, train loss: 464.4306, lr: 0.000100, spent: 51398.7 secs
epoch: 234, test val_loss: 0.141986
epoch: 234, train loss: 464.4294, lr: 0.000100, spent: 51619.1 secs
epoch: 235, test val_loss: 0.141986
epoch: 235, train loss: 464.5410, lr: 0.000100, spent: 51838.0 secs
epoch: 236, test val_loss: 0.141986
epoch: 236, train loss: 464.6502, lr: 0.000100, spent: 52056.0 secs
epoch: 237, test val_loss: 0.141986
epoch: 237, train loss: 464.4312, lr: 0.000100, spent: 52274.3 secs
epoch: 238, test val_loss: 0.141986
epoch: 238, train loss: 464.4300, lr: 0.000100, spent: 52494.2 secs
epoch: 239, test val_loss: 0.141986
epoch: 239, train loss: 464.4294, lr: 0.000100, spent: 52713.8 secs
epoch: 240, test val_loss: 0.141986
epoch: 240, train loss: 464.4306, lr: 0.000100, spent: 52932.3 secs
epoch: 241, test val_loss: 0.141986
epoch: 241, train loss: 464.5404, lr: 0.000100, spent: 53151.4 secs
epoch: 242, test val_loss: 0.141986
epoch: 242, train loss: 464.4294, lr: 0.000100, spent: 53370.3 secs
epoch: 243, test val_loss: 0.141986
epoch: 243, train loss: 464.4306, lr: 0.000100, spent: 53588.4 secs
epoch: 244, test val_loss: 0.141986
epoch: 244, train loss: 464.5404, lr: 0.000100, spent: 53805.6 secs
epoch: 245, test val_loss: 0.141986
epoch: 245, train loss: 464.4294, lr: 0.000100, spent: 54023.6 secs
epoch: 246, test val_loss: 0.141986
epoch: 246, train loss: 464.6502, lr: 0.000100, spent: 54242.9 secs
epoch: 247, test val_loss: 0.141986
epoch: 247, train loss: 464.4300, lr: 0.000100, spent: 54461.4 secs
epoch: 248, test val_loss: 0.141986
epoch: 248, train loss: 464.4300, lr: 0.000100, spent: 54683.5 secs
epoch: 249, test val_loss: 0.141986
epoch: 249, train loss: 464.5422, lr: 0.000100, spent: 54901.3 secs
epoch: 250, test val_loss: 0.141986
epoch: 250, train loss: 464.4300, lr: 0.000100, spent: 55120.1 secs
epoch: 251, test val_loss: 0.141986
epoch: 251, train loss: 464.4306, lr: 0.000100, spent: 55339.9 secs
epoch: 252, test val_loss: 0.141986
epoch: 252, train loss: 464.6508, lr: 0.000100, spent: 55558.5 secs
epoch: 253, test val_loss: 0.141986
epoch: 253, train loss: 464.4294, lr: 0.000100, spent: 55778.0 secs
epoch: 254, test val_loss: 0.141986
epoch: 254, train loss: 464.4294, lr: 0.000100, spent: 55998.5 secs
epoch: 255, test val_loss: 0.141986
epoch: 255, train loss: 464.4300, lr: 0.000100, spent: 56219.4 secs
epoch: 256, test val_loss: 0.141986
epoch: 256, train loss: 464.4306, lr: 0.000100, spent: 56438.0 secs
epoch: 257, test val_loss: 0.141986
epoch: 257, train loss: 464.5410, lr: 0.000100, spent: 56657.1 secs
epoch: 258, test val_loss: 0.141986
epoch: 258, train loss: 464.4294, lr: 0.000100, spent: 56875.8 secs
epoch: 259, test val_loss: 0.141986
epoch: 259, train loss: 464.4312, lr: 0.000100, spent: 57093.9 secs
epoch: 260, test val_loss: 0.141986
epoch: 260, train loss: 464.4294, lr: 0.000100, spent: 57314.3 secs
epoch: 261, test val_loss: 0.141986
epoch: 261, train loss: 464.5392, lr: 0.000100, spent: 57532.8 secs
epoch: 262, test val_loss: 0.141986
epoch: 262, train loss: 464.5410, lr: 0.000100, spent: 57751.9 secs
epoch: 263, test val_loss: 0.141986
epoch: 263, train loss: 464.4317, lr: 0.000100, spent: 57969.6 secs
epoch: 264, test val_loss: 0.141986
epoch: 264, train loss: 464.7612, lr: 0.000100, spent: 58187.4 secs
epoch: 265, test val_loss: 0.141986
epoch: 265, train loss: 464.4288, lr: 0.000100, spent: 58406.0 secs
epoch: 266, test val_loss: 0.141986
epoch: 266, train loss: 464.4317, lr: 0.000100, spent: 58624.8 secs
epoch: 267, test val_loss: 0.141986
epoch: 267, train loss: 464.4300, lr: 0.000100, spent: 58846.5 secs
epoch: 268, test val_loss: 0.141986
epoch: 268, train loss: 464.7612, lr: 0.000100, spent: 59067.4 secs
epoch: 269, test val_loss: 0.141986
epoch: 269, train loss: 464.4288, lr: 0.000100, spent: 59288.1 secs
epoch: 270, test val_loss: 0.141986
epoch: 270, train loss: 464.6502, lr: 0.000100, spent: 59509.3 secs
epoch: 271, test val_loss: 0.141986
epoch: 271, train loss: 464.4300, lr: 0.000100, spent: 59733.9 secs
epoch: 272, test val_loss: 0.141986
epoch: 272, train loss: 464.4323, lr: 0.000100, spent: 59959.3 secs
epoch: 273, test val_loss: 0.141986
epoch: 273, train loss: 464.6526, lr: 0.000100, spent: 60181.3 secs
epoch: 274, test val_loss: 0.141986
epoch: 274, train loss: 464.5398, lr: 0.000100, spent: 60401.8 secs
epoch: 275, test val_loss: 0.141986
epoch: 275, train loss: 464.4317, lr: 0.000100, spent: 60621.7 secs
epoch: 276, test val_loss: 0.141986
epoch: 276, train loss: 464.4294, lr: 0.000100, spent: 60842.4 secs
epoch: 277, test val_loss: 0.141986
epoch: 277, train loss: 464.4300, lr: 0.000100, spent: 61062.9 secs
epoch: 278, test val_loss: 0.141986
epoch: 278, train loss: 464.5398, lr: 0.000100, spent: 61283.1 secs
epoch: 279, test val_loss: 0.141986
epoch: 279, train loss: 464.6520, lr: 0.000100, spent: 61505.5 secs
epoch: 280, test val_loss: 0.141986
epoch: 280, train loss: 464.5392, lr: 0.000100, spent: 61726.5 secs
epoch: 281, test val_loss: 0.141986
epoch: 281, train loss: 464.4317, lr: 0.000100, spent: 61948.9 secs
epoch: 282, test val_loss: 0.141986
epoch: 282, train loss: 464.6508, lr: 0.000100, spent: 62170.7 secs
epoch: 283, test val_loss: 0.141986
epoch: 283, train loss: 464.6520, lr: 0.000100, spent: 62392.8 secs
epoch: 284, test val_loss: 0.141986
epoch: 284, train loss: 464.4300, lr: 0.000100, spent: 62614.7 secs
epoch: 285, test val_loss: 0.141986
epoch: 285, train loss: 464.4306, lr: 0.000100, spent: 62838.4 secs
epoch: 286, test val_loss: 0.141986
epoch: 286, train loss: 464.4300, lr: 0.000100, spent: 63057.9 secs
epoch: 287, test val_loss: 0.141986
epoch: 287, train loss: 464.5404, lr: 0.000100, spent: 63278.4 secs
epoch: 288, test val_loss: 0.141986
epoch: 288, train loss: 464.5404, lr: 0.000100, spent: 63498.5 secs
epoch: 289, test val_loss: 0.141986
epoch: 289, train loss: 464.4300, lr: 0.000100, spent: 63717.1 secs
epoch: 290, test val_loss: 0.141986
epoch: 290, train loss: 464.4300, lr: 0.000100, spent: 63938.2 secs
epoch: 291, test val_loss: 0.141986
epoch: 291, train loss: 464.4288, lr: 0.000100, spent: 64158.9 secs
epoch: 292, test val_loss: 0.141986
epoch: 292, train loss: 464.4300, lr: 0.000100, spent: 64378.5 secs
epoch: 293, test val_loss: 0.141986
epoch: 293, train loss: 464.4288, lr: 0.000100, spent: 64601.8 secs
epoch: 294, test val_loss: 0.141986
epoch: 294, train loss: 464.4288, lr: 0.000100, spent: 64821.6 secs
epoch: 295, test val_loss: 0.141986
epoch: 295, train loss: 464.4312, lr: 0.000100, spent: 65042.6 secs
epoch: 296, test val_loss: 0.141986
epoch: 296, train loss: 464.5404, lr: 0.000100, spent: 65261.8 secs
epoch: 297, test val_loss: 0.141986
epoch: 297, train loss: 464.5398, lr: 0.000100, spent: 65481.3 secs
epoch: 298, test val_loss: 0.141986
epoch: 298, train loss: 464.6496, lr: 0.000100, spent: 65701.6 secs
epoch: 299, test val_loss: 0.141986
epoch: 299, train loss: 464.4306, lr: 0.000100, spent: 65921.0 secs
epoch: 300, test val_loss: 0.141986
epoch: 300, train loss: 464.4306, lr: 0.000100, spent: 66141.4 secs
epoch: 301, test val_loss: 0.141986
epoch: 301, train loss: 464.5392, lr: 0.000100, spent: 66361.0 secs
epoch: 302, test val_loss: 0.141986
epoch: 302, train loss: 464.4300, lr: 0.000100, spent: 66579.5 secs
epoch: 303, test val_loss: 0.141986
epoch: 303, train loss: 464.6502, lr: 0.000100, spent: 66797.1 secs
epoch: 304, test val_loss: 0.141986
epoch: 304, train loss: 464.5392, lr: 0.000100, spent: 67016.1 secs
epoch: 305, test val_loss: 0.141986
epoch: 305, train loss: 464.6502, lr: 0.000100, spent: 67235.5 secs
epoch: 306, test val_loss: 0.141986
epoch: 306, train loss: 464.4288, lr: 0.000100, spent: 67454.2 secs
epoch: 307, test val_loss: 0.141986
epoch: 307, train loss: 464.4288, lr: 0.000100, spent: 67672.1 secs
epoch: 308, test val_loss: 0.141986
epoch: 308, train loss: 464.4300, lr: 0.000100, spent: 67891.3 secs
epoch: 309, test val_loss: 0.141986
epoch: 309, train loss: 464.6520, lr: 0.000100, spent: 68111.0 secs
epoch: 310, test val_loss: 0.141986
epoch: 310, train loss: 464.7606, lr: 0.000100, spent: 68328.6 secs
epoch: 311, test val_loss: 0.141986
epoch: 311, train loss: 464.4300, lr: 0.000100, spent: 68549.9 secs
epoch: 312, test val_loss: 0.141986
epoch: 312, train loss: 464.5392, lr: 0.000100, spent: 68770.9 secs
epoch: 313, test val_loss: 0.141986
epoch: 313, train loss: 464.7612, lr: 0.000100, spent: 68990.4 secs
epoch: 314, test val_loss: 0.141986
epoch: 314, train loss: 464.4288, lr: 0.000100, spent: 69209.5 secs
epoch: 315, test val_loss: 0.141986
epoch: 315, train loss: 464.4294, lr: 0.000100, spent: 69428.0 secs
epoch: 316, test val_loss: 0.141986
epoch: 316, train loss: 464.6496, lr: 0.000100, spent: 69646.7 secs
epoch: 317, test val_loss: 0.141986
epoch: 317, train loss: 464.4300, lr: 0.000100, spent: 69865.4 secs
epoch: 318, test val_loss: 0.141986
epoch: 318, train loss: 464.4300, lr: 0.000100, spent: 70084.7 secs
epoch: 319, test val_loss: 0.141986
epoch: 319, train loss: 464.6496, lr: 0.000100, spent: 70304.9 secs
epoch: 320, test val_loss: 0.141986
epoch: 320, train loss: 464.5398, lr: 0.000100, spent: 70523.5 secs
epoch: 321, test val_loss: 0.141986
epoch: 321, train loss: 464.5392, lr: 0.000100, spent: 70744.7 secs
epoch: 322, test val_loss: 0.141986
epoch: 322, train loss: 464.4294, lr: 0.000100, spent: 70964.7 secs
epoch: 323, test val_loss: 0.141986
epoch: 323, train loss: 464.6496, lr: 0.000100, spent: 71185.7 secs
epoch: 324, test val_loss: 0.141986
epoch: 324, train loss: 464.4300, lr: 0.000100, spent: 71404.2 secs
epoch: 325, test val_loss: 0.141986
epoch: 325, train loss: 464.4317, lr: 0.000100, spent: 71622.8 secs
epoch: 326, test val_loss: 0.141986
epoch: 326, train loss: 464.5404, lr: 0.000100, spent: 71843.6 secs
epoch: 327, test val_loss: 0.141986
epoch: 327, train loss: 464.5398, lr: 0.000100, spent: 72063.3 secs
epoch: 328, test val_loss: 0.141986
epoch: 328, train loss: 464.5404, lr: 0.000100, spent: 72284.7 secs
epoch: 329, test val_loss: 0.141986
epoch: 329, train loss: 464.6508, lr: 0.000100, spent: 72504.9 secs
epoch: 330, test val_loss: 0.141986
epoch: 330, train loss: 464.6508, lr: 0.000100, spent: 72725.3 secs
epoch: 331, test val_loss: 0.141986
epoch: 331, train loss: 464.6502, lr: 0.000100, spent: 72947.3 secs
epoch: 332, test val_loss: 0.141986
epoch: 332, train loss: 464.6508, lr: 0.000100, spent: 73167.5 secs
epoch: 333, test val_loss: 0.141986
epoch: 333, train loss: 464.4306, lr: 0.000100, spent: 73386.9 secs
epoch: 334, test val_loss: 0.141986
epoch: 334, train loss: 464.4294, lr: 0.000100, spent: 73606.4 secs
epoch: 335, test val_loss: 0.141986
epoch: 335, train loss: 464.4300, lr: 0.000100, spent: 73825.5 secs
epoch: 336, test val_loss: 0.141986
epoch: 336, train loss: 464.5404, lr: 0.000100, spent: 74045.6 secs
epoch: 337, test val_loss: 0.141986
epoch: 337, train loss: 464.4306, lr: 0.000100, spent: 74264.8 secs
epoch: 338, test val_loss: 0.141986
epoch: 338, train loss: 464.5398, lr: 0.000100, spent: 74483.6 secs
epoch: 339, test val_loss: 0.141986
epoch: 339, train loss: 464.4306, lr: 0.000100, spent: 74700.9 secs
epoch: 340, test val_loss: 0.141986
epoch: 340, train loss: 464.5416, lr: 0.000100, spent: 74919.7 secs
epoch: 341, test val_loss: 0.141986
epoch: 341, train loss: 464.5416, lr: 0.000100, spent: 75139.4 secs
epoch: 342, test val_loss: 0.141986
epoch: 342, train loss: 464.4288, lr: 0.000100, spent: 75360.4 secs
epoch: 343, test val_loss: 0.141986
epoch: 343, train loss: 464.6502, lr: 0.000100, spent: 75579.7 secs
epoch: 344, test val_loss: 0.141986
epoch: 344, train loss: 464.7618, lr: 0.000100, spent: 75798.3 secs
epoch: 345, test val_loss: 0.141986
epoch: 345, train loss: 464.6526, lr: 0.000100, spent: 76016.6 secs
epoch: 346, test val_loss: 0.141986
epoch: 346, train loss: 464.6496, lr: 0.000100, spent: 76236.1 secs
epoch: 347, test val_loss: 0.141986
epoch: 347, train loss: 464.5410, lr: 0.000100, spent: 76457.4 secs
epoch: 348, test val_loss: 0.141986
epoch: 348, train loss: 464.4306, lr: 0.000100, spent: 76676.2 secs
epoch: 349, test val_loss: 0.141986
epoch: 349, train loss: 464.4306, lr: 0.000100, spent: 76896.7 secs
epoch: 350, test val_loss: 0.141986
epoch: 350, train loss: 464.6508, lr: 0.000100, spent: 77116.4 secs
epoch: 351, test val_loss: 0.141986
epoch: 351, train loss: 464.4306, lr: 0.000100, spent: 77336.6 secs
epoch: 352, test val_loss: 0.141986
epoch: 352, train loss: 464.5398, lr: 0.000100, spent: 77554.9 secs
epoch: 353, test val_loss: 0.141986
epoch: 353, train loss: 464.5416, lr: 0.000100, spent: 77774.5 secs
epoch: 354, test val_loss: 0.141986
epoch: 354, train loss: 464.4300, lr: 0.000100, spent: 77995.9 secs
epoch: 355, test val_loss: 0.141986
epoch: 355, train loss: 464.5410, lr: 0.000100, spent: 78216.1 secs
epoch: 356, test val_loss: 0.141986
epoch: 356, train loss: 464.5410, lr: 0.000100, spent: 78434.5 secs
epoch: 357, test val_loss: 0.141986
epoch: 357, train loss: 464.4312, lr: 0.000100, spent: 78654.7 secs
epoch: 358, test val_loss: 0.141986
epoch: 358, train loss: 464.5416, lr: 0.000100, spent: 78873.7 secs
epoch: 359, test val_loss: 0.141986
epoch: 359, train loss: 464.4306, lr: 0.000100, spent: 79095.3 secs
epoch: 360, test val_loss: 0.141986
epoch: 360, train loss: 464.4294, lr: 0.000100, spent: 79313.9 secs
epoch: 361, test val_loss: 0.141986
epoch: 361, train loss: 464.5410, lr: 0.000100, spent: 79531.4 secs
epoch: 362, test val_loss: 0.141986
epoch: 362, train loss: 464.6502, lr: 0.000100, spent: 79748.3 secs
epoch: 363, test val_loss: 0.141986
epoch: 363, train loss: 464.7612, lr: 0.000100, spent: 79965.0 secs
epoch: 364, test val_loss: 0.141986
epoch: 364, train loss: 464.4300, lr: 0.000100, spent: 80182.8 secs
epoch: 365, test val_loss: 0.141986
epoch: 365, train loss: 464.4312, lr: 0.000100, spent: 80400.1 secs
epoch: 366, test val_loss: 0.141986
epoch: 366, train loss: 464.5440, lr: 0.000100, spent: 80616.7 secs
epoch: 367, test val_loss: 0.141986
epoch: 367, train loss: 464.5404, lr: 0.000100, spent: 80833.9 secs
epoch: 368, test val_loss: 0.141986
epoch: 368, train loss: 464.5404, lr: 0.000100, spent: 81051.8 secs
epoch: 369, test val_loss: 0.141986
epoch: 369, train loss: 464.5398, lr: 0.000100, spent: 81268.9 secs
epoch: 370, test val_loss: 0.141986
epoch: 370, train loss: 464.4294, lr: 0.000100, spent: 81485.4 secs
epoch: 371, test val_loss: 0.141986
epoch: 371, train loss: 464.4294, lr: 0.000100, spent: 81702.7 secs
epoch: 372, test val_loss: 0.141986
epoch: 372, train loss: 464.4300, lr: 0.000100, spent: 81920.6 secs
epoch: 373, test val_loss: 0.141986
epoch: 373, train loss: 464.6496, lr: 0.000100, spent: 82138.7 secs
epoch: 374, test val_loss: 0.141986
epoch: 374, train loss: 464.4294, lr: 0.000100, spent: 82355.7 secs
epoch: 375, test val_loss: 0.141986
epoch: 375, train loss: 464.5398, lr: 0.000100, spent: 82573.5 secs
epoch: 376, test val_loss: 0.141986
epoch: 376, train loss: 464.4300, lr: 0.000100, spent: 82790.8 secs
epoch: 377, test val_loss: 0.141986
epoch: 377, train loss: 464.4300, lr: 0.000100, spent: 83008.5 secs
epoch: 378, test val_loss: 0.141986
epoch: 378, train loss: 464.6502, lr: 0.000100, spent: 83226.2 secs
epoch: 379, test val_loss: 0.141986
epoch: 379, train loss: 464.5404, lr: 0.000100, spent: 83444.2 secs
epoch: 380, test val_loss: 0.141986
epoch: 380, train loss: 464.5416, lr: 0.000100, spent: 83661.6 secs
epoch: 381, test val_loss: 0.141986
epoch: 381, train loss: 464.5404, lr: 0.000100, spent: 83878.6 secs
epoch: 382, test val_loss: 0.141986
epoch: 382, train loss: 464.4317, lr: 0.000100, spent: 84094.5 secs
epoch: 383, test val_loss: 0.141986
epoch: 383, train loss: 464.5404, lr: 0.000100, spent: 84312.1 secs
epoch: 384, test val_loss: 0.141986
epoch: 384, train loss: 464.4300, lr: 0.000100, spent: 84529.7 secs
epoch: 385, test val_loss: 0.141986
epoch: 385, train loss: 464.4306, lr: 0.000100, spent: 84748.0 secs
epoch: 386, test val_loss: 0.141986
epoch: 386, train loss: 464.5404, lr: 0.000100, spent: 84966.0 secs
epoch: 387, test val_loss: 0.141986
epoch: 387, train loss: 464.5404, lr: 0.000100, spent: 85182.9 secs
epoch: 388, test val_loss: 0.141986
epoch: 388, train loss: 464.5392, lr: 0.000100, spent: 85401.5 secs
epoch: 389, test val_loss: 0.141986
epoch: 389, train loss: 464.5404, lr: 0.000100, spent: 85618.9 secs
epoch: 390, test val_loss: 0.141986
epoch: 390, train loss: 464.6526, lr: 0.000100, spent: 85837.5 secs
epoch: 391, test val_loss: 0.141986
epoch: 391, train loss: 464.6502, lr: 0.000100, spent: 86055.7 secs
epoch: 392, test val_loss: 0.141986
epoch: 392, train loss: 464.6502, lr: 0.000100, spent: 86272.5 secs
epoch: 393, test val_loss: 0.141986
epoch: 393, train loss: 464.5422, lr: 0.000100, spent: 86490.3 secs
epoch: 394, test val_loss: 0.141986
epoch: 394, train loss: 464.4294, lr: 0.000100, spent: 86707.4 secs
epoch: 395, test val_loss: 0.141986
epoch: 395, train loss: 464.5398, lr: 0.000100, spent: 86923.8 secs
epoch: 396, test val_loss: 0.141986
epoch: 396, train loss: 464.6514, lr: 0.000100, spent: 87140.1 secs
epoch: 397, test val_loss: 0.141986
epoch: 397, train loss: 464.5410, lr: 0.000100, spent: 87356.0 secs
epoch: 398, test val_loss: 0.141986
epoch: 398, train loss: 464.4294, lr: 0.000100, spent: 87572.8 secs
epoch: 399, test val_loss: 0.141986
epoch: 399, train loss: 464.6514, lr: 0.000100, spent: 87790.0 secs
epoch: 400, test val_loss: 0.141986
epoch: 400, train loss: 464.4306, lr: 0.000100, spent: 88005.8 secs
epoch: 401, test val_loss: 0.141986
epoch: 401, train loss: 464.4288, lr: 0.000100, spent: 88222.2 secs
epoch: 402, test val_loss: 0.141986
epoch: 402, train loss: 464.5398, lr: 0.000100, spent: 88438.5 secs
epoch: 403, test val_loss: 0.141986
epoch: 403, train loss: 464.4306, lr: 0.000100, spent: 88655.3 secs
epoch: 404, test val_loss: 0.141986
epoch: 404, train loss: 464.4306, lr: 0.000100, spent: 88872.4 secs
epoch: 405, test val_loss: 0.141986
epoch: 405, train loss: 464.7600, lr: 0.000100, spent: 89087.7 secs
epoch: 406, test val_loss: 0.141986
epoch: 406, train loss: 464.7642, lr: 0.000100, spent: 89304.6 secs
epoch: 407, test val_loss: 0.141986
epoch: 407, train loss: 464.4294, lr: 0.000100, spent: 89521.8 secs
epoch: 408, test val_loss: 0.141986
epoch: 408, train loss: 464.6514, lr: 0.000100, spent: 89738.6 secs
epoch: 409, test val_loss: 0.141986
epoch: 409, train loss: 464.4300, lr: 0.000100, spent: 89955.2 secs
epoch: 410, test val_loss: 0.141986
epoch: 410, train loss: 464.4312, lr: 0.000100, spent: 90172.2 secs
epoch: 411, test val_loss: 0.141986
epoch: 411, train loss: 464.4288, lr: 0.000100, spent: 90389.0 secs
epoch: 412, test val_loss: 0.141986
epoch: 412, train loss: 464.8705, lr: 0.000100, spent: 90606.1 secs
epoch: 413, test val_loss: 0.141986
epoch: 413, train loss: 464.4300, lr: 0.000100, spent: 90823.4 secs
epoch: 414, test val_loss: 0.141986
epoch: 414, train loss: 464.5398, lr: 0.000100, spent: 91039.9 secs
epoch: 415, test val_loss: 0.141986
epoch: 415, train loss: 464.5404, lr: 0.000100, spent: 91256.5 secs
epoch: 416, test val_loss: 0.141986
epoch: 416, train loss: 464.5392, lr: 0.000100, spent: 91473.3 secs
epoch: 417, test val_loss: 0.141986
epoch: 417, train loss: 464.4300, lr: 0.000100, spent: 91690.1 secs
epoch: 418, test val_loss: 0.141986
epoch: 418, train loss: 464.4306, lr: 0.000100, spent: 91907.3 secs
epoch: 419, test val_loss: 0.141986
epoch: 419, train loss: 464.4306, lr: 0.000100, spent: 92124.5 secs
epoch: 420, test val_loss: 0.141986
epoch: 420, train loss: 464.4300, lr: 0.000100, spent: 92341.5 secs
epoch: 421, test val_loss: 0.141986
epoch: 421, train loss: 464.4306, lr: 0.000100, spent: 92558.3 secs
epoch: 422, test val_loss: 0.141986
epoch: 422, train loss: 464.4306, lr: 0.000100, spent: 92774.9 secs
epoch: 423, test val_loss: 0.141986
epoch: 423, train loss: 464.5404, lr: 0.000100, spent: 92990.4 secs
epoch: 424, test val_loss: 0.141986
epoch: 424, train loss: 464.4312, lr: 0.000100, spent: 93207.2 secs
epoch: 425, test val_loss: 0.141986
epoch: 425, train loss: 464.4300, lr: 0.000100, spent: 93424.3 secs
epoch: 426, test val_loss: 0.141986
epoch: 426, train loss: 464.4300, lr: 0.000100, spent: 93641.0 secs
epoch: 427, test val_loss: 0.141986
epoch: 427, train loss: 464.4306, lr: 0.000100, spent: 93857.7 secs
epoch: 428, test val_loss: 0.141986
epoch: 428, train loss: 464.6508, lr: 0.000100, spent: 94074.4 secs
epoch: 429, test val_loss: 0.141986
epoch: 429, train loss: 464.4300, lr: 0.000100, spent: 94289.8 secs
epoch: 430, test val_loss: 0.141986
epoch: 430, train loss: 464.4323, lr: 0.000100, spent: 94506.1 secs
epoch: 431, test val_loss: 0.141986
epoch: 431, train loss: 464.4294, lr: 0.000100, spent: 94722.2 secs
epoch: 432, test val_loss: 0.141986
epoch: 432, train loss: 464.4294, lr: 0.000100, spent: 94937.4 secs
epoch: 433, test val_loss: 0.141986
epoch: 433, train loss: 464.6508, lr: 0.000100, spent: 95154.0 secs
epoch: 434, test val_loss: 0.141986
epoch: 434, train loss: 464.4294, lr: 0.000100, spent: 95371.2 secs
epoch: 435, test val_loss: 0.141986
epoch: 435, train loss: 464.5404, lr: 0.000100, spent: 95588.5 secs
epoch: 436, test val_loss: 0.141986
epoch: 436, train loss: 464.4294, lr: 0.000100, spent: 95805.9 secs
epoch: 437, test val_loss: 0.141986
epoch: 437, train loss: 464.4306, lr: 0.000100, spent: 96023.2 secs
epoch: 438, test val_loss: 0.141986
epoch: 438, train loss: 464.5392, lr: 0.000100, spent: 96239.6 secs
epoch: 439, test val_loss: 0.141986
epoch: 439, train loss: 464.4294, lr: 0.000100, spent: 96456.4 secs
epoch: 440, test val_loss: 0.141986
epoch: 440, train loss: 464.5410, lr: 0.000100, spent: 96673.1 secs
epoch: 441, test val_loss: 0.141986
epoch: 441, train loss: 464.5404, lr: 0.000100, spent: 96890.8 secs
epoch: 442, test val_loss: 0.141986
epoch: 442, train loss: 464.6508, lr: 0.000100, spent: 97108.8 secs
epoch: 443, test val_loss: 0.141986
epoch: 443, train loss: 464.7612, lr: 0.000100, spent: 97326.6 secs
epoch: 444, test val_loss: 0.141986
epoch: 444, train loss: 464.4294, lr: 0.000100, spent: 97544.3 secs
epoch: 445, test val_loss: 0.141986
epoch: 445, train loss: 464.5398, lr: 0.000100, spent: 97762.0 secs
epoch: 446, test val_loss: 0.141986
epoch: 446, train loss: 464.6502, lr: 0.000100, spent: 97979.5 secs
epoch: 447, test val_loss: 0.141986
epoch: 447, train loss: 464.4288, lr: 0.000100, spent: 98196.4 secs
epoch: 448, test val_loss: 0.141986
epoch: 448, train loss: 464.5404, lr: 0.000100, spent: 98413.5 secs
epoch: 449, test val_loss: 0.141986
epoch: 449, train loss: 464.5398, lr: 0.000100, spent: 98631.6 secs
epoch: 450, test val_loss: 0.141986
epoch: 450, train loss: 464.4306, lr: 0.000100, spent: 98848.9 secs
epoch: 451, test val_loss: 0.141986
epoch: 451, train loss: 464.7624, lr: 0.000100, spent: 99066.3 secs
epoch: 452, test val_loss: 0.141986
epoch: 452, train loss: 464.5404, lr: 0.000100, spent: 99283.5 secs
epoch: 453, test val_loss: 0.141986
epoch: 453, train loss: 464.5410, lr: 0.000100, spent: 99500.8 secs
epoch: 454, test val_loss: 0.141986
epoch: 454, train loss: 464.6502, lr: 0.000100, spent: 99719.0 secs
epoch: 455, test val_loss: 0.141986
epoch: 455, train loss: 464.4312, lr: 0.000100, spent: 99936.7 secs
epoch: 456, test val_loss: 0.141986
epoch: 456, train loss: 464.5398, lr: 0.000100, spent: 100154.6 secs
epoch: 457, test val_loss: 0.141986
epoch: 457, train loss: 464.6496, lr: 0.000100, spent: 100372.5 secs
epoch: 458, test val_loss: 0.141986
epoch: 458, train loss: 464.5404, lr: 0.000100, spent: 100589.9 secs
epoch: 459, test val_loss: 0.141986
epoch: 459, train loss: 464.5392, lr: 0.000100, spent: 100805.9 secs
epoch: 460, test val_loss: 0.141986
epoch: 460, train loss: 464.5392, lr: 0.000100, spent: 101022.3 secs
epoch: 461, test val_loss: 0.141986
epoch: 461, train loss: 464.4294, lr: 0.000100, spent: 101239.3 secs
epoch: 462, test val_loss: 0.141986
epoch: 462, train loss: 464.5428, lr: 0.000100, spent: 101457.3 secs
epoch: 463, test val_loss: 0.141986
epoch: 463, train loss: 464.4288, lr: 0.000100, spent: 101675.0 secs
epoch: 464, test val_loss: 0.141986
epoch: 464, train loss: 464.4300, lr: 0.000100, spent: 101892.7 secs
epoch: 465, test val_loss: 0.141986
epoch: 465, train loss: 464.7612, lr: 0.000100, spent: 102110.7 secs
epoch: 466, test val_loss: 0.141986
epoch: 466, train loss: 464.4300, lr: 0.000100, spent: 102328.0 secs
epoch: 467, test val_loss: 0.141986
epoch: 467, train loss: 464.5410, lr: 0.000100, spent: 102544.6 secs
epoch: 468, test val_loss: 0.141986
epoch: 468, train loss: 464.5410, lr: 0.000100, spent: 102762.1 secs
epoch: 469, test val_loss: 0.141986
epoch: 469, train loss: 464.5404, lr: 0.000100, spent: 102979.7 secs
epoch: 470, test val_loss: 0.141986
epoch: 470, train loss: 464.5404, lr: 0.000100, spent: 103198.0 secs
epoch: 471, test val_loss: 0.141986
epoch: 471, train loss: 464.4294, lr: 0.000100, spent: 103414.9 secs
epoch: 472, test val_loss: 0.141986
epoch: 472, train loss: 464.5398, lr: 0.000100, spent: 103631.2 secs
epoch: 473, test val_loss: 0.141986
epoch: 473, train loss: 464.6514, lr: 0.000100, spent: 103848.2 secs
epoch: 474, test val_loss: 0.141986
epoch: 474, train loss: 464.4294, lr: 0.000100, spent: 104065.1 secs
epoch: 475, test val_loss: 0.141986
epoch: 475, train loss: 464.4300, lr: 0.000100, spent: 104281.2 secs
epoch: 476, test val_loss: 0.141986
epoch: 476, train loss: 464.6508, lr: 0.000100, spent: 104497.7 secs
epoch: 477, test val_loss: 0.141986
epoch: 477, train loss: 464.4288, lr: 0.000100, spent: 104713.7 secs
epoch: 478, test val_loss: 0.141986
epoch: 478, train loss: 464.4306, lr: 0.000100, spent: 104930.8 secs
epoch: 479, test val_loss: 0.141986
epoch: 479, train loss: 464.7606, lr: 0.000100, spent: 105147.5 secs
epoch: 480, test val_loss: 0.141986
epoch: 480, train loss: 464.4300, lr: 0.000100, spent: 105364.4 secs
epoch: 481, test val_loss: 0.141986
epoch: 481, train loss: 464.4288, lr: 0.000100, spent: 105580.7 secs
epoch: 482, test val_loss: 0.141986
epoch: 482, train loss: 464.4294, lr: 0.000100, spent: 105797.6 secs
epoch: 483, test val_loss: 0.141986
epoch: 483, train loss: 464.7600, lr: 0.000100, spent: 106014.9 secs
epoch: 484, test val_loss: 0.141986
epoch: 484, train loss: 464.5398, lr: 0.000100, spent: 106229.8 secs
epoch: 485, test val_loss: 0.141986
epoch: 485, train loss: 464.4288, lr: 0.000100, spent: 106446.3 secs
epoch: 486, test val_loss: 0.141986
epoch: 486, train loss: 464.5410, lr: 0.000100, spent: 106663.2 secs
epoch: 487, test val_loss: 0.141986
epoch: 487, train loss: 464.4288, lr: 0.000100, spent: 106880.2 secs
epoch: 488, test val_loss: 0.141986
epoch: 488, train loss: 464.5404, lr: 0.000100, spent: 107097.3 secs
epoch: 489, test val_loss: 0.141986
epoch: 489, train loss: 464.7606, lr: 0.000100, spent: 107314.4 secs
epoch: 490, test val_loss: 0.141986
epoch: 490, train loss: 464.4323, lr: 0.000100, spent: 107531.1 secs
epoch: 491, test val_loss: 0.141986
epoch: 491, train loss: 464.6496, lr: 0.000100, spent: 107747.7 secs
epoch: 492, test val_loss: 0.141986
epoch: 492, train loss: 464.4306, lr: 0.000100, spent: 107964.5 secs
epoch: 493, test val_loss: 0.141986
epoch: 493, train loss: 464.5392, lr: 0.000100, spent: 108182.5 secs
epoch: 494, test val_loss: 0.141986
epoch: 494, train loss: 464.5398, lr: 0.000100, spent: 108400.1 secs
epoch: 495, test val_loss: 0.141986
epoch: 495, train loss: 464.4288, lr: 0.000100, spent: 108616.6 secs
epoch: 496, test val_loss: 0.141986
epoch: 496, train loss: 464.6508, lr: 0.000100, spent: 108833.1 secs
epoch: 497, test val_loss: 0.141986
epoch: 497, train loss: 464.5404, lr: 0.000100, spent: 109047.7 secs
epoch: 498, test val_loss: 0.141986
epoch: 498, train loss: 464.4294, lr: 0.000100, spent: 109265.4 secs
epoch: 499, test val_loss: 0.141986
epoch: 499, train loss: 464.5398, lr: 0.000100, spent: 109482.9 secs
epoch: 500, test val_loss: 0.141986
epoch: 500, train loss: 464.6496, lr: 0.000100, spent: 109700.6 secs
epoch: 501, test val_loss: 0.141986
epoch: 501, train loss: 464.4300, lr: 0.000100, spent: 109918.2 secs
epoch: 502, test val_loss: 0.141986
epoch: 502, train loss: 464.4294, lr: 0.000100, spent: 110135.6 secs
epoch: 503, test val_loss: 0.141986
epoch: 503, train loss: 464.5398, lr: 0.000100, spent: 110353.8 secs
epoch: 504, test val_loss: 0.141986
epoch: 504, train loss: 464.4294, lr: 0.000100, spent: 110571.4 secs
epoch: 505, test val_loss: 0.141986
epoch: 505, train loss: 464.5422, lr: 0.000100, spent: 110788.8 secs
epoch: 506, test val_loss: 0.141986
epoch: 506, train loss: 464.4288, lr: 0.000100, spent: 111006.4 secs
epoch: 507, test val_loss: 0.141986
epoch: 507, train loss: 464.4288, lr: 0.000100, spent: 111223.6 secs
epoch: 508, test val_loss: 0.141986
epoch: 508, train loss: 464.4288, lr: 0.000100, spent: 111440.8 secs
epoch: 509, test val_loss: 0.141986
epoch: 509, train loss: 464.6508, lr: 0.000100, spent: 111657.1 secs
epoch: 510, test val_loss: 0.141986
epoch: 510, train loss: 464.5416, lr: 0.000100, spent: 111872.6 secs
epoch: 511, test val_loss: 0.141986
epoch: 511, train loss: 464.4288, lr: 0.000100, spent: 112089.4 secs
epoch: 512, test val_loss: 0.141986
epoch: 512, train loss: 464.6526, lr: 0.000100, spent: 112306.5 secs
epoch: 513, test val_loss: 0.141986
epoch: 513, train loss: 464.4294, lr: 0.000100, spent: 112523.5 secs
epoch: 514, test val_loss: 0.141986
epoch: 514, train loss: 464.5410, lr: 0.000100, spent: 112740.1 secs
epoch: 515, test val_loss: 0.141986
epoch: 515, train loss: 464.5398, lr: 0.000100, spent: 112957.5 secs
epoch: 516, test val_loss: 0.141986
epoch: 516, train loss: 464.4312, lr: 0.000100, spent: 113175.3 secs
epoch: 517, test val_loss: 0.141986
epoch: 517, train loss: 464.5410, lr: 0.000100, spent: 113392.9 secs
epoch: 518, test val_loss: 0.141986
epoch: 518, train loss: 464.4306, lr: 0.000100, spent: 113609.8 secs
epoch: 519, test val_loss: 0.141986
epoch: 519, train loss: 464.5398, lr: 0.000100, spent: 113827.1 secs
epoch: 520, test val_loss: 0.141986
epoch: 520, train loss: 464.4306, lr: 0.000100, spent: 114044.6 secs
epoch: 521, test val_loss: 0.141986
epoch: 521, train loss: 464.4300, lr: 0.000100, spent: 114262.1 secs
epoch: 522, test val_loss: 0.141986
epoch: 522, train loss: 464.5416, lr: 0.000100, spent: 114479.4 secs
epoch: 523, test val_loss: 0.141986
epoch: 523, train loss: 464.5392, lr: 0.000100, spent: 114696.8 secs
epoch: 524, test val_loss: 0.141986
epoch: 524, train loss: 464.4300, lr: 0.000100, spent: 114913.5 secs
epoch: 525, test val_loss: 0.141986
epoch: 525, train loss: 464.5445, lr: 0.000100, spent: 115130.7 secs
epoch: 526, test val_loss: 0.141986
epoch: 526, train loss: 464.5410, lr: 0.000100, spent: 115348.0 secs
epoch: 527, test val_loss: 0.141986
epoch: 527, train loss: 464.4288, lr: 0.000100, spent: 115565.5 secs
epoch: 528, test val_loss: 0.141986
epoch: 528, train loss: 464.4306, lr: 0.000100, spent: 115783.0 secs
epoch: 529, test val_loss: 0.141986
epoch: 529, train loss: 464.5398, lr: 0.000100, spent: 116000.2 secs
epoch: 530, test val_loss: 0.141986
epoch: 530, train loss: 464.5404, lr: 0.000100, spent: 116217.7 secs
epoch: 531, test val_loss: 0.141986
epoch: 531, train loss: 464.4300, lr: 0.000100, spent: 116434.9 secs
epoch: 532, test val_loss: 0.141986
epoch: 532, train loss: 464.4288, lr: 0.000100, spent: 116652.3 secs
epoch: 533, test val_loss: 0.141986
epoch: 533, train loss: 464.4300, lr: 0.000100, spent: 116869.6 secs
epoch: 534, test val_loss: 0.141986
epoch: 534, train loss: 464.4288, lr: 0.000100, spent: 117086.9 secs
epoch: 535, test val_loss: 0.141986
epoch: 535, train loss: 464.4312, lr: 0.000100, spent: 117303.4 secs
epoch: 536, test val_loss: 0.141986
epoch: 536, train loss: 464.4288, lr: 0.000100, spent: 117520.5 secs
epoch: 537, test val_loss: 0.141986
epoch: 537, train loss: 464.4288, lr: 0.000100, spent: 117738.7 secs
epoch: 538, test val_loss: 0.141986
epoch: 538, train loss: 464.4294, lr: 0.000100, spent: 117955.0 secs
epoch: 539, test val_loss: 0.141986
epoch: 539, train loss: 464.5398, lr: 0.000100, spent: 118171.2 secs
epoch: 540, test val_loss: 0.141986
epoch: 540, train loss: 464.8717, lr: 0.000100, spent: 118388.0 secs
epoch: 541, test val_loss: 0.141986
epoch: 541, train loss: 464.4294, lr: 0.000100, spent: 118604.2 secs
epoch: 542, test val_loss: 0.141986
epoch: 542, train loss: 464.5416, lr: 0.000100, spent: 118821.6 secs
epoch: 543, test val_loss: 0.141986
epoch: 543, train loss: 464.4306, lr: 0.000100, spent: 119039.0 secs
epoch: 544, test val_loss: 0.141986
epoch: 544, train loss: 464.6502, lr: 0.000100, spent: 119255.8 secs
epoch: 545, test val_loss: 0.141986
epoch: 545, train loss: 464.4294, lr: 0.000100, spent: 119473.2 secs
epoch: 546, test val_loss: 0.141986
epoch: 546, train loss: 464.6514, lr: 0.000100, spent: 119691.3 secs
epoch: 547, test val_loss: 0.141986
epoch: 547, train loss: 464.5398, lr: 0.000100, spent: 119909.1 secs
epoch: 548, test val_loss: 0.141986
epoch: 548, train loss: 464.5410, lr: 0.000100, spent: 120126.2 secs
epoch: 549, test val_loss: 0.141986
epoch: 549, train loss: 464.5398, lr: 0.000100, spent: 120343.1 secs
epoch: 550, test val_loss: 0.141986
epoch: 550, train loss: 464.5410, lr: 0.000100, spent: 120560.5 secs
epoch: 551, test val_loss: 0.141986
epoch: 551, train loss: 464.6502, lr: 0.000100, spent: 120777.2 secs
epoch: 552, test val_loss: 0.141986
epoch: 552, train loss: 464.5404, lr: 0.000100, spent: 120994.1 secs
epoch: 553, test val_loss: 0.141986
epoch: 553, train loss: 464.5410, lr: 0.000100, spent: 121206.9 secs
epoch: 554, test val_loss: 0.141986
epoch: 554, train loss: 464.5398, lr: 0.000100, spent: 121423.3 secs
epoch: 555, test val_loss: 0.141986
epoch: 555, train loss: 464.5410, lr: 0.000100, spent: 121640.6 secs
epoch: 556, test val_loss: 0.141986
epoch: 556, train loss: 464.5398, lr: 0.000100, spent: 121858.5 secs
epoch: 557, test val_loss: 0.141986
epoch: 557, train loss: 464.7606, lr: 0.000100, spent: 122075.4 secs
epoch: 558, test val_loss: 0.141986
epoch: 558, train loss: 464.4288, lr: 0.000100, spent: 122292.6 secs
epoch: 559, test val_loss: 0.141986
epoch: 559, train loss: 464.4294, lr: 0.000100, spent: 122509.8 secs
epoch: 560, test val_loss: 0.141986
epoch: 560, train loss: 464.4300, lr: 0.000100, spent: 122728.0 secs
epoch: 561, test val_loss: 0.141986
epoch: 561, train loss: 464.5398, lr: 0.000100, spent: 122946.5 secs
epoch: 562, test val_loss: 0.141986
epoch: 562, train loss: 464.4300, lr: 0.000100, spent: 123164.0 secs
epoch: 563, test val_loss: 0.141986
epoch: 563, train loss: 464.5398, lr: 0.000100, spent: 123381.6 secs
epoch: 564, test val_loss: 0.141986
epoch: 564, train loss: 464.6532, lr: 0.000100, spent: 123599.7 secs
epoch: 565, test val_loss: 0.141986
epoch: 565, train loss: 464.6496, lr: 0.000100, spent: 123817.2 secs
epoch: 566, test val_loss: 0.141986
epoch: 566, train loss: 464.5404, lr: 0.000100, spent: 124034.2 secs
epoch: 567, test val_loss: 0.141986
epoch: 567, train loss: 464.4300, lr: 0.000100, spent: 124250.6 secs
epoch: 568, test val_loss: 0.141986
epoch: 568, train loss: 464.4323, lr: 0.000100, spent: 124466.7 secs
epoch: 569, test val_loss: 0.141986
epoch: 569, train loss: 464.4288, lr: 0.000100, spent: 124683.8 secs
epoch: 570, test val_loss: 0.141986
epoch: 570, train loss: 464.4294, lr: 0.000100, spent: 124901.7 secs
epoch: 571, test val_loss: 0.141986
epoch: 571, train loss: 464.4294, lr: 0.000100, spent: 125119.8 secs
epoch: 572, test val_loss: 0.141986
epoch: 572, train loss: 464.4294, lr: 0.000100, spent: 125337.1 secs
epoch: 573, test val_loss: 0.141986
epoch: 573, train loss: 464.5416, lr: 0.000100, spent: 125553.4 secs
epoch: 574, test val_loss: 0.141986
epoch: 574, train loss: 464.5404, lr: 0.000100, spent: 125770.2 secs
epoch: 575, test val_loss: 0.141986
epoch: 575, train loss: 464.4312, lr: 0.000100, spent: 125987.1 secs
epoch: 576, test val_loss: 0.141986
epoch: 576, train loss: 464.6502, lr: 0.000100, spent: 126202.3 secs
epoch: 577, test val_loss: 0.141986
epoch: 577, train loss: 464.5410, lr: 0.000100, spent: 126419.7 secs
epoch: 578, test val_loss: 0.141986
epoch: 578, train loss: 464.4300, lr: 0.000100, spent: 126636.8 secs
epoch: 579, test val_loss: 0.141986
epoch: 579, train loss: 464.4294, lr: 0.000100, spent: 126853.7 secs
epoch: 580, test val_loss: 0.141986
epoch: 580, train loss: 464.4288, lr: 0.000100, spent: 127070.7 secs
epoch: 581, test val_loss: 0.141986
epoch: 581, train loss: 464.5398, lr: 0.000100, spent: 127287.2 secs
epoch: 582, test val_loss: 0.141986
epoch: 582, train loss: 464.7606, lr: 0.000100, spent: 127503.7 secs
epoch: 583, test val_loss: 0.141986
epoch: 583, train loss: 464.5392, lr: 0.000100, spent: 127720.9 secs
epoch: 584, test val_loss: 0.141986
epoch: 584, train loss: 464.4312, lr: 0.000100, spent: 127938.0 secs
epoch: 585, test val_loss: 0.141986
epoch: 585, train loss: 464.5410, lr: 0.000100, spent: 128153.3 secs
epoch: 586, test val_loss: 0.141986
epoch: 586, train loss: 464.6502, lr: 0.000100, spent: 128370.8 secs
epoch: 587, test val_loss: 0.141986
epoch: 587, train loss: 464.4294, lr: 0.000100, spent: 128586.7 secs
epoch: 588, test val_loss: 0.141986
epoch: 588, train loss: 464.4294, lr: 0.000100, spent: 128803.4 secs
epoch: 589, test val_loss: 0.141986
epoch: 589, train loss: 464.5410, lr: 0.000100, spent: 129019.6 secs
epoch: 590, test val_loss: 0.141986
epoch: 590, train loss: 464.5404, lr: 0.000100, spent: 129236.5 secs
epoch: 591, test val_loss: 0.141986
epoch: 591, train loss: 464.5416, lr: 0.000100, spent: 129454.0 secs
epoch: 592, test val_loss: 0.141986
epoch: 592, train loss: 464.4306, lr: 0.000100, spent: 129671.7 secs
epoch: 593, test val_loss: 0.141986
epoch: 593, train loss: 464.6520, lr: 0.000100, spent: 129889.2 secs
epoch: 594, test val_loss: 0.141986
epoch: 594, train loss: 464.5392, lr: 0.000100, spent: 130107.1 secs
epoch: 595, test val_loss: 0.141986
epoch: 595, train loss: 464.5404, lr: 0.000100, spent: 130322.8 secs
epoch: 596, test val_loss: 0.141986
epoch: 596, train loss: 464.4306, lr: 0.000100, spent: 130540.4 secs
epoch: 597, test val_loss: 0.141986
epoch: 597, train loss: 464.4306, lr: 0.000100, spent: 130757.7 secs
epoch: 598, test val_loss: 0.141986
epoch: 598, train loss: 464.5398, lr: 0.000100, spent: 130974.2 secs
epoch: 599, test val_loss: 0.141986
epoch: 599, train loss: 464.4294, lr: 0.000100, spent: 131191.2 secs
epoch: 600, test val_loss: 0.141986
epoch: 600, train loss: 464.6508, lr: 0.000100, spent: 131407.8 secs
epoch: 601, test val_loss: 0.141986
epoch: 601, train loss: 464.6502, lr: 0.000100, spent: 131622.0 secs
epoch: 602, test val_loss: 0.141986
epoch: 602, train loss: 464.4294, lr: 0.000100, spent: 131839.5 secs
epoch: 603, test val_loss: 0.141986
epoch: 603, train loss: 464.4300, lr: 0.000100, spent: 132056.3 secs
epoch: 604, test val_loss: 0.141986
epoch: 604, train loss: 464.4300, lr: 0.000100, spent: 132273.0 secs
epoch: 605, test val_loss: 0.141986
epoch: 605, train loss: 464.5398, lr: 0.000100, spent: 132490.0 secs
epoch: 606, test val_loss: 0.141986
epoch: 606, train loss: 464.5398, lr: 0.000100, spent: 132707.5 secs
epoch: 607, test val_loss: 0.141986
epoch: 607, train loss: 464.4311, lr: 0.000100, spent: 132924.1 secs
epoch: 608, test val_loss: 0.141986
epoch: 608, train loss: 464.6514, lr: 0.000100, spent: 133141.1 secs
epoch: 609, test val_loss: 0.141986
epoch: 609, train loss: 464.5398, lr: 0.000100, spent: 133358.1 secs
epoch: 610, test val_loss: 0.141986
epoch: 610, train loss: 464.5422, lr: 0.000100, spent: 133575.0 secs
epoch: 611, test val_loss: 0.141986
epoch: 611, train loss: 464.4317, lr: 0.000100, spent: 133792.0 secs
epoch: 612, test val_loss: 0.141986
epoch: 612, train loss: 464.4306, lr: 0.000100, spent: 134009.0 secs
epoch: 613, test val_loss: 0.141986
epoch: 613, train loss: 464.5404, lr: 0.000100, spent: 134226.0 secs
epoch: 614, test val_loss: 0.141986
epoch: 614, train loss: 464.5398, lr: 0.000100, spent: 134443.1 secs
epoch: 615, test val_loss: 0.141986
epoch: 615, train loss: 464.4300, lr: 0.000100, spent: 134660.3 secs
epoch: 616, test val_loss: 0.141986
epoch: 616, train loss: 464.4300, lr: 0.000100, spent: 134877.0 secs
epoch: 617, test val_loss: 0.141986
epoch: 617, train loss: 464.7618, lr: 0.000100, spent: 135093.8 secs
epoch: 618, test val_loss: 0.141986
epoch: 618, train loss: 464.4294, lr: 0.000100, spent: 135310.8 secs
epoch: 619, test val_loss: 0.141986
epoch: 619, train loss: 464.7624, lr: 0.000100, spent: 135528.3 secs
epoch: 620, test val_loss: 0.141986
epoch: 620, train loss: 464.5392, lr: 0.000100, spent: 135745.8 secs
epoch: 621, test val_loss: 0.141986
epoch: 621, train loss: 464.5398, lr: 0.000100, spent: 135962.8 secs
epoch: 622, test val_loss: 0.141986
epoch: 622, train loss: 464.4288, lr: 0.000100, spent: 136179.6 secs
epoch: 623, test val_loss: 0.141986
epoch: 623, train loss: 464.6514, lr: 0.000100, spent: 136396.5 secs
epoch: 624, test val_loss: 0.141986
epoch: 624, train loss: 464.4300, lr: 0.000100, spent: 136614.0 secs
epoch: 625, test val_loss: 0.141986
epoch: 625, train loss: 464.5410, lr: 0.000100, spent: 136831.0 secs
epoch: 626, test val_loss: 0.141986
epoch: 626, train loss: 464.4306, lr: 0.000100, spent: 137047.0 secs
epoch: 627, test val_loss: 0.141986
epoch: 627, train loss: 464.5410, lr: 0.000100, spent: 137264.0 secs
epoch: 628, test val_loss: 0.141986
epoch: 628, train loss: 464.5398, lr: 0.000100, spent: 137480.7 secs
epoch: 629, test val_loss: 0.141986
epoch: 629, train loss: 464.4300, lr: 0.000100, spent: 137697.5 secs
epoch: 630, test val_loss: 0.141986
epoch: 630, train loss: 464.6514, lr: 0.000100, spent: 137914.2 secs
epoch: 631, test val_loss: 0.141986
epoch: 631, train loss: 464.6502, lr: 0.000100, spent: 138130.7 secs
epoch: 632, test val_loss: 0.141986
epoch: 632, train loss: 464.4300, lr: 0.000100, spent: 138348.0 secs
epoch: 633, test val_loss: 0.141986
epoch: 633, train loss: 464.4312, lr: 0.000100, spent: 138566.0 secs
epoch: 634, test val_loss: 0.141986
epoch: 634, train loss: 464.5404, lr: 0.000100, spent: 138784.3 secs
epoch: 635, test val_loss: 0.141986
epoch: 635, train loss: 464.4288, lr: 0.000100, spent: 139001.2 secs
epoch: 636, test val_loss: 0.141986
epoch: 636, train loss: 464.5404, lr: 0.000100, spent: 139218.2 secs
epoch: 637, test val_loss: 0.141986
epoch: 637, train loss: 464.4294, lr: 0.000100, spent: 139435.3 secs
epoch: 638, test val_loss: 0.141986
epoch: 638, train loss: 464.6502, lr: 0.000100, spent: 139651.8 secs
epoch: 639, test val_loss: 0.141986
epoch: 639, train loss: 464.4300, lr: 0.000100, spent: 139868.6 secs
epoch: 640, test val_loss: 0.141986
epoch: 640, train loss: 464.6514, lr: 0.000100, spent: 140085.6 secs
epoch: 641, test val_loss: 0.141986
epoch: 641, train loss: 464.5398, lr: 0.000100, spent: 140302.3 secs
epoch: 642, test val_loss: 0.141986
epoch: 642, train loss: 464.5410, lr: 0.000100, spent: 140518.8 secs
epoch: 643, test val_loss: 0.141986
epoch: 643, train loss: 464.4294, lr: 0.000100, spent: 140735.5 secs
epoch: 644, test val_loss: 0.141986
epoch: 644, train loss: 464.4306, lr: 0.000100, spent: 140952.3 secs
epoch: 645, test val_loss: 0.141986
epoch: 645, train loss: 464.5392, lr: 0.000100, spent: 141169.0 secs
epoch: 646, test val_loss: 0.141986
epoch: 646, train loss: 464.4300, lr: 0.000100, spent: 141386.5 secs
epoch: 647, test val_loss: 0.141986
epoch: 647, train loss: 464.5398, lr: 0.000100, spent: 141603.7 secs
epoch: 648, test val_loss: 0.141986
epoch: 648, train loss: 464.4312, lr: 0.000100, spent: 141820.9 secs
epoch: 649, test val_loss: 0.141986
epoch: 649, train loss: 464.4306, lr: 0.000100, spent: 142037.6 secs
epoch: 650, test val_loss: 0.141986
epoch: 650, train loss: 464.5404, lr: 0.000100, spent: 142255.7 secs
epoch: 651, test val_loss: 0.141986
epoch: 651, train loss: 464.4312, lr: 0.000100, spent: 142472.4 secs
epoch: 652, test val_loss: 0.141986
epoch: 652, train loss: 464.6508, lr: 0.000100, spent: 142687.8 secs
epoch: 653, test val_loss: 0.141986
epoch: 653, train loss: 464.4306, lr: 0.000100, spent: 142904.8 secs
epoch: 654, test val_loss: 0.141986
epoch: 654, train loss: 464.5404, lr: 0.000100, spent: 143122.4 secs
epoch: 655, test val_loss: 0.141986
epoch: 655, train loss: 464.4288, lr: 0.000100, spent: 143339.1 secs
epoch: 656, test val_loss: 0.141986
epoch: 656, train loss: 464.5398, lr: 0.000100, spent: 143556.0 secs
epoch: 657, test val_loss: 0.141986
epoch: 657, train loss: 464.5416, lr: 0.000100, spent: 143773.5 secs
epoch: 658, test val_loss: 0.141986
epoch: 658, train loss: 464.4306, lr: 0.000100, spent: 143991.1 secs
epoch: 659, test val_loss: 0.141986
epoch: 659, train loss: 464.5398, lr: 0.000100, spent: 144209.6 secs
epoch: 660, test val_loss: 0.141986
epoch: 660, train loss: 464.5416, lr: 0.000100, spent: 144427.0 secs
epoch: 661, test val_loss: 0.141986
epoch: 661, train loss: 464.5398, lr: 0.000100, spent: 144644.3 secs
epoch: 662, test val_loss: 0.141986
epoch: 662, train loss: 464.4294, lr: 0.000100, spent: 144861.3 secs
epoch: 663, test val_loss: 0.141986
epoch: 663, train loss: 464.5410, lr: 0.000100, spent: 145078.2 secs
epoch: 664, test val_loss: 0.141986
epoch: 664, train loss: 464.5410, lr: 0.000100, spent: 145295.3 secs
epoch: 665, test val_loss: 0.141986
epoch: 665, train loss: 464.7606, lr: 0.000100, spent: 145512.8 secs
epoch: 666, test val_loss: 0.141986
epoch: 666, train loss: 464.4317, lr: 0.000100, spent: 145730.8 secs
epoch: 667, test val_loss: 0.141986
epoch: 667, train loss: 464.4312, lr: 0.000100, spent: 145949.0 secs
epoch: 668, test val_loss: 0.141986
epoch: 668, train loss: 464.4294, lr: 0.000100, spent: 146166.7 secs
epoch: 669, test val_loss: 0.141986
epoch: 669, train loss: 464.6508, lr: 0.000100, spent: 146386.2 secs
epoch: 670, test val_loss: 0.141986
epoch: 670, train loss: 464.4300, lr: 0.000100, spent: 146603.6 secs
epoch: 671, test val_loss: 0.141986
epoch: 671, train loss: 464.5392, lr: 0.000100, spent: 146821.0 secs
epoch: 672, test val_loss: 0.141986
epoch: 672, train loss: 464.5410, lr: 0.000100, spent: 147039.9 secs
epoch: 673, test val_loss: 0.141986
epoch: 673, train loss: 464.4288, lr: 0.000100, spent: 147258.6 secs
epoch: 674, test val_loss: 0.141986
epoch: 674, train loss: 464.5404, lr: 0.000100, spent: 147475.4 secs
epoch: 675, test val_loss: 0.141986
epoch: 675, train loss: 464.4288, lr: 0.000100, spent: 147692.4 secs
epoch: 676, test val_loss: 0.141986
epoch: 676, train loss: 464.5404, lr: 0.000100, spent: 147910.6 secs
epoch: 677, test val_loss: 0.141986
epoch: 677, train loss: 464.4300, lr: 0.000100, spent: 148129.5 secs
epoch: 678, test val_loss: 0.141986
epoch: 678, train loss: 464.5398, lr: 0.000100, spent: 148348.4 secs
epoch: 679, test val_loss: 0.141986
epoch: 679, train loss: 464.5398, lr: 0.000100, spent: 148566.1 secs
epoch: 680, test val_loss: 0.141986
epoch: 680, train loss: 464.4300, lr: 0.000100, spent: 148783.8 secs
epoch: 681, test val_loss: 0.141986
epoch: 681, train loss: 464.5410, lr: 0.000100, spent: 149002.2 secs
epoch: 682, test val_loss: 0.141986
epoch: 682, train loss: 464.5392, lr: 0.000100, spent: 149219.8 secs
epoch: 683, test val_loss: 0.141986
epoch: 683, train loss: 464.5410, lr: 0.000100, spent: 149437.1 secs
epoch: 684, test val_loss: 0.141986
epoch: 684, train loss: 464.5410, lr: 0.000100, spent: 149654.6 secs
epoch: 685, test val_loss: 0.141986
epoch: 685, train loss: 464.4306, lr: 0.000100, spent: 149871.8 secs
epoch: 686, test val_loss: 0.141986
epoch: 686, train loss: 464.5410, lr: 0.000100, spent: 150089.6 secs
epoch: 687, test val_loss: 0.141986
epoch: 687, train loss: 464.6508, lr: 0.000100, spent: 150305.7 secs
epoch: 688, test val_loss: 0.141986
epoch: 688, train loss: 464.4312, lr: 0.000100, spent: 150525.2 secs
epoch: 689, test val_loss: 0.141986
epoch: 689, train loss: 464.5392, lr: 0.000100, spent: 150745.7 secs
epoch: 690, test val_loss: 0.141986
epoch: 690, train loss: 464.4294, lr: 0.000100, spent: 150962.4 secs
epoch: 691, test val_loss: 0.141986
epoch: 691, train loss: 464.5392, lr: 0.000100, spent: 151185.6 secs
epoch: 692, test val_loss: 0.141986
epoch: 692, train loss: 464.5410, lr: 0.000100, spent: 151403.1 secs
epoch: 693, test val_loss: 0.141986
epoch: 693, train loss: 464.5410, lr: 0.000100, spent: 151619.1 secs
epoch: 694, test val_loss: 0.141986
epoch: 694, train loss: 464.5398, lr: 0.000100, spent: 151840.7 secs
epoch: 695, test val_loss: 0.141986
epoch: 695, train loss: 464.4312, lr: 0.000100, spent: 152058.2 secs
epoch: 696, test val_loss: 0.141986
epoch: 696, train loss: 464.5398, lr: 0.000100, spent: 152276.1 secs
epoch: 697, test val_loss: 0.141986
epoch: 697, train loss: 464.5422, lr: 0.000100, spent: 152495.2 secs
epoch: 698, test val_loss: 0.141986
epoch: 698, train loss: 464.4300, lr: 0.000100, spent: 152712.2 secs
epoch: 699, test val_loss: 0.141986
epoch: 699, train loss: 464.4294, lr: 0.000100, spent: 152929.8 secs
epoch: 700, test val_loss: 0.141986
epoch: 700, train loss: 464.5392, lr: 0.000100, spent: 153147.1 secs
epoch: 701, test val_loss: 0.141986
epoch: 701, train loss: 464.7642, lr: 0.000100, spent: 153363.5 secs
epoch: 702, test val_loss: 0.141986
epoch: 702, train loss: 464.4300, lr: 0.000100, spent: 153581.4 secs
epoch: 703, test val_loss: 0.141986
epoch: 703, train loss: 464.6502, lr: 0.000100, spent: 153797.7 secs
epoch: 704, test val_loss: 0.141986
epoch: 704, train loss: 464.4288, lr: 0.000100, spent: 154014.6 secs
epoch: 705, test val_loss: 0.141986
epoch: 705, train loss: 464.6508, lr: 0.000100, spent: 154232.1 secs
epoch: 706, test val_loss: 0.141986
epoch: 706, train loss: 464.5398, lr: 0.000100, spent: 154449.7 secs
epoch: 707, test val_loss: 0.141986
epoch: 707, train loss: 464.4306, lr: 0.000100, spent: 154667.1 secs
epoch: 708, test val_loss: 0.141986
epoch: 708, train loss: 464.4312, lr: 0.000100, spent: 154884.7 secs
epoch: 709, test val_loss: 0.141986
epoch: 709, train loss: 464.4288, lr: 0.000100, spent: 155101.4 secs
epoch: 710, test val_loss: 0.141986
epoch: 710, train loss: 464.5410, lr: 0.000100, spent: 155318.2 secs
epoch: 711, test val_loss: 0.141986
epoch: 711, train loss: 464.4300, lr: 0.000100, spent: 155535.0 secs
epoch: 712, test val_loss: 0.141986
epoch: 712, train loss: 464.4312, lr: 0.000100, spent: 155751.5 secs
epoch: 713, test val_loss: 0.141986
epoch: 713, train loss: 464.4294, lr: 0.000100, spent: 155969.0 secs
epoch: 714, test val_loss: 0.141986
epoch: 714, train loss: 464.4294, lr: 0.000100, spent: 156186.3 secs
epoch: 715, test val_loss: 0.141986
epoch: 715, train loss: 464.4323, lr: 0.000100, spent: 156403.2 secs
epoch: 716, test val_loss: 0.141986
epoch: 716, train loss: 464.4306, lr: 0.000100, spent: 156619.9 secs
epoch: 717, test val_loss: 0.141986
epoch: 717, train loss: 464.8717, lr: 0.000100, spent: 156836.6 secs
epoch: 718, test val_loss: 0.141986
epoch: 718, train loss: 464.4300, lr: 0.000100, spent: 157053.1 secs
epoch: 719, test val_loss: 0.141986
epoch: 719, train loss: 464.6520, lr: 0.000100, spent: 157269.5 secs
epoch: 720, test val_loss: 0.141986
epoch: 720, train loss: 464.4306, lr: 0.000100, spent: 157488.7 secs
epoch: 721, test val_loss: 0.141986
epoch: 721, train loss: 464.4300, lr: 0.000100, spent: 157710.3 secs
epoch: 722, test val_loss: 0.141986
epoch: 722, train loss: 464.4306, lr: 0.000100, spent: 157929.3 secs
epoch: 723, test val_loss: 0.141986
epoch: 723, train loss: 464.5398, lr: 0.000100, spent: 158147.3 secs
epoch: 724, test val_loss: 0.141986
epoch: 724, train loss: 464.8705, lr: 0.000100, spent: 158364.8 secs
epoch: 725, test val_loss: 0.141986
epoch: 725, train loss: 464.6502, lr: 0.000100, spent: 158582.8 secs
epoch: 726, test val_loss: 0.141986
epoch: 726, train loss: 464.6496, lr: 0.000100, spent: 158802.5 secs
epoch: 727, test val_loss: 0.141986
epoch: 727, train loss: 464.5404, lr: 0.000100, spent: 159027.2 secs
epoch: 728, test val_loss: 0.141986
epoch: 728, train loss: 464.5398, lr: 0.000100, spent: 159249.3 secs
epoch: 729, test val_loss: 0.141986
epoch: 729, train loss: 464.5404, lr: 0.000100, spent: 159467.6 secs
epoch: 730, test val_loss: 0.141986
epoch: 730, train loss: 464.6520, lr: 0.000100, spent: 159684.5 secs
epoch: 731, test val_loss: 0.141986
epoch: 731, train loss: 464.5404, lr: 0.000100, spent: 159902.6 secs
epoch: 732, test val_loss: 0.141986
epoch: 732, train loss: 464.6532, lr: 0.000100, spent: 160123.8 secs
epoch: 733, test val_loss: 0.141986
epoch: 733, train loss: 464.5404, lr: 0.000100, spent: 160343.2 secs
epoch: 734, test val_loss: 0.141986
epoch: 734, train loss: 464.5398, lr: 0.000100, spent: 160560.8 secs
epoch: 735, test val_loss: 0.141986
epoch: 735, train loss: 464.6496, lr: 0.000100, spent: 160777.1 secs
epoch: 736, test val_loss: 0.141986
epoch: 736, train loss: 464.4300, lr: 0.000100, spent: 160994.9 secs
epoch: 737, test val_loss: 0.141986
epoch: 737, train loss: 464.4300, lr: 0.000100, spent: 161211.8 secs
epoch: 738, test val_loss: 0.141986
epoch: 738, train loss: 464.5398, lr: 0.000100, spent: 161429.8 secs
epoch: 739, test val_loss: 0.141986
epoch: 739, train loss: 464.5398, lr: 0.000100, spent: 161647.4 secs
epoch: 740, test val_loss: 0.141986
epoch: 740, train loss: 464.4323, lr: 0.000100, spent: 161866.5 secs
epoch: 741, test val_loss: 0.141986
epoch: 741, train loss: 464.4300, lr: 0.000100, spent: 162085.2 secs
epoch: 742, test val_loss: 0.141986
epoch: 742, train loss: 464.5404, lr: 0.000100, spent: 162302.6 secs
epoch: 743, test val_loss: 0.141986
epoch: 743, train loss: 464.4312, lr: 0.000100, spent: 162519.9 secs
epoch: 744, test val_loss: 0.141986
epoch: 744, train loss: 464.7612, lr: 0.000100, spent: 162736.7 secs
epoch: 745, test val_loss: 0.141986
epoch: 745, train loss: 464.5422, lr: 0.000100, spent: 162953.8 secs
epoch: 746, test val_loss: 0.141986
epoch: 746, train loss: 464.5410, lr: 0.000100, spent: 163171.7 secs
epoch: 747, test val_loss: 0.141986
epoch: 747, train loss: 464.5392, lr: 0.000100, spent: 163388.2 secs
epoch: 748, test val_loss: 0.141986
epoch: 748, train loss: 464.5392, lr: 0.000100, spent: 163604.8 secs
epoch: 749, test val_loss: 0.141986
epoch: 749, train loss: 464.4294, lr: 0.000100, spent: 163821.8 secs
epoch: 750, test val_loss: 0.141986
epoch: 750, train loss: 464.5416, lr: 0.000100, spent: 164040.0 secs
epoch: 751, test val_loss: 0.141986
epoch: 751, train loss: 464.6508, lr: 0.000100, spent: 164257.7 secs
epoch: 752, test val_loss: 0.141986
epoch: 752, train loss: 464.6502, lr: 0.000100, spent: 164474.6 secs
epoch: 753, test val_loss: 0.141986
epoch: 753, train loss: 464.4306, lr: 0.000100, spent: 164689.9 secs
epoch: 754, test val_loss: 0.141986
epoch: 754, train loss: 464.5392, lr: 0.000100, spent: 164905.9 secs
epoch: 755, test val_loss: 0.141986
epoch: 755, train loss: 464.4294, lr: 0.000100, spent: 165123.6 secs
epoch: 756, test val_loss: 0.141986
epoch: 756, train loss: 464.5392, lr: 0.000100, spent: 165340.8 secs
epoch: 757, test val_loss: 0.141986
epoch: 757, train loss: 464.4288, lr: 0.000100, spent: 165558.9 secs
epoch: 758, test val_loss: 0.141986
epoch: 758, train loss: 464.4300, lr: 0.000100, spent: 165779.6 secs
epoch: 759, test val_loss: 0.141986
epoch: 759, train loss: 464.4288, lr: 0.000100, spent: 165998.2 secs
epoch: 760, test val_loss: 0.141986
epoch: 760, train loss: 464.4288, lr: 0.000100, spent: 166216.3 secs
epoch: 761, test val_loss: 0.141986
epoch: 761, train loss: 464.5404, lr: 0.000100, spent: 166436.1 secs
epoch: 762, test val_loss: 0.141986
epoch: 762, train loss: 464.4312, lr: 0.000100, spent: 166654.7 secs
epoch: 763, test val_loss: 0.141986
epoch: 763, train loss: 464.4294, lr: 0.000100, spent: 166873.9 secs
epoch: 764, test val_loss: 0.141986
epoch: 764, train loss: 464.5410, lr: 0.000100, spent: 167092.2 secs
epoch: 765, test val_loss: 0.141986
epoch: 765, train loss: 464.5404, lr: 0.000100, spent: 167312.3 secs
epoch: 766, test val_loss: 0.141986
epoch: 766, train loss: 464.4294, lr: 0.000100, spent: 167532.7 secs
epoch: 767, test val_loss: 0.141986
epoch: 767, train loss: 464.5398, lr: 0.000100, spent: 167752.5 secs
epoch: 768, test val_loss: 0.141986
epoch: 768, train loss: 464.4300, lr: 0.000100, spent: 167971.9 secs
epoch: 769, test val_loss: 0.141986
epoch: 769, train loss: 464.4300, lr: 0.000100, spent: 168191.2 secs
epoch: 770, test val_loss: 0.141986
epoch: 770, train loss: 464.5404, lr: 0.000100, spent: 168411.3 secs
epoch: 771, test val_loss: 0.141986
epoch: 771, train loss: 464.5392, lr: 0.000100, spent: 168630.8 secs
epoch: 772, test val_loss: 0.141986
epoch: 772, train loss: 464.4311, lr: 0.000100, spent: 168850.6 secs
epoch: 773, test val_loss: 0.141986
epoch: 773, train loss: 464.4312, lr: 0.000100, spent: 169071.7 secs
epoch: 774, test val_loss: 0.141986
epoch: 774, train loss: 464.4300, lr: 0.000100, spent: 169291.7 secs
epoch: 775, test val_loss: 0.141986
epoch: 775, train loss: 464.4288, lr: 0.000100, spent: 169510.3 secs
epoch: 776, test val_loss: 0.141986
epoch: 776, train loss: 464.5398, lr: 0.000100, spent: 169729.9 secs
epoch: 777, test val_loss: 0.141986
epoch: 777, train loss: 464.4300, lr: 0.000100, spent: 169949.2 secs
epoch: 778, test val_loss: 0.141986
epoch: 778, train loss: 464.4294, lr: 0.000100, spent: 170168.8 secs
epoch: 779, test val_loss: 0.141986
epoch: 779, train loss: 464.4294, lr: 0.000100, spent: 170388.6 secs
epoch: 780, test val_loss: 0.141986
epoch: 780, train loss: 464.6496, lr: 0.000100, spent: 170607.2 secs
epoch: 781, test val_loss: 0.141986
epoch: 781, train loss: 464.5404, lr: 0.000100, spent: 170826.2 secs
epoch: 782, test val_loss: 0.141986
epoch: 782, train loss: 464.5404, lr: 0.000100, spent: 171046.5 secs
epoch: 783, test val_loss: 0.141986
epoch: 783, train loss: 464.4300, lr: 0.000100, spent: 171266.9 secs
epoch: 784, test val_loss: 0.141986
epoch: 784, train loss: 464.5404, lr: 0.000100, spent: 171487.5 secs
epoch: 785, test val_loss: 0.141986
epoch: 785, train loss: 464.6502, lr: 0.000100, spent: 171704.7 secs
epoch: 786, test val_loss: 0.141986
epoch: 786, train loss: 464.5398, lr: 0.000100, spent: 171923.8 secs
epoch: 787, test val_loss: 0.141986
epoch: 787, train loss: 464.4288, lr: 0.000100, spent: 172141.5 secs
epoch: 788, test val_loss: 0.141986
epoch: 788, train loss: 464.4300, lr: 0.000100, spent: 172359.1 secs
epoch: 789, test val_loss: 0.141986
epoch: 789, train loss: 464.4294, lr: 0.000100, spent: 172579.4 secs
epoch: 790, test val_loss: 0.141986
epoch: 790, train loss: 464.4300, lr: 0.000100, spent: 172798.5 secs
epoch: 791, test val_loss: 0.141986
epoch: 791, train loss: 464.6502, lr: 0.000100, spent: 173017.2 secs
epoch: 792, test val_loss: 0.141986
epoch: 792, train loss: 464.5392, lr: 0.000100, spent: 173234.6 secs
epoch: 793, test val_loss: 0.141986
epoch: 793, train loss: 464.5410, lr: 0.000100, spent: 173454.8 secs
epoch: 794, test val_loss: 0.141986
epoch: 794, train loss: 464.4306, lr: 0.000100, spent: 173673.6 secs
epoch: 795, test val_loss: 0.141986
epoch: 795, train loss: 464.6502, lr: 0.000100, spent: 173892.7 secs
epoch: 796, test val_loss: 0.141986
epoch: 796, train loss: 464.5404, lr: 0.000100, spent: 174112.0 secs
epoch: 797, test val_loss: 0.141986
epoch: 797, train loss: 464.5410, lr: 0.000100, spent: 174331.4 secs
epoch: 798, test val_loss: 0.141986
epoch: 798, train loss: 464.4288, lr: 0.000100, spent: 174551.1 secs
epoch: 799, test val_loss: 0.141986
epoch: 799, train loss: 464.4294, lr: 0.000100, spent: 174770.6 secs
epoch: 800, test val_loss: 0.141986
epoch: 800, train loss: 464.4306, lr: 0.000100, spent: 174990.4 secs
epoch: 801, test val_loss: 0.141986
epoch: 801, train loss: 464.5398, lr: 0.000100, spent: 175209.6 secs
epoch: 802, test val_loss: 0.141986
epoch: 802, train loss: 464.5398, lr: 0.000100, spent: 175430.0 secs
epoch: 803, test val_loss: 0.141986
epoch: 803, train loss: 464.7612, lr: 0.000100, spent: 175650.7 secs
epoch: 804, test val_loss: 0.141986
epoch: 804, train loss: 464.5404, lr: 0.000100, spent: 175870.2 secs
epoch: 805, test val_loss: 0.141986
epoch: 805, train loss: 464.4312, lr: 0.000100, spent: 176089.3 secs
epoch: 806, test val_loss: 0.141986
epoch: 806, train loss: 464.6496, lr: 0.000100, spent: 176308.2 secs
epoch: 807, test val_loss: 0.141986
epoch: 807, train loss: 464.4306, lr: 0.000100, spent: 176527.8 secs
epoch: 808, test val_loss: 0.141986
epoch: 808, train loss: 464.5398, lr: 0.000100, spent: 176745.8 secs
epoch: 809, test val_loss: 0.141986
epoch: 809, train loss: 464.4300, lr: 0.000100, spent: 176965.3 secs
epoch: 810, test val_loss: 0.141986
epoch: 810, train loss: 464.5428, lr: 0.000100, spent: 177184.6 secs
epoch: 811, test val_loss: 0.141986
epoch: 811, train loss: 464.5416, lr: 0.000100, spent: 177402.1 secs
epoch: 812, test val_loss: 0.141986
epoch: 812, train loss: 464.4306, lr: 0.000100, spent: 177620.9 secs
epoch: 813, test val_loss: 0.141986
epoch: 813, train loss: 464.6508, lr: 0.000100, spent: 177839.7 secs
epoch: 814, test val_loss: 0.141986
epoch: 814, train loss: 464.5404, lr: 0.000100, spent: 178058.8 secs
epoch: 815, test val_loss: 0.141986
epoch: 815, train loss: 464.4300, lr: 0.000100, spent: 178278.9 secs
epoch: 816, test val_loss: 0.141986
epoch: 816, train loss: 464.4306, lr: 0.000100, spent: 178497.8 secs
epoch: 817, test val_loss: 0.141986
epoch: 817, train loss: 464.5422, lr: 0.000100, spent: 178717.3 secs
epoch: 818, test val_loss: 0.141986
epoch: 818, train loss: 464.5404, lr: 0.000100, spent: 178938.1 secs
epoch: 819, test val_loss: 0.141986
epoch: 819, train loss: 464.4288, lr: 0.000100, spent: 179157.6 secs
epoch: 820, test val_loss: 0.141986
epoch: 820, train loss: 464.7612, lr: 0.000100, spent: 179377.5 secs
epoch: 821, test val_loss: 0.141986
epoch: 821, train loss: 464.4294, lr: 0.000100, spent: 179596.6 secs
epoch: 822, test val_loss: 0.141986
epoch: 822, train loss: 464.5404, lr: 0.000100, spent: 179817.0 secs
epoch: 823, test val_loss: 0.141986
epoch: 823, train loss: 464.5392, lr: 0.000100, spent: 180036.2 secs
epoch: 824, test val_loss: 0.141986
epoch: 824, train loss: 464.4306, lr: 0.000100, spent: 180255.8 secs
epoch: 825, test val_loss: 0.141986
epoch: 825, train loss: 464.5416, lr: 0.000100, spent: 180475.5 secs
epoch: 826, test val_loss: 0.141986
epoch: 826, train loss: 464.5398, lr: 0.000100, spent: 180696.2 secs
epoch: 827, test val_loss: 0.141986
epoch: 827, train loss: 464.5404, lr: 0.000100, spent: 180915.6 secs
epoch: 828, test val_loss: 0.141986
epoch: 828, train loss: 464.4288, lr: 0.000100, spent: 181134.8 secs
epoch: 829, test val_loss: 0.141986
epoch: 829, train loss: 464.4294, lr: 0.000100, spent: 181353.6 secs
epoch: 830, test val_loss: 0.141986
epoch: 830, train loss: 464.4288, lr: 0.000100, spent: 181572.8 secs
epoch: 831, test val_loss: 0.141986
epoch: 831, train loss: 464.7600, lr: 0.000100, spent: 181793.1 secs
epoch: 832, test val_loss: 0.141986
epoch: 832, train loss: 464.4312, lr: 0.000100, spent: 182012.3 secs
epoch: 833, test val_loss: 0.141986
epoch: 833, train loss: 464.4300, lr: 0.000100, spent: 182230.5 secs
epoch: 834, test val_loss: 0.141986
epoch: 834, train loss: 464.6508, lr: 0.000100, spent: 182448.8 secs
epoch: 835, test val_loss: 0.141986
epoch: 835, train loss: 464.4312, lr: 0.000100, spent: 182668.6 secs
epoch: 836, test val_loss: 0.141986
epoch: 836, train loss: 464.6514, lr: 0.000100, spent: 182887.8 secs
epoch: 837, test val_loss: 0.141986
epoch: 837, train loss: 464.4317, lr: 0.000100, spent: 183106.8 secs
epoch: 838, test val_loss: 0.141986
epoch: 838, train loss: 464.4288, lr: 0.000100, spent: 183326.0 secs
epoch: 839, test val_loss: 0.141986
epoch: 839, train loss: 464.4288, lr: 0.000100, spent: 183545.1 secs
epoch: 840, test val_loss: 0.141986
epoch: 840, train loss: 464.4300, lr: 0.000100, spent: 183763.3 secs
epoch: 841, test val_loss: 0.141986
epoch: 841, train loss: 464.4312, lr: 0.000100, spent: 183982.3 secs
epoch: 842, test val_loss: 0.141986
epoch: 842, train loss: 464.5398, lr: 0.000100, spent: 184201.4 secs
epoch: 843, test val_loss: 0.141986
epoch: 843, train loss: 464.4294, lr: 0.000100, spent: 184420.0 secs
epoch: 844, test val_loss: 0.141986
epoch: 844, train loss: 464.5398, lr: 0.000100, spent: 184638.6 secs
epoch: 845, test val_loss: 0.141986
epoch: 845, train loss: 464.4306, lr: 0.000100, spent: 184856.0 secs
epoch: 846, test val_loss: 0.141986
epoch: 846, train loss: 464.4300, lr: 0.000100, spent: 185075.2 secs
epoch: 847, test val_loss: 0.141986
epoch: 847, train loss: 464.5398, lr: 0.000100, spent: 185294.1 secs
epoch: 848, test val_loss: 0.141986
epoch: 848, train loss: 464.6508, lr: 0.000100, spent: 185514.6 secs
epoch: 849, test val_loss: 0.141986
epoch: 849, train loss: 464.5398, lr: 0.000100, spent: 185734.2 secs
epoch: 850, test val_loss: 0.141986
epoch: 850, train loss: 464.4306, lr: 0.000100, spent: 185953.8 secs
epoch: 851, test val_loss: 0.141986
epoch: 851, train loss: 464.5404, lr: 0.000100, spent: 186173.0 secs
epoch: 852, test val_loss: 0.141986
epoch: 852, train loss: 464.4312, lr: 0.000100, spent: 186392.7 secs
epoch: 853, test val_loss: 0.141986
epoch: 853, train loss: 464.4306, lr: 0.000100, spent: 186612.2 secs
epoch: 854, test val_loss: 0.141986
epoch: 854, train loss: 464.5398, lr: 0.000100, spent: 186831.5 secs
epoch: 855, test val_loss: 0.141986
epoch: 855, train loss: 464.4306, lr: 0.000100, spent: 187049.5 secs
epoch: 856, test val_loss: 0.141986
epoch: 856, train loss: 464.8711, lr: 0.000100, spent: 187269.1 secs
epoch: 857, test val_loss: 0.141986
epoch: 857, train loss: 464.5392, lr: 0.000100, spent: 187488.2 secs
epoch: 858, test val_loss: 0.141986
epoch: 858, train loss: 464.4288, lr: 0.000100, spent: 187707.3 secs
epoch: 859, test val_loss: 0.141986
epoch: 859, train loss: 464.4300, lr: 0.000100, spent: 187926.5 secs
epoch: 860, test val_loss: 0.141986
epoch: 860, train loss: 464.4306, lr: 0.000100, spent: 188145.8 secs
epoch: 861, test val_loss: 0.141986
epoch: 861, train loss: 464.4306, lr: 0.000100, spent: 188366.2 secs
epoch: 862, test val_loss: 0.141986
epoch: 862, train loss: 464.4294, lr: 0.000100, spent: 188585.9 secs
epoch: 863, test val_loss: 0.141986
epoch: 863, train loss: 464.5404, lr: 0.000100, spent: 188806.2 secs
epoch: 864, test val_loss: 0.141986
epoch: 864, train loss: 464.5404, lr: 0.000100, spent: 189027.1 secs
epoch: 865, test val_loss: 0.141986
epoch: 865, train loss: 464.4306, lr: 0.000100, spent: 189246.3 secs
epoch: 866, test val_loss: 0.141986
epoch: 866, train loss: 464.4300, lr: 0.000100, spent: 189466.0 secs
epoch: 867, test val_loss: 0.141986
epoch: 867, train loss: 464.4288, lr: 0.000100, spent: 189685.3 secs
epoch: 868, test val_loss: 0.141986
epoch: 868, train loss: 464.4288, lr: 0.000100, spent: 189904.4 secs
epoch: 869, test val_loss: 0.141986
epoch: 869, train loss: 464.8723, lr: 0.000100, spent: 190124.5 secs
epoch: 870, test val_loss: 0.141986
epoch: 870, train loss: 464.6508, lr: 0.000100, spent: 190343.8 secs
epoch: 871, test val_loss: 0.141986
epoch: 871, train loss: 464.4300, lr: 0.000100, spent: 190564.9 secs
epoch: 872, test val_loss: 0.141986
epoch: 872, train loss: 464.4294, lr: 0.000100, spent: 190786.0 secs
epoch: 873, test val_loss: 0.141986
epoch: 873, train loss: 464.7630, lr: 0.000100, spent: 191005.3 secs
epoch: 874, test val_loss: 0.141986
epoch: 874, train loss: 464.5416, lr: 0.000100, spent: 191224.1 secs
epoch: 875, test val_loss: 0.141986
epoch: 875, train loss: 464.4317, lr: 0.000100, spent: 191444.9 secs
epoch: 876, test val_loss: 0.141986
epoch: 876, train loss: 464.5416, lr: 0.000100, spent: 191665.1 secs
epoch: 877, test val_loss: 0.141986
epoch: 877, train loss: 464.6502, lr: 0.000100, spent: 191883.4 secs
epoch: 878, test val_loss: 0.141986
epoch: 878, train loss: 464.4300, lr: 0.000100, spent: 192101.8 secs
epoch: 879, test val_loss: 0.141986
epoch: 879, train loss: 464.4312, lr: 0.000100, spent: 192321.1 secs
epoch: 880, test val_loss: 0.141986
epoch: 880, train loss: 464.4312, lr: 0.000100, spent: 192540.1 secs
epoch: 881, test val_loss: 0.141986
epoch: 881, train loss: 464.4306, lr: 0.000100, spent: 192759.6 secs
epoch: 882, test val_loss: 0.141986
epoch: 882, train loss: 464.4288, lr: 0.000100, spent: 192979.0 secs
epoch: 883, test val_loss: 0.141986
epoch: 883, train loss: 464.5404, lr: 0.000100, spent: 193198.8 secs
epoch: 884, test val_loss: 0.141986
epoch: 884, train loss: 464.4317, lr: 0.000100, spent: 193418.0 secs
epoch: 885, test val_loss: 0.141986
epoch: 885, train loss: 464.5398, lr: 0.000100, spent: 193637.8 secs
epoch: 886, test val_loss: 0.141986
epoch: 886, train loss: 464.5404, lr: 0.000100, spent: 193857.8 secs
epoch: 887, test val_loss: 0.141986
epoch: 887, train loss: 464.5410, lr: 0.000100, spent: 194078.0 secs
epoch: 888, test val_loss: 0.141986
epoch: 888, train loss: 464.5404, lr: 0.000100, spent: 194297.9 secs
epoch: 889, test val_loss: 0.141986
epoch: 889, train loss: 464.5416, lr: 0.000100, spent: 194516.5 secs
epoch: 890, test val_loss: 0.141986
epoch: 890, train loss: 464.5404, lr: 0.000100, spent: 194735.2 secs
epoch: 891, test val_loss: 0.141986
epoch: 891, train loss: 464.4294, lr: 0.000100, spent: 194954.2 secs
epoch: 892, test val_loss: 0.141986
epoch: 892, train loss: 464.6496, lr: 0.000100, spent: 195173.0 secs
epoch: 893, test val_loss: 0.141986
epoch: 893, train loss: 464.6502, lr: 0.000100, spent: 195392.0 secs
epoch: 894, test val_loss: 0.141986
epoch: 894, train loss: 464.5428, lr: 0.000100, spent: 195611.7 secs
epoch: 895, test val_loss: 0.141986
epoch: 895, train loss: 464.4312, lr: 0.000100, spent: 195830.7 secs
epoch: 896, test val_loss: 0.141986
epoch: 896, train loss: 464.5398, lr: 0.000100, spent: 196050.7 secs
epoch: 897, test val_loss: 0.141986
epoch: 897, train loss: 464.4300, lr: 0.000100, spent: 196269.5 secs
epoch: 898, test val_loss: 0.141986
epoch: 898, train loss: 464.4306, lr: 0.000100, spent: 196489.4 secs
epoch: 899, test val_loss: 0.141986
epoch: 899, train loss: 464.5392, lr: 0.000100, spent: 196708.9 secs
epoch: 900, test val_loss: 0.141986
epoch: 900, train loss: 464.4294, lr: 0.000100, spent: 196928.9 secs
epoch: 901, test val_loss: 0.141986
epoch: 901, train loss: 464.4294, lr: 0.000100, spent: 197148.6 secs
epoch: 902, test val_loss: 0.141986
epoch: 902, train loss: 464.5422, lr: 0.000100, spent: 197367.7 secs
epoch: 903, test val_loss: 0.141986
epoch: 903, train loss: 464.4288, lr: 0.000100, spent: 197586.5 secs
epoch: 904, test val_loss: 0.141986
epoch: 904, train loss: 464.5398, lr: 0.000100, spent: 197805.0 secs
epoch: 905, test val_loss: 0.141986
epoch: 905, train loss: 464.5428, lr: 0.000100, spent: 198023.9 secs
epoch: 906, test val_loss: 0.141986
epoch: 906, train loss: 464.4294, lr: 0.000100, spent: 198243.1 secs
epoch: 907, test val_loss: 0.141986
epoch: 907, train loss: 464.4288, lr: 0.000100, spent: 198462.7 secs
epoch: 908, test val_loss: 0.141986
epoch: 908, train loss: 464.5422, lr: 0.000100, spent: 198681.8 secs
epoch: 909, test val_loss: 0.141986
epoch: 909, train loss: 464.6496, lr: 0.000100, spent: 198900.9 secs
epoch: 910, test val_loss: 0.141986
epoch: 910, train loss: 464.7612, lr: 0.000100, spent: 199121.9 secs
epoch: 911, test val_loss: 0.141986
epoch: 911, train loss: 464.4300, lr: 0.000100, spent: 199342.0 secs
epoch: 912, test val_loss: 0.141986
epoch: 912, train loss: 464.4294, lr: 0.000100, spent: 199562.0 secs
epoch: 913, test val_loss: 0.141986
epoch: 913, train loss: 464.5398, lr: 0.000100, spent: 199781.4 secs
epoch: 914, test val_loss: 0.141986
epoch: 914, train loss: 464.4311, lr: 0.000100, spent: 200001.2 secs
epoch: 915, test val_loss: 0.141986
epoch: 915, train loss: 464.4300, lr: 0.000100, spent: 200221.1 secs
epoch: 916, test val_loss: 0.141986
epoch: 916, train loss: 464.6496, lr: 0.000100, spent: 200440.3 secs
epoch: 917, test val_loss: 0.141986
epoch: 917, train loss: 464.4300, lr: 0.000100, spent: 200659.7 secs
epoch: 918, test val_loss: 0.141986
epoch: 918, train loss: 464.5404, lr: 0.000100, spent: 200879.8 secs
epoch: 919, test val_loss: 0.141986
epoch: 919, train loss: 464.6496, lr: 0.000100, spent: 201098.7 secs
epoch: 920, test val_loss: 0.141986
epoch: 920, train loss: 464.4300, lr: 0.000100, spent: 201318.7 secs
epoch: 921, test val_loss: 0.141986
epoch: 921, train loss: 464.4294, lr: 0.000100, spent: 201538.3 secs
epoch: 922, test val_loss: 0.141986
epoch: 922, train loss: 464.5404, lr: 0.000100, spent: 201757.0 secs
epoch: 923, test val_loss: 0.141986
epoch: 923, train loss: 464.4312, lr: 0.000100, spent: 201975.8 secs
epoch: 924, test val_loss: 0.141986
epoch: 924, train loss: 464.4300, lr: 0.000100, spent: 202195.2 secs
epoch: 925, test val_loss: 0.141986
epoch: 925, train loss: 464.4300, lr: 0.000100, spent: 202415.5 secs
epoch: 926, test val_loss: 0.141986
epoch: 926, train loss: 464.5392, lr: 0.000100, spent: 202634.8 secs
epoch: 927, test val_loss: 0.141986
epoch: 927, train loss: 464.4294, lr: 0.000100, spent: 202855.3 secs
epoch: 928, test val_loss: 0.141986
epoch: 928, train loss: 464.5398, lr: 0.000100, spent: 203074.7 secs
epoch: 929, test val_loss: 0.141986
epoch: 929, train loss: 464.7606, lr: 0.000100, spent: 203292.7 secs
epoch: 930, test val_loss: 0.141986
epoch: 930, train loss: 464.5416, lr: 0.000100, spent: 203512.3 secs
epoch: 931, test val_loss: 0.141986
epoch: 931, train loss: 464.4294, lr: 0.000100, spent: 203731.1 secs
epoch: 932, test val_loss: 0.141986
epoch: 932, train loss: 464.4294, lr: 0.000100, spent: 203950.3 secs
epoch: 933, test val_loss: 0.141986
epoch: 933, train loss: 464.4294, lr: 0.000100, spent: 204169.5 secs
epoch: 934, test val_loss: 0.141986
epoch: 934, train loss: 464.6520, lr: 0.000100, spent: 204389.1 secs
epoch: 935, test val_loss: 0.141986
epoch: 935, train loss: 464.4300, lr: 0.000100, spent: 204607.4 secs
epoch: 936, test val_loss: 0.141986
epoch: 936, train loss: 464.4329, lr: 0.000100, spent: 204826.5 secs
epoch: 937, test val_loss: 0.141986
epoch: 937, train loss: 464.4300, lr: 0.000100, spent: 205044.7 secs
epoch: 938, test val_loss: 0.141986
epoch: 938, train loss: 464.5398, lr: 0.000100, spent: 205264.0 secs
epoch: 939, test val_loss: 0.141986
epoch: 939, train loss: 464.4294, lr: 0.000100, spent: 205483.5 secs
epoch: 940, test val_loss: 0.141986
epoch: 940, train loss: 464.4300, lr: 0.000100, spent: 205704.0 secs
epoch: 941, test val_loss: 0.141986
epoch: 941, train loss: 464.4300, lr: 0.000100, spent: 205921.9 secs
epoch: 942, test val_loss: 0.141986
epoch: 942, train loss: 464.5392, lr: 0.000100, spent: 206141.7 secs
epoch: 943, test val_loss: 0.141986
epoch: 943, train loss: 464.5404, lr: 0.000100, spent: 206362.0 secs
epoch: 944, test val_loss: 0.141986
epoch: 944, train loss: 464.5398, lr: 0.000100, spent: 206582.8 secs
epoch: 945, test val_loss: 0.141986
epoch: 945, train loss: 464.6508, lr: 0.000100, spent: 206801.9 secs
epoch: 946, test val_loss: 0.141986
epoch: 946, train loss: 464.7606, lr: 0.000100, spent: 207021.7 secs
epoch: 947, test val_loss: 0.141986
epoch: 947, train loss: 464.7612, lr: 0.000100, spent: 207241.1 secs
epoch: 948, test val_loss: 0.141986
epoch: 948, train loss: 464.5398, lr: 0.000100, spent: 207460.4 secs
epoch: 949, test val_loss: 0.141986
epoch: 949, train loss: 464.6496, lr: 0.000100, spent: 207679.7 secs
epoch: 950, test val_loss: 0.141986
epoch: 950, train loss: 464.4294, lr: 0.000100, spent: 207899.0 secs
epoch: 951, test val_loss: 0.141986
epoch: 951, train loss: 464.4294, lr: 0.000100, spent: 208117.8 secs
epoch: 952, test val_loss: 0.141986
epoch: 952, train loss: 464.5404, lr: 0.000100, spent: 208337.4 secs
epoch: 953, test val_loss: 0.141986
epoch: 953, train loss: 464.5410, lr: 0.000100, spent: 208558.3 secs
epoch: 954, test val_loss: 0.141986
epoch: 954, train loss: 464.4294, lr: 0.000100, spent: 208778.0 secs
epoch: 955, test val_loss: 0.141986
epoch: 955, train loss: 464.5404, lr: 0.000100, spent: 208998.0 secs
epoch: 956, test val_loss: 0.141986
epoch: 956, train loss: 464.4294, lr: 0.000100, spent: 209217.8 secs
epoch: 957, test val_loss: 0.141986
epoch: 957, train loss: 464.6508, lr: 0.000100, spent: 209435.6 secs
epoch: 958, test val_loss: 0.141986
epoch: 958, train loss: 464.4294, lr: 0.000100, spent: 209653.9 secs
epoch: 959, test val_loss: 0.141986
epoch: 959, train loss: 464.4300, lr: 0.000100, spent: 209872.5 secs
epoch: 960, test val_loss: 0.141986
epoch: 960, train loss: 464.4294, lr: 0.000100, spent: 210090.8 secs
epoch: 961, test val_loss: 0.141986
epoch: 961, train loss: 464.4306, lr: 0.000100, spent: 210308.3 secs
epoch: 962, test val_loss: 0.141986
epoch: 962, train loss: 464.5398, lr: 0.000100, spent: 210527.7 secs
epoch: 963, test val_loss: 0.141986
epoch: 963, train loss: 464.4294, lr: 0.000100, spent: 210746.2 secs
epoch: 964, test val_loss: 0.141986
epoch: 964, train loss: 464.5398, lr: 0.000100, spent: 210966.5 secs
epoch: 965, test val_loss: 0.141986
epoch: 965, train loss: 464.5410, lr: 0.000100, spent: 211185.0 secs
epoch: 966, test val_loss: 0.141986
epoch: 966, train loss: 464.6526, lr: 0.000100, spent: 211404.2 secs
epoch: 967, test val_loss: 0.141986
epoch: 967, train loss: 464.5398, lr: 0.000100, spent: 211624.0 secs
epoch: 968, test val_loss: 0.141986
epoch: 968, train loss: 464.5410, lr: 0.000100, spent: 211842.4 secs
epoch: 969, test val_loss: 0.141986
epoch: 969, train loss: 464.6502, lr: 0.000100, spent: 212061.1 secs
epoch: 970, test val_loss: 0.141986
epoch: 970, train loss: 464.4300, lr: 0.000100, spent: 212279.7 secs
epoch: 971, test val_loss: 0.141986
epoch: 971, train loss: 464.6520, lr: 0.000100, spent: 212497.7 secs
epoch: 972, test val_loss: 0.141986
epoch: 972, train loss: 464.6508, lr: 0.000100, spent: 212717.7 secs
epoch: 973, test val_loss: 0.141986
epoch: 973, train loss: 464.4306, lr: 0.000100, spent: 212938.4 secs
epoch: 974, test val_loss: 0.141986
epoch: 974, train loss: 464.5392, lr: 0.000100, spent: 213158.2 secs
epoch: 975, test val_loss: 0.141986
epoch: 975, train loss: 464.9839, lr: 0.000100, spent: 213377.2 secs
epoch: 976, test val_loss: 0.141986
epoch: 976, train loss: 464.5410, lr: 0.000100, spent: 213595.4 secs
epoch: 977, test val_loss: 0.141986
epoch: 977, train loss: 464.4300, lr: 0.000100, spent: 213815.2 secs
epoch: 978, test val_loss: 0.141986
epoch: 978, train loss: 464.4300, lr: 0.000100, spent: 214035.5 secs
epoch: 979, test val_loss: 0.141986
epoch: 979, train loss: 464.6496, lr: 0.000100, spent: 214255.1 secs
epoch: 980, test val_loss: 0.141986
epoch: 980, train loss: 464.4294, lr: 0.000100, spent: 214476.3 secs
epoch: 981, test val_loss: 0.141986
epoch: 981, train loss: 464.4294, lr: 0.000100, spent: 214696.4 secs
epoch: 982, test val_loss: 0.141986
epoch: 982, train loss: 464.4288, lr: 0.000100, spent: 214915.9 secs
epoch: 983, test val_loss: 0.141986
epoch: 983, train loss: 464.7606, lr: 0.000100, spent: 215136.1 secs
epoch: 984, test val_loss: 0.141986
epoch: 984, train loss: 464.6514, lr: 0.000100, spent: 215356.8 secs
epoch: 985, test val_loss: 0.141986
epoch: 985, train loss: 464.4317, lr: 0.000100, spent: 215577.5 secs
epoch: 986, test val_loss: 0.141986
epoch: 986, train loss: 464.4306, lr: 0.000100, spent: 215797.9 secs
epoch: 987, test val_loss: 0.141986
epoch: 987, train loss: 464.4294, lr: 0.000100, spent: 216017.9 secs
epoch: 988, test val_loss: 0.141986
epoch: 988, train loss: 464.5392, lr: 0.000100, spent: 216237.7 secs
epoch: 989, test val_loss: 0.141986
epoch: 989, train loss: 464.4294, lr: 0.000100, spent: 216457.2 secs
epoch: 990, test val_loss: 0.141986
epoch: 990, train loss: 464.4294, lr: 0.000100, spent: 216675.5 secs
epoch: 991, test val_loss: 0.141986
epoch: 991, train loss: 464.5404, lr: 0.000100, spent: 216893.8 secs
epoch: 992, test val_loss: 0.141986
epoch: 992, train loss: 464.7606, lr: 0.000100, spent: 217113.1 secs
epoch: 993, test val_loss: 0.141986
epoch: 993, train loss: 464.4294, lr: 0.000100, spent: 217330.6 secs
epoch: 994, test val_loss: 0.141986
epoch: 994, train loss: 464.6508, lr: 0.000100, spent: 217551.9 secs
epoch: 995, test val_loss: 0.141986
epoch: 995, train loss: 464.6508, lr: 0.000100, spent: 217771.3 secs
epoch: 996, test val_loss: 0.141986
epoch: 996, train loss: 464.4294, lr: 0.000100, spent: 217991.6 secs
epoch: 997, test val_loss: 0.141986
epoch: 997, train loss: 464.4294, lr: 0.000100, spent: 218210.9 secs
epoch: 998, test val_loss: 0.141986
epoch: 998, train loss: 464.4300, lr: 0.000100, spent: 218430.4 secs
epoch: 999, test val_loss: 0.141986
epoch: 999, train loss: 464.4300, lr: 0.000100, spent: 218650.5 secs
[0.8372290359985571]
